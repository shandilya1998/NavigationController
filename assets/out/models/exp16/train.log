2021-12-16 02:26:21.939147: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/shandilya/.mujoco/mjpro150/bin
2021-12-16 02:26:21.939189: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
/home/shandilya/Desktop/Projects/NavigationController
Env Type: maze
Task: GoalRewardNoObstacle
Model: <class 'stable_baselines3.td3.td3.TD3'>
Using cpu device
Logging to assets/out/models/exp16/TD3_1
Terminated
2021-12-16 02:28:30.592052: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/shandilya/.mujoco/mjpro150/bin
2021-12-16 02:28:30.592085: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
/home/shandilya/Desktop/Projects/NavigationController
Env Type: maze
Task: GoalRewardNoObstacle
Model: <class 'stable_baselines3.td3.td3.TD3'>
Using cpu device
Logging to assets/out/models/exp16/TD3_2
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 228      |
|    ep_rew_mean     | -0.266   |
| time/              |          |
|    episodes        | 4        |
|    fps             | 16       |
|    time_elapsed    | 56       |
|    total timesteps | 911      |
| train/             |          |
|    actor_loss      | 32.6     |
|    critic_loss     | 19.1     |
|    learning_rate   | 0.000999 |
|    n_updates       | 660      |
---------------------------------
Terminated
2021-12-16 02:30:18.982894: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/shandilya/.mujoco/mjpro150/bin
2021-12-16 02:30:18.982936: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
/home/shandilya/Desktop/Projects/NavigationController
Env Type: maze
Task: GoalRewardNoObstacle
Model: <class 'stable_baselines3.td3.td3.TD3'>
Using cpu device
Logging to assets/out/models/exp16/TD3_3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | 3.78     |
| time/              |          |
|    episodes        | 4        |
|    fps             | 22       |
|    time_elapsed    | 45       |
|    total timesteps | 1004     |
| train/             |          |
|    actor_loss      | 6.71     |
|    critic_loss     | 2.77     |
|    learning_rate   | 0.000999 |
|    n_updates       | 502      |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -1.09    |
| time/              |          |
|    episodes        | 8        |
|    fps             | 16       |
|    time_elapsed    | 124      |
|    total timesteps | 2008     |
| train/             |          |
|    actor_loss      | 9.72     |
|    critic_loss     | 2.52     |
|    learning_rate   | 0.000998 |
|    n_updates       | 1506     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -1.25    |
| time/              |          |
|    episodes        | 12       |
|    fps             | 14       |
|    time_elapsed    | 208      |
|    total timesteps | 3012     |
| train/             |          |
|    actor_loss      | 9.91     |
|    critic_loss     | 2.59     |
|    learning_rate   | 0.000997 |
|    n_updates       | 2510     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | 0.0838   |
| time/              |          |
|    episodes        | 16       |
|    fps             | 13       |
|    time_elapsed    | 290      |
|    total timesteps | 4016     |
| train/             |          |
|    actor_loss      | 9.13     |
|    critic_loss     | 1.54     |
|    learning_rate   | 0.000996 |
|    n_updates       | 3514     |
---------------------------------
Eval num_timesteps=5000, episode_reward=0.22 +/- 5.35
Episode length: 251.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 251      |
|    mean_reward     | 0.218    |
| time/              |          |
|    total_timesteps | 5000     |
| train/             |          |
|    actor_loss      | 8.78     |
|    critic_loss     | 1.7      |
|    learning_rate   | 0.000995 |
|    n_updates       | 4518     |
---------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -1.86    |
| time/              |          |
|    episodes        | 20       |
|    fps             | 12       |
|    time_elapsed    | 393      |
|    total timesteps | 5020     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -3.72    |
| time/              |          |
|    episodes        | 24       |
|    fps             | 12       |
|    time_elapsed    | 476      |
|    total timesteps | 6024     |
| train/             |          |
|    actor_loss      | 8.28     |
|    critic_loss     | 1.93     |
|    learning_rate   | 0.000994 |
|    n_updates       | 5522     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -4.26    |
| time/              |          |
|    episodes        | 28       |
|    fps             | 12       |
|    time_elapsed    | 558      |
|    total timesteps | 7028     |
| train/             |          |
|    actor_loss      | 7.91     |
|    critic_loss     | 1.83     |
|    learning_rate   | 0.000993 |
|    n_updates       | 6526     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -4.92    |
| time/              |          |
|    episodes        | 32       |
|    fps             | 12       |
|    time_elapsed    | 641      |
|    total timesteps | 8032     |
| train/             |          |
|    actor_loss      | 7.49     |
|    critic_loss     | 1.07     |
|    learning_rate   | 0.000992 |
|    n_updates       | 7530     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -5.28    |
| time/              |          |
|    episodes        | 36       |
|    fps             | 12       |
|    time_elapsed    | 723      |
|    total timesteps | 9036     |
| train/             |          |
|    actor_loss      | 7.52     |
|    critic_loss     | 1.34     |
|    learning_rate   | 0.000991 |
|    n_updates       | 8534     |
---------------------------------
2021-12-16 02:43:03.390744: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/shandilya/.mujoco/mjpro150/bin
2021-12-16 02:43:03.390780: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
/home/shandilya/Desktop/Projects/NavigationController
Env Type: maze
Task: GoalRewardNoObstacle
Model: <class 'stable_baselines3.td3.td3.TD3'>
Using cpu device
Logging to assets/out/models/exp16/TD3_4
Terminated
Terminated
2021-12-16 02:43:25.703505: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/shandilya/.mujoco/mjpro150/bin
2021-12-16 02:43:25.703556: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
/home/shandilya/Desktop/Projects/NavigationController
Env Type: maze
Task: GoalRewardNoObstacle
Model: <class 'stable_baselines3.td3.td3.TD3'>
Using cpu device
Logging to assets/out/models/exp16/TD3_5
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -10.7    |
| time/              |          |
|    episodes        | 4        |
|    fps             | 22       |
|    time_elapsed    | 45       |
|    total timesteps | 1004     |
| train/             |          |
|    actor_loss      | 14.3     |
|    critic_loss     | 9.65     |
|    learning_rate   | 0.000999 |
|    n_updates       | 502      |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -8.26    |
| time/              |          |
|    episodes        | 8        |
|    fps             | 16       |
|    time_elapsed    | 123      |
|    total timesteps | 2008     |
| train/             |          |
|    actor_loss      | 15.8     |
|    critic_loss     | 5.75     |
|    learning_rate   | 0.000998 |
|    n_updates       | 1506     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -6.51    |
| time/              |          |
|    episodes        | 12       |
|    fps             | 14       |
|    time_elapsed    | 205      |
|    total timesteps | 3012     |
| train/             |          |
|    actor_loss      | 14.5     |
|    critic_loss     | 3.89     |
|    learning_rate   | 0.000997 |
|    n_updates       | 2510     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -3       |
| time/              |          |
|    episodes        | 16       |
|    fps             | 13       |
|    time_elapsed    | 288      |
|    total timesteps | 4016     |
| train/             |          |
|    actor_loss      | 13.9     |
|    critic_loss     | 3.67     |
|    learning_rate   | 0.000996 |
|    n_updates       | 3514     |
---------------------------------
Eval num_timesteps=5000, episode_reward=0.73 +/- 6.33
Episode length: 251.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 251      |
|    mean_reward     | 0.731    |
| time/              |          |
|    total_timesteps | 5000     |
| train/             |          |
|    actor_loss      | 12.9     |
|    critic_loss     | 2.87     |
|    learning_rate   | 0.000995 |
|    n_updates       | 4518     |
---------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -6.1     |
| time/              |          |
|    episodes        | 20       |
|    fps             | 12       |
|    time_elapsed    | 391      |
|    total timesteps | 5020     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -7.24    |
| time/              |          |
|    episodes        | 24       |
|    fps             | 12       |
|    time_elapsed    | 474      |
|    total timesteps | 6024     |
| train/             |          |
|    actor_loss      | 12.4     |
|    critic_loss     | 2.68     |
|    learning_rate   | 0.000994 |
|    n_updates       | 5522     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -6.6     |
| time/              |          |
|    episodes        | 28       |
|    fps             | 12       |
|    time_elapsed    | 556      |
|    total timesteps | 7028     |
| train/             |          |
|    actor_loss      | 11.8     |
|    critic_loss     | 3.31     |
|    learning_rate   | 0.000993 |
|    n_updates       | 6526     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -8.51    |
| time/              |          |
|    episodes        | 32       |
|    fps             | 12       |
|    time_elapsed    | 637      |
|    total timesteps | 8032     |
| train/             |          |
|    actor_loss      | 11.3     |
|    critic_loss     | 2.5      |
|    learning_rate   | 0.000992 |
|    n_updates       | 7530     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -7.45    |
| time/              |          |
|    episodes        | 36       |
|    fps             | 12       |
|    time_elapsed    | 721      |
|    total timesteps | 9036     |
| train/             |          |
|    actor_loss      | 10.8     |
|    critic_loss     | 2.33     |
|    learning_rate   | 0.000991 |
|    n_updates       | 8534     |
---------------------------------
Eval num_timesteps=10000, episode_reward=1.48 +/- 8.27
Episode length: 251.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 251      |
|    mean_reward     | 1.48     |
| time/              |          |
|    total_timesteps | 10000    |
| train/             |          |
|    actor_loss      | 10.4     |
|    critic_loss     | 2.13     |
|    learning_rate   | 0.00099  |
|    n_updates       | 9538     |
---------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -8.62    |
| time/              |          |
|    episodes        | 40       |
|    fps             | 12       |
|    time_elapsed    | 825      |
|    total timesteps | 10040    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -8.42    |
| time/              |          |
|    episodes        | 44       |
|    fps             | 12       |
|    time_elapsed    | 910      |
|    total timesteps | 11044    |
| train/             |          |
|    actor_loss      | 10.2     |
|    critic_loss     | 2.22     |
|    learning_rate   | 0.000989 |
|    n_updates       | 10542    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -8.1     |
| time/              |          |
|    episodes        | 48       |
|    fps             | 12       |
|    time_elapsed    | 994      |
|    total timesteps | 12048    |
| train/             |          |
|    actor_loss      | 9.91     |
|    critic_loss     | 2.58     |
|    learning_rate   | 0.000988 |
|    n_updates       | 11546    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -8.42    |
| time/              |          |
|    episodes        | 52       |
|    fps             | 12       |
|    time_elapsed    | 1078     |
|    total timesteps | 13052    |
| train/             |          |
|    actor_loss      | 9.64     |
|    critic_loss     | 2.49     |
|    learning_rate   | 0.000987 |
|    n_updates       | 12550    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -8.45    |
| time/              |          |
|    episodes        | 56       |
|    fps             | 12       |
|    time_elapsed    | 1161     |
|    total timesteps | 14056    |
| train/             |          |
|    actor_loss      | 9.33     |
|    critic_loss     | 1.85     |
|    learning_rate   | 0.000986 |
|    n_updates       | 13554    |
---------------------------------
Eval num_timesteps=15000, episode_reward=-1.40 +/- 5.10
Episode length: 251.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 251      |
|    mean_reward     | -1.4     |
| time/              |          |
|    total_timesteps | 15000    |
| train/             |          |
|    actor_loss      | 9.15     |
|    critic_loss     | 2.19     |
|    learning_rate   | 0.000985 |
|    n_updates       | 14558    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -8.96    |
| time/              |          |
|    episodes        | 60       |
|    fps             | 11       |
|    time_elapsed    | 1264     |
|    total timesteps | 15060    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -10.2    |
| time/              |          |
|    episodes        | 64       |
|    fps             | 11       |
|    time_elapsed    | 1347     |
|    total timesteps | 16052    |
| train/             |          |
|    actor_loss      | 8.86     |
|    critic_loss     | 2.14     |
|    learning_rate   | 0.000984 |
|    n_updates       | 15550    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -9.53    |
| time/              |          |
|    episodes        | 68       |
|    fps             | 11       |
|    time_elapsed    | 1429     |
|    total timesteps | 17056    |
| train/             |          |
|    actor_loss      | 8.58     |
|    critic_loss     | 1.43     |
|    learning_rate   | 0.000983 |
|    n_updates       | 16554    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -10.8    |
| time/              |          |
|    episodes        | 72       |
|    fps             | 11       |
|    time_elapsed    | 1513     |
|    total timesteps | 18060    |
| train/             |          |
|    actor_loss      | 8.35     |
|    critic_loss     | 2.26     |
|    learning_rate   | 0.000982 |
|    n_updates       | 17558    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -10.8    |
| time/              |          |
|    episodes        | 76       |
|    fps             | 11       |
|    time_elapsed    | 1596     |
|    total timesteps | 19064    |
| train/             |          |
|    actor_loss      | 8.12     |
|    critic_loss     | 1.94     |
|    learning_rate   | 0.000981 |
|    n_updates       | 18562    |
---------------------------------
Eval num_timesteps=20000, episode_reward=2.12 +/- 3.93
Episode length: 251.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 251      |
|    mean_reward     | 2.12     |
| time/              |          |
|    total_timesteps | 20000    |
| train/             |          |
|    actor_loss      | 7.97     |
|    critic_loss     | 2.7      |
|    learning_rate   | 0.00098  |
|    n_updates       | 19566    |
---------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -10.4    |
| time/              |          |
|    episodes        | 80       |
|    fps             | 11       |
|    time_elapsed    | 1700     |
|    total timesteps | 20068    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -10.2    |
| time/              |          |
|    episodes        | 84       |
|    fps             | 11       |
|    time_elapsed    | 1785     |
|    total timesteps | 21072    |
| train/             |          |
|    actor_loss      | 7.8      |
|    critic_loss     | 2.06     |
|    learning_rate   | 0.000979 |
|    n_updates       | 20570    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -10      |
| time/              |          |
|    episodes        | 88       |
|    fps             | 11       |
|    time_elapsed    | 1869     |
|    total timesteps | 22076    |
| train/             |          |
|    actor_loss      | 7.61     |
|    critic_loss     | 1.96     |
|    learning_rate   | 0.000978 |
|    n_updates       | 21574    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -9.54    |
| time/              |          |
|    episodes        | 92       |
|    fps             | 11       |
|    time_elapsed    | 1952     |
|    total timesteps | 23080    |
| train/             |          |
|    actor_loss      | 7.49     |
|    critic_loss     | 2.33     |
|    learning_rate   | 0.000977 |
|    n_updates       | 22578    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -9.45    |
| time/              |          |
|    episodes        | 96       |
|    fps             | 11       |
|    time_elapsed    | 2034     |
|    total timesteps | 24084    |
| train/             |          |
|    actor_loss      | 7.27     |
|    critic_loss     | 1.7      |
|    learning_rate   | 0.000976 |
|    n_updates       | 23582    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -9.22    |
| time/              |          |
|    episodes        | 100      |
|    fps             | 11       |
|    time_elapsed    | 2111     |
|    total timesteps | 24995    |
| train/             |          |
|    actor_loss      | 7.13     |
|    critic_loss     | 1.99     |
|    learning_rate   | 0.000976 |
|    n_updates       | 24493    |
---------------------------------
Eval num_timesteps=25000, episode_reward=-0.83 +/- 4.96
Episode length: 251.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 251      |
|    mean_reward     | -0.833   |
| time/              |          |
|    total_timesteps | 25000    |
| train/             |          |
|    actor_loss      | 7.09     |
|    critic_loss     | 1.8      |
|    learning_rate   | 0.000975 |
|    n_updates       | 24744    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -9.21    |
| time/              |          |
|    episodes        | 104      |
|    fps             | 11       |
|    time_elapsed    | 2215     |
|    total timesteps | 25999    |
| train/             |          |
|    actor_loss      | 6.95     |
|    critic_loss     | 1.92     |
|    learning_rate   | 0.000975 |
|    n_updates       | 25497    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -9.01    |
| time/              |          |
|    episodes        | 108      |
|    fps             | 11       |
|    time_elapsed    | 2300     |
|    total timesteps | 27003    |
| train/             |          |
|    actor_loss      | 6.78     |
|    critic_loss     | 2.15     |
|    learning_rate   | 0.000974 |
|    n_updates       | 26501    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -9.23    |
| time/              |          |
|    episodes        | 112      |
|    fps             | 11       |
|    time_elapsed    | 2383     |
|    total timesteps | 28007    |
| train/             |          |
|    actor_loss      | 6.62     |
|    critic_loss     | 1.62     |
|    learning_rate   | 0.000973 |
|    n_updates       | 27505    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -10.1    |
| time/              |          |
|    episodes        | 116      |
|    fps             | 11       |
|    time_elapsed    | 2468     |
|    total timesteps | 29011    |
| train/             |          |
|    actor_loss      | 6.43     |
|    critic_loss     | 1.88     |
|    learning_rate   | 0.000972 |
|    n_updates       | 28509    |
---------------------------------
Eval num_timesteps=30000, episode_reward=2.58 +/- 5.05
Episode length: 251.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 251      |
|    mean_reward     | 2.58     |
| time/              |          |
|    total_timesteps | 30000    |
| train/             |          |
|    actor_loss      | 6.28     |
|    critic_loss     | 2.03     |
|    learning_rate   | 0.000971 |
|    n_updates       | 29513    |
---------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -9.63    |
| time/              |          |
|    episodes        | 120      |
|    fps             | 11       |
|    time_elapsed    | 2572     |
|    total timesteps | 30015    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -9.06    |
| time/              |          |
|    episodes        | 124      |
|    fps             | 11       |
|    time_elapsed    | 2656     |
|    total timesteps | 31019    |
| train/             |          |
|    actor_loss      | 6.14     |
|    critic_loss     | 1.62     |
|    learning_rate   | 0.00097  |
|    n_updates       | 30517    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -9.85    |
| time/              |          |
|    episodes        | 128      |
|    fps             | 11       |
|    time_elapsed    | 2741     |
|    total timesteps | 32023    |
| train/             |          |
|    actor_loss      | 6        |
|    critic_loss     | 1.6      |
|    learning_rate   | 0.000969 |
|    n_updates       | 31521    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -9.11    |
| time/              |          |
|    episodes        | 132      |
|    fps             | 11       |
|    time_elapsed    | 2826     |
|    total timesteps | 33027    |
| train/             |          |
|    actor_loss      | 5.87     |
|    critic_loss     | 1.76     |
|    learning_rate   | 0.000968 |
|    n_updates       | 32525    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -8.99    |
| time/              |          |
|    episodes        | 136      |
|    fps             | 11       |
|    time_elapsed    | 2911     |
|    total timesteps | 34031    |
| train/             |          |
|    actor_loss      | 5.73     |
|    critic_loss     | 1.78     |
|    learning_rate   | 0.000967 |
|    n_updates       | 33529    |
---------------------------------
Eval num_timesteps=35000, episode_reward=3.10 +/- 4.48
Episode length: 251.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 251      |
|    mean_reward     | 3.1      |
| time/              |          |
|    total_timesteps | 35000    |
| train/             |          |
|    actor_loss      | 5.61     |
|    critic_loss     | 1.78     |
|    learning_rate   | 0.000966 |
|    n_updates       | 34533    |
---------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -8.27    |
| time/              |          |
|    episodes        | 140      |
|    fps             | 11       |
|    time_elapsed    | 3016     |
|    total timesteps | 35035    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -9.41    |
| time/              |          |
|    episodes        | 144      |
|    fps             | 11       |
|    time_elapsed    | 3100     |
|    total timesteps | 36039    |
| train/             |          |
|    actor_loss      | 5.49     |
|    critic_loss     | 1.73     |
|    learning_rate   | 0.000965 |
|    n_updates       | 35537    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -9.09    |
| time/              |          |
|    episodes        | 148      |
|    fps             | 11       |
|    time_elapsed    | 3185     |
|    total timesteps | 37043    |
| train/             |          |
|    actor_loss      | 5.38     |
|    critic_loss     | 1.47     |
|    learning_rate   | 0.000964 |
|    n_updates       | 36541    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -8.95    |
| time/              |          |
|    episodes        | 152      |
|    fps             | 11       |
|    time_elapsed    | 3269     |
|    total timesteps | 38047    |
| train/             |          |
|    actor_loss      | 5.28     |
|    critic_loss     | 1.73     |
|    learning_rate   | 0.000963 |
|    n_updates       | 37545    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -8.91    |
| time/              |          |
|    episodes        | 156      |
|    fps             | 11       |
|    time_elapsed    | 3353     |
|    total timesteps | 39051    |
| train/             |          |
|    actor_loss      | 5.17     |
|    critic_loss     | 1.52     |
|    learning_rate   | 0.000962 |
|    n_updates       | 38549    |
---------------------------------
Eval num_timesteps=40000, episode_reward=3.57 +/- 4.21
Episode length: 251.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 251      |
|    mean_reward     | 3.57     |
| time/              |          |
|    total_timesteps | 40000    |
| train/             |          |
|    actor_loss      | 5.05     |
|    critic_loss     | 1.24     |
|    learning_rate   | 0.000961 |
|    n_updates       | 39553    |
---------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -8.22    |
| time/              |          |
|    episodes        | 160      |
|    fps             | 11       |
|    time_elapsed    | 3457     |
|    total timesteps | 40055    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -7.44    |
| time/              |          |
|    episodes        | 164      |
|    fps             | 11       |
|    time_elapsed    | 3541     |
|    total timesteps | 41059    |
| train/             |          |
|    actor_loss      | 4.96     |
|    critic_loss     | 1.33     |
|    learning_rate   | 0.00096  |
|    n_updates       | 40557    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -7.14    |
| time/              |          |
|    episodes        | 168      |
|    fps             | 11       |
|    time_elapsed    | 3624     |
|    total timesteps | 42063    |
| train/             |          |
|    actor_loss      | 4.87     |
|    critic_loss     | 2.18     |
|    learning_rate   | 0.000959 |
|    n_updates       | 41561    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -6.34    |
| time/              |          |
|    episodes        | 172      |
|    fps             | 11       |
|    time_elapsed    | 3711     |
|    total timesteps | 43067    |
| train/             |          |
|    actor_loss      | 4.72     |
|    critic_loss     | 1.37     |
|    learning_rate   | 0.000958 |
|    n_updates       | 42565    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -5.92    |
| time/              |          |
|    episodes        | 176      |
|    fps             | 11       |
|    time_elapsed    | 3795     |
|    total timesteps | 44071    |
| train/             |          |
|    actor_loss      | 4.63     |
|    critic_loss     | 1.8      |
|    learning_rate   | 0.000957 |
|    n_updates       | 43569    |
---------------------------------
Eval num_timesteps=45000, episode_reward=3.09 +/- 5.70
Episode length: 251.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 251      |
|    mean_reward     | 3.09     |
| time/              |          |
|    total_timesteps | 45000    |
| train/             |          |
|    actor_loss      | 4.54     |
|    critic_loss     | 1.38     |
|    learning_rate   | 0.000956 |
|    n_updates       | 44573    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -5.78    |
| time/              |          |
|    episodes        | 180      |
|    fps             | 11       |
|    time_elapsed    | 3899     |
|    total timesteps | 45075    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -5.89    |
| time/              |          |
|    episodes        | 184      |
|    fps             | 11       |
|    time_elapsed    | 3985     |
|    total timesteps | 46079    |
| train/             |          |
|    actor_loss      | 4.44     |
|    critic_loss     | 1.41     |
|    learning_rate   | 0.000955 |
|    n_updates       | 45577    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -6.74    |
| time/              |          |
|    episodes        | 188      |
|    fps             | 11       |
|    time_elapsed    | 4069     |
|    total timesteps | 47083    |
| train/             |          |
|    actor_loss      | 4.35     |
|    critic_loss     | 1.56     |
|    learning_rate   | 0.000954 |
|    n_updates       | 46581    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -6.96    |
| time/              |          |
|    episodes        | 192      |
|    fps             | 11       |
|    time_elapsed    | 4155     |
|    total timesteps | 48087    |
| train/             |          |
|    actor_loss      | 4.26     |
|    critic_loss     | 1.14     |
|    learning_rate   | 0.000953 |
|    n_updates       | 47585    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -6.56    |
| time/              |          |
|    episodes        | 196      |
|    fps             | 11       |
|    time_elapsed    | 4239     |
|    total timesteps | 49091    |
| train/             |          |
|    actor_loss      | 4.19     |
|    critic_loss     | 1.4      |
|    learning_rate   | 0.000952 |
|    n_updates       | 48589    |
---------------------------------
Eval num_timesteps=50000, episode_reward=-9.85 +/- 8.56
Episode length: 251.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 251      |
|    mean_reward     | -9.85    |
| time/              |          |
|    total_timesteps | 50000    |
| train/             |          |
|    actor_loss      | 4.11     |
|    critic_loss     | 1.43     |
|    learning_rate   | 0.000951 |
|    n_updates       | 49593    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -6.69    |
| time/              |          |
|    episodes        | 200      |
|    fps             | 11       |
|    time_elapsed    | 4345     |
|    total timesteps | 50095    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -6.77    |
| time/              |          |
|    episodes        | 204      |
|    fps             | 11       |
|    time_elapsed    | 4429     |
|    total timesteps | 51099    |
| train/             |          |
|    actor_loss      | 4.03     |
|    critic_loss     | 1.35     |
|    learning_rate   | 0.00095  |
|    n_updates       | 50597    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -7.13    |
| time/              |          |
|    episodes        | 208      |
|    fps             | 11       |
|    time_elapsed    | 4514     |
|    total timesteps | 52103    |
| train/             |          |
|    actor_loss      | 3.98     |
|    critic_loss     | 1.71     |
|    learning_rate   | 0.000949 |
|    n_updates       | 51601    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -7.2     |
| time/              |          |
|    episodes        | 212      |
|    fps             | 11       |
|    time_elapsed    | 4600     |
|    total timesteps | 53107    |
| train/             |          |
|    actor_loss      | 3.9      |
|    critic_loss     | 1.47     |
|    learning_rate   | 0.000948 |
|    n_updates       | 52605    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -7.95    |
| time/              |          |
|    episodes        | 216      |
|    fps             | 11       |
|    time_elapsed    | 4685     |
|    total timesteps | 54111    |
| train/             |          |
|    actor_loss      | 3.86     |
|    critic_loss     | 1.64     |
|    learning_rate   | 0.000947 |
|    n_updates       | 53609    |
---------------------------------
Terminated
/home/shandilya/Desktop/Projects/NavigationController
Env Type: maze
Task: GoalRewardSimple
Traceback (most recent call last):
  File "train.py", line 80, in <module>
    lmbda = args.lmbda
  File "/home/shandilya/Desktop/Projects/NavigationController/learning/explore.py", line 71, in __init__
    lambda : sb3.common.monitor.Monitor(env_class(
  File "/home/shandilya/py36/lib/python3.6/site-packages/stable_baselines3/common/vec_env/dummy_vec_env.py", line 25, in __init__
    self.envs = [fn() for fn in env_fns]
  File "/home/shandilya/py36/lib/python3.6/site-packages/stable_baselines3/common/vec_env/dummy_vec_env.py", line 25, in <listcomp>
    self.envs = [fn() for fn in env_fns]
  File "/home/shandilya/Desktop/Projects/NavigationController/learning/explore.py", line 76, in <lambda>
    history_steps
  File "/home/shandilya/Desktop/Projects/NavigationController/simulations/maze_env.py", line 117, in __init__
    self.set_env()
  File "/home/shandilya/Desktop/Projects/NavigationController/simulations/maze_env.py", line 244, in set_env
    self.sampled_path = self.__sample_path()
  File "/home/shandilya/Desktop/Projects/NavigationController/simulations/maze_env.py", line 311, in __sample_path
    target
  File "/home/shandilya/py36/lib/python3.6/site-packages/networkx/algorithms/shortest_paths/generic.py", line 526, in _build_paths_from_predecessors
    f"Target {target} cannot be reached" f"from given sources"
networkx.exception.NetworkXNoPath: Target 6 cannot be reachedfrom given sources
2021-12-16 04:03:58.463961: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/shandilya/.mujoco/mjpro150/bin
2021-12-16 04:03:58.463996: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
/home/shandilya/Desktop/Projects/NavigationController
Env Type: maze
Task: GoalRewardNoObstacle
Model: <class 'stable_baselines3.td3.td3.TD3'>
Using cpu device
Logging to assets/out/models/exp16/TD3_6
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 170      |
|    ep_rew_mean     | 9.25     |
| time/              |          |
|    episodes        | 4        |
|    fps             | 62       |
|    time_elapsed    | 10       |
|    total timesteps | 682      |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 211      |
|    ep_rew_mean     | 1.43     |
| time/              |          |
|    episodes        | 8        |
|    fps             | 19       |
|    time_elapsed    | 87       |
|    total timesteps | 1686     |
| train/             |          |
|    actor_loss      | 9.42     |
|    critic_loss     | 3.6      |
|    learning_rate   | 0.000999 |
|    n_updates       | 1004     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 224      |
|    ep_rew_mean     | 3.22     |
| time/              |          |
|    episodes        | 12       |
|    fps             | 15       |
|    time_elapsed    | 169      |
|    total timesteps | 2690     |
| train/             |          |
|    actor_loss      | 8.93     |
|    critic_loss     | 2.52     |
|    learning_rate   | 0.000998 |
|    n_updates       | 2008     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 231      |
|    ep_rew_mean     | 1.41     |
| time/              |          |
|    episodes        | 16       |
|    fps             | 14       |
|    time_elapsed    | 252      |
|    total timesteps | 3694     |
| train/             |          |
|    actor_loss      | 8.28     |
|    critic_loss     | 2.6      |
|    learning_rate   | 0.000997 |
|    n_updates       | 3012     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 235      |
|    ep_rew_mean     | 2.14     |
| time/              |          |
|    episodes        | 20       |
|    fps             | 14       |
|    time_elapsed    | 334      |
|    total timesteps | 4698     |
| train/             |          |
|    actor_loss      | 8.23     |
|    critic_loss     | 2        |
|    learning_rate   | 0.000996 |
|    n_updates       | 4016     |
---------------------------------
Eval num_timesteps=5000, episode_reward=1.60 +/- 9.39
Episode length: 251.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 251      |
|    mean_reward     | 1.6      |
| time/              |          |
|    total_timesteps | 5000     |
| train/             |          |
|    actor_loss      | 8.11     |
|    critic_loss     | 1.91     |
|    learning_rate   | 0.000995 |
|    n_updates       | 4518     |
---------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 238      |
|    ep_rew_mean     | -0.497   |
| time/              |          |
|    episodes        | 24       |
|    fps             | 13       |
|    time_elapsed    | 437      |
|    total timesteps | 5702     |
| train/             |          |
|    actor_loss      | 7.88     |
|    critic_loss     | 1.93     |
|    learning_rate   | 0.000995 |
|    n_updates       | 5020     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 234      |
|    ep_rew_mean     | 1.1      |
| time/              |          |
|    episodes        | 28       |
|    fps             | 12       |
|    time_elapsed    | 507      |
|    total timesteps | 6553     |
| train/             |          |
|    actor_loss      | 7.43     |
|    critic_loss     | 1.36     |
|    learning_rate   | 0.000994 |
|    n_updates       | 5871     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 236      |
|    ep_rew_mean     | -0.93    |
| time/              |          |
|    episodes        | 32       |
|    fps             | 12       |
|    time_elapsed    | 590      |
|    total timesteps | 7557     |
| train/             |          |
|    actor_loss      | 6.87     |
|    critic_loss     | 1.56     |
|    learning_rate   | 0.000993 |
|    n_updates       | 6875     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 238      |
|    ep_rew_mean     | -3.24    |
| time/              |          |
|    episodes        | 36       |
|    fps             | 12       |
|    time_elapsed    | 671      |
|    total timesteps | 8561     |
| train/             |          |
|    actor_loss      | 6.62     |
|    critic_loss     | 1.56     |
|    learning_rate   | 0.000992 |
|    n_updates       | 7879     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 239      |
|    ep_rew_mean     | -2.19    |
| time/              |          |
|    episodes        | 40       |
|    fps             | 12       |
|    time_elapsed    | 753      |
|    total timesteps | 9565     |
| train/             |          |
|    actor_loss      | 6.37     |
|    critic_loss     | 1.57     |
|    learning_rate   | 0.000991 |
|    n_updates       | 8883     |
---------------------------------
Eval num_timesteps=10000, episode_reward=0.80 +/- 8.85
Episode length: 251.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 251      |
|    mean_reward     | 0.801    |
| time/              |          |
|    total_timesteps | 10000    |
| train/             |          |
|    actor_loss      | 6.27     |
|    critic_loss     | 1.94     |
|    learning_rate   | 0.00099  |
|    n_updates       | 9385     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 240      |
|    ep_rew_mean     | -1.88    |
| time/              |          |
|    episodes        | 44       |
|    fps             | 12       |
|    time_elapsed    | 856      |
|    total timesteps | 10569    |
| train/             |          |
|    actor_loss      | 6.16     |
|    critic_loss     | 1.81     |
|    learning_rate   | 0.00099  |
|    n_updates       | 9887     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 241      |
|    ep_rew_mean     | -0.816   |
| time/              |          |
|    episodes        | 48       |
|    fps             | 12       |
|    time_elapsed    | 939      |
|    total timesteps | 11573    |
| train/             |          |
|    actor_loss      | 5.93     |
|    critic_loss     | 0.86     |
|    learning_rate   | 0.000989 |
|    n_updates       | 10891    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 242      |
|    ep_rew_mean     | -1.73    |
| time/              |          |
|    episodes        | 52       |
|    fps             | 12       |
|    time_elapsed    | 1021     |
|    total timesteps | 12577    |
| train/             |          |
|    actor_loss      | 5.73     |
|    critic_loss     | 1.47     |
|    learning_rate   | 0.000988 |
|    n_updates       | 11895    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 243      |
|    ep_rew_mean     | -1.16    |
| time/              |          |
|    episodes        | 56       |
|    fps             | 12       |
|    time_elapsed    | 1103     |
|    total timesteps | 13581    |
| train/             |          |
|    actor_loss      | 5.55     |
|    critic_loss     | 1.32     |
|    learning_rate   | 0.000987 |
|    n_updates       | 12899    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 243      |
|    ep_rew_mean     | -0.706   |
| time/              |          |
|    episodes        | 60       |
|    fps             | 12       |
|    time_elapsed    | 1186     |
|    total timesteps | 14585    |
| train/             |          |
|    actor_loss      | 5.38     |
|    critic_loss     | 1.44     |
|    learning_rate   | 0.000986 |
|    n_updates       | 13903    |
---------------------------------
Eval num_timesteps=15000, episode_reward=-0.29 +/- 7.79
Episode length: 251.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 251      |
|    mean_reward     | -0.294   |
| time/              |          |
|    total_timesteps | 15000    |
| train/             |          |
|    actor_loss      | 5.29     |
|    critic_loss     | 1.29     |
|    learning_rate   | 0.000985 |
|    n_updates       | 14405    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 244      |
|    ep_rew_mean     | -1.92    |
| time/              |          |
|    episodes        | 64       |
|    fps             | 12       |
|    time_elapsed    | 1289     |
|    total timesteps | 15589    |
| train/             |          |
|    actor_loss      | 5.17     |
|    critic_loss     | 1.22     |
|    learning_rate   | 0.000985 |
|    n_updates       | 14907    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 244      |
|    ep_rew_mean     | -1.61    |
| time/              |          |
|    episodes        | 68       |
|    fps             | 12       |
|    time_elapsed    | 1372     |
|    total timesteps | 16593    |
| train/             |          |
|    actor_loss      | 5.23     |
|    critic_loss     | 1.47     |
|    learning_rate   | 0.000984 |
|    n_updates       | 15911    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 244      |
|    ep_rew_mean     | -2.59    |
| time/              |          |
|    episodes        | 72       |
|    fps             | 12       |
|    time_elapsed    | 1454     |
|    total timesteps | 17597    |
| train/             |          |
|    actor_loss      | 5.08     |
|    critic_loss     | 1.2      |
|    learning_rate   | 0.000983 |
|    n_updates       | 16915    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 245      |
|    ep_rew_mean     | -2.93    |
| time/              |          |
|    episodes        | 76       |
|    fps             | 12       |
|    time_elapsed    | 1537     |
|    total timesteps | 18601    |
| train/             |          |
|    actor_loss      | 4.93     |
|    critic_loss     | 1.42     |
|    learning_rate   | 0.000982 |
|    n_updates       | 17919    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 245      |
|    ep_rew_mean     | -3.02    |
| time/              |          |
|    episodes        | 80       |
|    fps             | 12       |
|    time_elapsed    | 1619     |
|    total timesteps | 19605    |
| train/             |          |
|    actor_loss      | 4.77     |
|    critic_loss     | 1.29     |
|    learning_rate   | 0.000981 |
|    n_updates       | 18923    |
---------------------------------
Eval num_timesteps=20000, episode_reward=7.04 +/- 0.60
Episode length: 251.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 251      |
|    mean_reward     | 7.04     |
| time/              |          |
|    total_timesteps | 20000    |
| train/             |          |
|    actor_loss      | 4.73     |
|    critic_loss     | 1.53     |
|    learning_rate   | 0.00098  |
|    n_updates       | 19425    |
---------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 245      |
|    ep_rew_mean     | -3.24    |
| time/              |          |
|    episodes        | 84       |
|    fps             | 11       |
|    time_elapsed    | 1723     |
|    total timesteps | 20609    |
| train/             |          |
|    actor_loss      | 4.69     |
|    critic_loss     | 1.63     |
|    learning_rate   | 0.00098  |
|    n_updates       | 19927    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 246      |
|    ep_rew_mean     | -3.52    |
| time/              |          |
|    episodes        | 88       |
|    fps             | 11       |
|    time_elapsed    | 1805     |
|    total timesteps | 21613    |
| train/             |          |
|    actor_loss      | 4.6      |
|    critic_loss     | 1.65     |
|    learning_rate   | 0.000979 |
|    n_updates       | 20931    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 246      |
|    ep_rew_mean     | -4.35    |
| time/              |          |
|    episodes        | 92       |
|    fps             | 11       |
|    time_elapsed    | 1889     |
|    total timesteps | 22617    |
| train/             |          |
|    actor_loss      | 4.47     |
|    critic_loss     | 1.22     |
|    learning_rate   | 0.000978 |
|    n_updates       | 21935    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 246      |
|    ep_rew_mean     | -4.39    |
| time/              |          |
|    episodes        | 96       |
|    fps             | 11       |
|    time_elapsed    | 1972     |
|    total timesteps | 23621    |
| train/             |          |
|    actor_loss      | 4.43     |
|    critic_loss     | 1.89     |
|    learning_rate   | 0.000977 |
|    n_updates       | 22939    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 246      |
|    ep_rew_mean     | -4.41    |
| time/              |          |
|    episodes        | 100      |
|    fps             | 11       |
|    time_elapsed    | 2055     |
|    total timesteps | 24625    |
| train/             |          |
|    actor_loss      | 4.31     |
|    critic_loss     | 1.25     |
|    learning_rate   | 0.000976 |
|    n_updates       | 23943    |
---------------------------------
Eval num_timesteps=25000, episode_reward=7.27 +/- 2.21
Episode length: 251.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 251      |
|    mean_reward     | 7.27     |
| time/              |          |
|    total_timesteps | 25000    |
| train/             |          |
|    actor_loss      | 4.26     |
|    critic_loss     | 1.37     |
|    learning_rate   | 0.000975 |
|    n_updates       | 24414    |
---------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -5.27    |
| time/              |          |
|    episodes        | 104      |
|    fps             | 11       |
|    time_elapsed    | 2156     |
|    total timesteps | 25598    |
| train/             |          |
|    actor_loss      | 4.22     |
|    critic_loss     | 1.73     |
|    learning_rate   | 0.000975 |
|    n_updates       | 24916    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -5.58    |
| time/              |          |
|    episodes        | 108      |
|    fps             | 11       |
|    time_elapsed    | 2239     |
|    total timesteps | 26602    |
| train/             |          |
|    actor_loss      | 4.12     |
|    critic_loss     | 1.39     |
|    learning_rate   | 0.000974 |
|    n_updates       | 25920    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -5.84    |
| time/              |          |
|    episodes        | 112      |
|    fps             | 11       |
|    time_elapsed    | 2323     |
|    total timesteps | 27606    |
| train/             |          |
|    actor_loss      | 4.04     |
|    critic_loss     | 1.68     |
|    learning_rate   | 0.000973 |
|    n_updates       | 26924    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -6.51    |
| time/              |          |
|    episodes        | 116      |
|    fps             | 11       |
|    time_elapsed    | 2407     |
|    total timesteps | 28610    |
| train/             |          |
|    actor_loss      | 3.92     |
|    critic_loss     | 1.41     |
|    learning_rate   | 0.000972 |
|    n_updates       | 27928    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -7.71    |
| time/              |          |
|    episodes        | 120      |
|    fps             | 11       |
|    time_elapsed    | 2490     |
|    total timesteps | 29614    |
| train/             |          |
|    actor_loss      | 3.85     |
|    critic_loss     | 1.69     |
|    learning_rate   | 0.000971 |
|    n_updates       | 28932    |
---------------------------------
Eval num_timesteps=30000, episode_reward=4.31 +/- 5.15
Episode length: 251.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 251      |
|    mean_reward     | 4.31     |
| time/              |          |
|    total_timesteps | 30000    |
| train/             |          |
|    actor_loss      | 3.81     |
|    critic_loss     | 1.34     |
|    learning_rate   | 0.00097  |
|    n_updates       | 29434    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -7.07    |
| time/              |          |
|    episodes        | 124      |
|    fps             | 11       |
|    time_elapsed    | 2593     |
|    total timesteps | 30618    |
| train/             |          |
|    actor_loss      | 3.77     |
|    critic_loss     | 1.32     |
|    learning_rate   | 0.00097  |
|    n_updates       | 29936    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -7.85    |
| time/              |          |
|    episodes        | 128      |
|    fps             | 11       |
|    time_elapsed    | 2677     |
|    total timesteps | 31622    |
| train/             |          |
|    actor_loss      | 3.75     |
|    critic_loss     | 2.13     |
|    learning_rate   | 0.000969 |
|    n_updates       | 30940    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -7.29    |
| time/              |          |
|    episodes        | 132      |
|    fps             | 11       |
|    time_elapsed    | 2760     |
|    total timesteps | 32626    |
| train/             |          |
|    actor_loss      | 3.64     |
|    critic_loss     | 0.955    |
|    learning_rate   | 0.000968 |
|    n_updates       | 31944    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -6.99    |
| time/              |          |
|    episodes        | 136      |
|    fps             | 11       |
|    time_elapsed    | 2844     |
|    total timesteps | 33630    |
| train/             |          |
|    actor_loss      | 3.61     |
|    critic_loss     | 1.84     |
|    learning_rate   | 0.000967 |
|    n_updates       | 32948    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -7.59    |
| time/              |          |
|    episodes        | 140      |
|    fps             | 11       |
|    time_elapsed    | 2927     |
|    total timesteps | 34634    |
| train/             |          |
|    actor_loss      | 3.56     |
|    critic_loss     | 1.43     |
|    learning_rate   | 0.000966 |
|    n_updates       | 33952    |
---------------------------------
Eval num_timesteps=35000, episode_reward=2.76 +/- 2.99
Episode length: 251.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 251      |
|    mean_reward     | 2.76     |
| time/              |          |
|    total_timesteps | 35000    |
| train/             |          |
|    actor_loss      | 3.53     |
|    critic_loss     | 1.46     |
|    learning_rate   | 0.000965 |
|    n_updates       | 34454    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -8.08    |
| time/              |          |
|    episodes        | 144      |
|    fps             | 11       |
|    time_elapsed    | 3031     |
|    total timesteps | 35638    |
| train/             |          |
|    actor_loss      | 3.51     |
|    critic_loss     | 1.68     |
|    learning_rate   | 0.000965 |
|    n_updates       | 34956    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -8.78    |
| time/              |          |
|    episodes        | 148      |
|    fps             | 11       |
|    time_elapsed    | 3115     |
|    total timesteps | 36642    |
| train/             |          |
|    actor_loss      | 3.44     |
|    critic_loss     | 1.34     |
|    learning_rate   | 0.000964 |
|    n_updates       | 35960    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -8.34    |
| time/              |          |
|    episodes        | 152      |
|    fps             | 11       |
|    time_elapsed    | 3200     |
|    total timesteps | 37646    |
| train/             |          |
|    actor_loss      | 3.39     |
|    critic_loss     | 1.37     |
|    learning_rate   | 0.000963 |
|    n_updates       | 36964    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -8.26    |
| time/              |          |
|    episodes        | 156      |
|    fps             | 11       |
|    time_elapsed    | 3284     |
|    total timesteps | 38650    |
| train/             |          |
|    actor_loss      | 3.37     |
|    critic_loss     | 1.18     |
|    learning_rate   | 0.000962 |
|    n_updates       | 37968    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -9.6     |
| time/              |          |
|    episodes        | 160      |
|    fps             | 11       |
|    time_elapsed    | 3369     |
|    total timesteps | 39654    |
| train/             |          |
|    actor_loss      | 3.4      |
|    critic_loss     | 1.45     |
|    learning_rate   | 0.000961 |
|    n_updates       | 38972    |
---------------------------------
Eval num_timesteps=40000, episode_reward=2.12 +/- 3.32
Episode length: 251.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 251      |
|    mean_reward     | 2.12     |
| time/              |          |
|    total_timesteps | 40000    |
| train/             |          |
|    actor_loss      | 3.43     |
|    critic_loss     | 1.28     |
|    learning_rate   | 0.00096  |
|    n_updates       | 39474    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -9.58    |
| time/              |          |
|    episodes        | 164      |
|    fps             | 11       |
|    time_elapsed    | 3473     |
|    total timesteps | 40658    |
| train/             |          |
|    actor_loss      | 3.45     |
|    critic_loss     | 1.49     |
|    learning_rate   | 0.00096  |
|    n_updates       | 39976    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -9.52    |
| time/              |          |
|    episodes        | 168      |
|    fps             | 11       |
|    time_elapsed    | 3558     |
|    total timesteps | 41662    |
| train/             |          |
|    actor_loss      | 3.62     |
|    critic_loss     | 1.55     |
|    learning_rate   | 0.000959 |
|    n_updates       | 40980    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -8.44    |
| time/              |          |
|    episodes        | 172      |
|    fps             | 11       |
|    time_elapsed    | 3642     |
|    total timesteps | 42666    |
| train/             |          |
|    actor_loss      | 3.54     |
|    critic_loss     | 1.21     |
|    learning_rate   | 0.000958 |
|    n_updates       | 41984    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -7.74    |
| time/              |          |
|    episodes        | 176      |
|    fps             | 11       |
|    time_elapsed    | 3726     |
|    total timesteps | 43670    |
| train/             |          |
|    actor_loss      | 3.5      |
|    critic_loss     | 1.47     |
|    learning_rate   | 0.000957 |
|    n_updates       | 42988    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -8.34    |
| time/              |          |
|    episodes        | 180      |
|    fps             | 11       |
|    time_elapsed    | 3812     |
|    total timesteps | 44674    |
| train/             |          |
|    actor_loss      | 3.42     |
|    critic_loss     | 1.17     |
|    learning_rate   | 0.000956 |
|    n_updates       | 43992    |
---------------------------------
Eval num_timesteps=45000, episode_reward=4.30 +/- 3.82
Episode length: 251.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 251      |
|    mean_reward     | 4.3      |
| time/              |          |
|    total_timesteps | 45000    |
| train/             |          |
|    actor_loss      | 3.4      |
|    critic_loss     | 1.28     |
|    learning_rate   | 0.000956 |
|    n_updates       | 44494    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -8.42    |
| time/              |          |
|    episodes        | 184      |
|    fps             | 11       |
|    time_elapsed    | 3917     |
|    total timesteps | 45678    |
| train/             |          |
|    actor_loss      | 3.38     |
|    critic_loss     | 1.41     |
|    learning_rate   | 0.000955 |
|    n_updates       | 44996    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -9.66    |
| time/              |          |
|    episodes        | 188      |
|    fps             | 11       |
|    time_elapsed    | 4002     |
|    total timesteps | 46682    |
| train/             |          |
|    actor_loss      | 3.32     |
|    critic_loss     | 1.23     |
|    learning_rate   | 0.000954 |
|    n_updates       | 46000    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -8.59    |
| time/              |          |
|    episodes        | 192      |
|    fps             | 11       |
|    time_elapsed    | 4087     |
|    total timesteps | 47686    |
| train/             |          |
|    actor_loss      | 3.29     |
|    critic_loss     | 1.78     |
|    learning_rate   | 0.000953 |
|    n_updates       | 47004    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -8.69    |
| time/              |          |
|    episodes        | 196      |
|    fps             | 11       |
|    time_elapsed    | 4173     |
|    total timesteps | 48690    |
| train/             |          |
|    actor_loss      | 3.25     |
|    critic_loss     | 1.42     |
|    learning_rate   | 0.000952 |
|    n_updates       | 48008    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -8.19    |
| time/              |          |
|    episodes        | 200      |
|    fps             | 11       |
|    time_elapsed    | 4252     |
|    total timesteps | 49612    |
| train/             |          |
|    actor_loss      | 3.22     |
|    critic_loss     | 1.56     |
|    learning_rate   | 0.000951 |
|    n_updates       | 48930    |
---------------------------------
Eval num_timesteps=50000, episode_reward=3.42 +/- 4.45
Episode length: 251.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 251      |
|    mean_reward     | 3.42     |
| time/              |          |
|    total_timesteps | 50000    |
| train/             |          |
|    actor_loss      | 3.17     |
|    critic_loss     | 1.24     |
|    learning_rate   | 0.000951 |
|    n_updates       | 49413    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -8.05    |
| time/              |          |
|    episodes        | 204      |
|    fps             | 11       |
|    time_elapsed    | 4356     |
|    total timesteps | 50597    |
| train/             |          |
|    actor_loss      | 3.15     |
|    critic_loss     | 1.28     |
|    learning_rate   | 0.00095  |
|    n_updates       | 49915    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -7.96    |
| time/              |          |
|    episodes        | 208      |
|    fps             | 11       |
|    time_elapsed    | 4443     |
|    total timesteps | 51601    |
| train/             |          |
|    actor_loss      | 3.09     |
|    critic_loss     | 1.21     |
|    learning_rate   | 0.000949 |
|    n_updates       | 50919    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -8.38    |
| time/              |          |
|    episodes        | 212      |
|    fps             | 11       |
|    time_elapsed    | 4529     |
|    total timesteps | 52605    |
| train/             |          |
|    actor_loss      | 3.05     |
|    critic_loss     | 1.6      |
|    learning_rate   | 0.000948 |
|    n_updates       | 51923    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -7.34    |
| time/              |          |
|    episodes        | 216      |
|    fps             | 11       |
|    time_elapsed    | 4614     |
|    total timesteps | 53609    |
| train/             |          |
|    actor_loss      | 3.03     |
|    critic_loss     | 1.71     |
|    learning_rate   | 0.000947 |
|    n_updates       | 52927    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -7.32    |
| time/              |          |
|    episodes        | 220      |
|    fps             | 11       |
|    time_elapsed    | 4700     |
|    total timesteps | 54613    |
| train/             |          |
|    actor_loss      | 2.97     |
|    critic_loss     | 1.33     |
|    learning_rate   | 0.000946 |
|    n_updates       | 53931    |
---------------------------------
Eval num_timesteps=55000, episode_reward=7.66 +/- 1.58
Episode length: 251.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 251      |
|    mean_reward     | 7.66     |
| time/              |          |
|    total_timesteps | 55000    |
| train/             |          |
|    actor_loss      | 2.96     |
|    critic_loss     | 1.38     |
|    learning_rate   | 0.000946 |
|    n_updates       | 54433    |
---------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -7.63    |
| time/              |          |
|    episodes        | 224      |
|    fps             | 11       |
|    time_elapsed    | 4806     |
|    total timesteps | 55617    |
| train/             |          |
|    actor_loss      | 2.92     |
|    critic_loss     | 1.38     |
|    learning_rate   | 0.000945 |
|    n_updates       | 54935    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 248      |
|    ep_rew_mean     | -6.6     |
| time/              |          |
|    episodes        | 228      |
|    fps             | 11       |
|    time_elapsed    | 4880     |
|    total timesteps | 56468    |
| train/             |          |
|    actor_loss      | 2.88     |
|    critic_loss     | 1.34     |
|    learning_rate   | 0.000944 |
|    n_updates       | 55786    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 248      |
|    ep_rew_mean     | -6.36    |
| time/              |          |
|    episodes        | 232      |
|    fps             | 11       |
|    time_elapsed    | 4968     |
|    total timesteps | 57472    |
| train/             |          |
|    actor_loss      | 2.89     |
|    critic_loss     | 1.69     |
|    learning_rate   | 0.000943 |
|    n_updates       | 56790    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 248      |
|    ep_rew_mean     | -6.2     |
| time/              |          |
|    episodes        | 236      |
|    fps             | 11       |
|    time_elapsed    | 5056     |
|    total timesteps | 58476    |
| train/             |          |
|    actor_loss      | 2.81     |
|    critic_loss     | 0.876    |
|    learning_rate   | 0.000942 |
|    n_updates       | 57794    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 248      |
|    ep_rew_mean     | -5.85    |
| time/              |          |
|    episodes        | 240      |
|    fps             | 11       |
|    time_elapsed    | 5144     |
|    total timesteps | 59480    |
| train/             |          |
|    actor_loss      | 2.78     |
|    critic_loss     | 1.34     |
|    learning_rate   | 0.000941 |
|    n_updates       | 58798    |
---------------------------------
Eval num_timesteps=60000, episode_reward=-0.23 +/- 5.86
Episode length: 251.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 251      |
|    mean_reward     | -0.226   |
| time/              |          |
|    total_timesteps | 60000    |
| train/             |          |
|    actor_loss      | 2.72     |
|    critic_loss     | 0.993    |
|    learning_rate   | 0.000941 |
|    n_updates       | 59551    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 248      |
|    ep_rew_mean     | -5.76    |
| time/              |          |
|    episodes        | 244      |
|    fps             | 11       |
|    time_elapsed    | 5251     |
|    total timesteps | 60484    |
| train/             |          |
|    actor_loss      | 2.74     |
|    critic_loss     | 1.26     |
|    learning_rate   | 0.00094  |
|    n_updates       | 59802    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 248      |
|    ep_rew_mean     | -5.74    |
| time/              |          |
|    episodes        | 248      |
|    fps             | 11       |
|    time_elapsed    | 5340     |
|    total timesteps | 61488    |
| train/             |          |
|    actor_loss      | 2.73     |
|    critic_loss     | 1.61     |
|    learning_rate   | 0.000939 |
|    n_updates       | 60806    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 248      |
|    ep_rew_mean     | -5.4     |
| time/              |          |
|    episodes        | 252      |
|    fps             | 11       |
|    time_elapsed    | 5430     |
|    total timesteps | 62492    |
| train/             |          |
|    actor_loss      | 2.67     |
|    critic_loss     | 1.4      |
|    learning_rate   | 0.000938 |
|    n_updates       | 61810    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 248      |
|    ep_rew_mean     | -6.57    |
| time/              |          |
|    episodes        | 256      |
|    fps             | 11       |
|    time_elapsed    | 5520     |
|    total timesteps | 63496    |
| train/             |          |
|    actor_loss      | 2.62     |
|    critic_loss     | 1.03     |
|    learning_rate   | 0.000937 |
|    n_updates       | 62814    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 248      |
|    ep_rew_mean     | -5.78    |
| time/              |          |
|    episodes        | 260      |
|    fps             | 11       |
|    time_elapsed    | 5610     |
|    total timesteps | 64500    |
| train/             |          |
|    actor_loss      | 2.61     |
|    critic_loss     | 1.59     |
|    learning_rate   | 0.000936 |
|    n_updates       | 63818    |
---------------------------------
Eval num_timesteps=65000, episode_reward=-2.11 +/- 7.50
Episode length: 251.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 251      |
|    mean_reward     | -2.11    |
| time/              |          |
|    total_timesteps | 65000    |
| train/             |          |
|    actor_loss      | 2.59     |
|    critic_loss     | 1.14     |
|    learning_rate   | 0.000936 |
|    n_updates       | 64320    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 248      |
|    ep_rew_mean     | -5.47    |
| time/              |          |
|    episodes        | 264      |
|    fps             | 11       |
|    time_elapsed    | 5721     |
|    total timesteps | 65504    |
| train/             |          |
|    actor_loss      | 2.6      |
|    critic_loss     | 1.64     |
|    learning_rate   | 0.000935 |
|    n_updates       | 64822    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 248      |
|    ep_rew_mean     | -5.76    |
| time/              |          |
|    episodes        | 268      |
|    fps             | 11       |
|    time_elapsed    | 5813     |
|    total timesteps | 66508    |
| train/             |          |
|    actor_loss      | 2.57     |
|    critic_loss     | 1.1      |
|    learning_rate   | 0.000934 |
|    n_updates       | 65826    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 248      |
|    ep_rew_mean     | -6.47    |
| time/              |          |
|    episodes        | 272      |
|    fps             | 11       |
|    time_elapsed    | 5907     |
|    total timesteps | 67512    |
| train/             |          |
|    actor_loss      | 2.52     |
|    critic_loss     | 1.16     |
|    learning_rate   | 0.000933 |
|    n_updates       | 66830    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 248      |
|    ep_rew_mean     | -7.29    |
| time/              |          |
|    episodes        | 276      |
|    fps             | 11       |
|    time_elapsed    | 6000     |
|    total timesteps | 68516    |
| train/             |          |
|    actor_loss      | 2.48     |
|    critic_loss     | 1.53     |
|    learning_rate   | 0.000932 |
|    n_updates       | 67834    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 248      |
|    ep_rew_mean     | -6.5     |
| time/              |          |
|    episodes        | 280      |
|    fps             | 11       |
|    time_elapsed    | 6094     |
|    total timesteps | 69520    |
| train/             |          |
|    actor_loss      | 2.45     |
|    critic_loss     | 1.38     |
|    learning_rate   | 0.000931 |
|    n_updates       | 68838    |
---------------------------------
Eval num_timesteps=70000, episode_reward=2.99 +/- 3.83
Episode length: 251.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 251      |
|    mean_reward     | 2.99     |
| time/              |          |
|    total_timesteps | 70000    |
| train/             |          |
|    actor_loss      | 2.44     |
|    critic_loss     | 1.27     |
|    learning_rate   | 0.000931 |
|    n_updates       | 69340    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 248      |
|    ep_rew_mean     | -7.07    |
| time/              |          |
|    episodes        | 284      |
|    fps             | 11       |
|    time_elapsed    | 6208     |
|    total timesteps | 70524    |
| train/             |          |
|    actor_loss      | 2.45     |
|    critic_loss     | 1.66     |
|    learning_rate   | 0.00093  |
|    n_updates       | 69842    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 248      |
|    ep_rew_mean     | -5.89    |
| time/              |          |
|    episodes        | 288      |
|    fps             | 11       |
|    time_elapsed    | 6302     |
|    total timesteps | 71528    |
| train/             |          |
|    actor_loss      | 2.41     |
|    critic_loss     | 1.34     |
|    learning_rate   | 0.000929 |
|    n_updates       | 70846    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 248      |
|    ep_rew_mean     | -6.74    |
| time/              |          |
|    episodes        | 292      |
|    fps             | 11       |
|    time_elapsed    | 6396     |
|    total timesteps | 72532    |
| train/             |          |
|    actor_loss      | 2.42     |
|    critic_loss     | 1.44     |
|    learning_rate   | 0.000928 |
|    n_updates       | 71850    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 248      |
|    ep_rew_mean     | -6.28    |
| time/              |          |
|    episodes        | 296      |
|    fps             | 11       |
|    time_elapsed    | 6492     |
|    total timesteps | 73536    |
| train/             |          |
|    actor_loss      | 2.42     |
|    critic_loss     | 1.36     |
|    learning_rate   | 0.000927 |
|    n_updates       | 72854    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -6.94    |
| time/              |          |
|    episodes        | 300      |
|    fps             | 11       |
|    time_elapsed    | 6588     |
|    total timesteps | 74540    |
| train/             |          |
|    actor_loss      | 2.44     |
|    critic_loss     | 2.01     |
|    learning_rate   | 0.000926 |
|    n_updates       | 73858    |
---------------------------------
Eval num_timesteps=75000, episode_reward=0.29 +/- 4.04
Episode length: 251.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 251      |
|    mean_reward     | 0.294    |
| time/              |          |
|    total_timesteps | 75000    |
| train/             |          |
|    actor_loss      | 2.4      |
|    critic_loss     | 0.923    |
|    learning_rate   | 0.000926 |
|    n_updates       | 74360    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -6.86    |
| time/              |          |
|    episodes        | 304      |
|    fps             | 11       |
|    time_elapsed    | 6704     |
|    total timesteps | 75544    |
| train/             |          |
|    actor_loss      | 2.39     |
|    critic_loss     | 1.09     |
|    learning_rate   | 0.000925 |
|    n_updates       | 74862    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -6.23    |
| time/              |          |
|    episodes        | 308      |
|    fps             | 11       |
|    time_elapsed    | 6800     |
|    total timesteps | 76548    |
| train/             |          |
|    actor_loss      | 2.39     |
|    critic_loss     | 0.96     |
|    learning_rate   | 0.000924 |
|    n_updates       | 75866    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -6.17    |
| time/              |          |
|    episodes        | 312      |
|    fps             | 11       |
|    time_elapsed    | 6897     |
|    total timesteps | 77552    |
| train/             |          |
|    actor_loss      | 2.36     |
|    critic_loss     | 1.21     |
|    learning_rate   | 0.000923 |
|    n_updates       | 76870    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -6.77    |
| time/              |          |
|    episodes        | 316      |
|    fps             | 11       |
|    time_elapsed    | 6995     |
|    total timesteps | 78556    |
| train/             |          |
|    actor_loss      | 2.31     |
|    critic_loss     | 1.02     |
|    learning_rate   | 0.000922 |
|    n_updates       | 77874    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -6.86    |
| time/              |          |
|    episodes        | 320      |
|    fps             | 11       |
|    time_elapsed    | 7093     |
|    total timesteps | 79560    |
| train/             |          |
|    actor_loss      | 2.28     |
|    critic_loss     | 0.932    |
|    learning_rate   | 0.000921 |
|    n_updates       | 78878    |
---------------------------------
Eval num_timesteps=80000, episode_reward=2.21 +/- 4.27
Episode length: 251.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 251      |
|    mean_reward     | 2.21     |
| time/              |          |
|    total_timesteps | 80000    |
| train/             |          |
|    actor_loss      | 2.32     |
|    critic_loss     | 1.65     |
|    learning_rate   | 0.000921 |
|    n_updates       | 79380    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -7.87    |
| time/              |          |
|    episodes        | 324      |
|    fps             | 11       |
|    time_elapsed    | 7212     |
|    total timesteps | 80564    |
| train/             |          |
|    actor_loss      | 2.3      |
|    critic_loss     | 1.51     |
|    learning_rate   | 0.00092  |
|    n_updates       | 79882    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -9.43    |
| time/              |          |
|    episodes        | 328      |
|    fps             | 11       |
|    time_elapsed    | 7312     |
|    total timesteps | 81568    |
| train/             |          |
|    actor_loss      | 2.28     |
|    critic_loss     | 1.04     |
|    learning_rate   | 0.000919 |
|    n_updates       | 80886    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -10.5    |
| time/              |          |
|    episodes        | 332      |
|    fps             | 11       |
|    time_elapsed    | 7414     |
|    total timesteps | 82572    |
| train/             |          |
|    actor_loss      | 2.28     |
|    critic_loss     | 1.38     |
|    learning_rate   | 0.000919 |
|    n_updates       | 81890    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -10.5    |
| time/              |          |
|    episodes        | 336      |
|    fps             | 11       |
|    time_elapsed    | 7517     |
|    total timesteps | 83576    |
| train/             |          |
|    actor_loss      | 2.26     |
|    critic_loss     | 1.44     |
|    learning_rate   | 0.000918 |
|    n_updates       | 82894    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -10.1    |
| time/              |          |
|    episodes        | 340      |
|    fps             | 11       |
|    time_elapsed    | 7623     |
|    total timesteps | 84580    |
| train/             |          |
|    actor_loss      | 2.22     |
|    critic_loss     | 1.33     |
|    learning_rate   | 0.000917 |
|    n_updates       | 83898    |
---------------------------------
Eval num_timesteps=85000, episode_reward=-3.85 +/- 8.38
Episode length: 251.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 251      |
|    mean_reward     | -3.85    |
| time/              |          |
|    total_timesteps | 85000    |
| train/             |          |
|    actor_loss      | 2.22     |
|    critic_loss     | 1.38     |
|    learning_rate   | 0.000916 |
|    n_updates       | 84400    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -9.72    |
| time/              |          |
|    episodes        | 344      |
|    fps             | 11       |
|    time_elapsed    | 7751     |
|    total timesteps | 85584    |
| train/             |          |
|    actor_loss      | 2.22     |
|    critic_loss     | 1.11     |
|    learning_rate   | 0.000916 |
|    n_updates       | 84902    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -10.1    |
| time/              |          |
|    episodes        | 348      |
|    fps             | 11       |
|    time_elapsed    | 7849     |
|    total timesteps | 86468    |
| train/             |          |
|    actor_loss      | 2.22     |
|    critic_loss     | 1.3      |
|    learning_rate   | 0.000915 |
|    n_updates       | 85786    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -11.3    |
| time/              |          |
|    episodes        | 352      |
|    fps             | 10       |
|    time_elapsed    | 7962     |
|    total timesteps | 87472    |
| train/             |          |
|    actor_loss      | 2.21     |
|    critic_loss     | 1.27     |
|    learning_rate   | 0.000914 |
|    n_updates       | 86790    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -10.9    |
| time/              |          |
|    episodes        | 356      |
|    fps             | 10       |
|    time_elapsed    | 8077     |
|    total timesteps | 88476    |
| train/             |          |
|    actor_loss      | 2.19     |
|    critic_loss     | 1.13     |
|    learning_rate   | 0.000913 |
|    n_updates       | 87794    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -11.5    |
| time/              |          |
|    episodes        | 360      |
|    fps             | 10       |
|    time_elapsed    | 8194     |
|    total timesteps | 89480    |
| train/             |          |
|    actor_loss      | 2.2      |
|    critic_loss     | 1.24     |
|    learning_rate   | 0.000912 |
|    n_updates       | 88798    |
---------------------------------
Eval num_timesteps=90000, episode_reward=3.33 +/- 5.35
Episode length: 251.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 251      |
|    mean_reward     | 3.33     |
| time/              |          |
|    total_timesteps | 90000    |
| train/             |          |
|    actor_loss      | 2.22     |
|    critic_loss     | 1.65     |
|    learning_rate   | 0.000911 |
|    n_updates       | 89535    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -10.5    |
| time/              |          |
|    episodes        | 364      |
|    fps             | 10       |
|    time_elapsed    | 8331     |
|    total timesteps | 90463    |
| train/             |          |
|    actor_loss      | 2.22     |
|    critic_loss     | 1.42     |
|    learning_rate   | 0.000911 |
|    n_updates       | 89781    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -10.8    |
| time/              |          |
|    episodes        | 368      |
|    fps             | 10       |
|    time_elapsed    | 8449     |
|    total timesteps | 91467    |
| train/             |          |
|    actor_loss      | 2.23     |
|    critic_loss     | 1.57     |
|    learning_rate   | 0.00091  |
|    n_updates       | 90785    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -11.2    |
| time/              |          |
|    episodes        | 372      |
|    fps             | 10       |
|    time_elapsed    | 8568     |
|    total timesteps | 92471    |
| train/             |          |
|    actor_loss      | 2.26     |
|    critic_loss     | 2.03     |
|    learning_rate   | 0.000909 |
|    n_updates       | 91789    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -11      |
| time/              |          |
|    episodes        | 376      |
|    fps             | 10       |
|    time_elapsed    | 8676     |
|    total timesteps | 93374    |
| train/             |          |
|    actor_loss      | 2.21     |
|    critic_loss     | 1        |
|    learning_rate   | 0.000908 |
|    n_updates       | 92692    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -11.1    |
| time/              |          |
|    episodes        | 380      |
|    fps             | 10       |
|    time_elapsed    | 8796     |
|    total timesteps | 94378    |
| train/             |          |
|    actor_loss      | 2.21     |
|    critic_loss     | 1.18     |
|    learning_rate   | 0.000907 |
|    n_updates       | 93696    |
---------------------------------
Eval num_timesteps=95000, episode_reward=1.18 +/- 4.78
Episode length: 251.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 251      |
|    mean_reward     | 1.18     |
| time/              |          |
|    total_timesteps | 95000    |
| train/             |          |
|    actor_loss      | 2.22     |
|    critic_loss     | 1.25     |
|    learning_rate   | 0.000906 |
|    n_updates       | 94449    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -10.8    |
| time/              |          |
|    episodes        | 384      |
|    fps             | 10       |
|    time_elapsed    | 8936     |
|    total timesteps | 95382    |
| train/             |          |
|    actor_loss      | 2.23     |
|    critic_loss     | 1.64     |
|    learning_rate   | 0.000906 |
|    n_updates       | 94700    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -11      |
| time/              |          |
|    episodes        | 388      |
|    fps             | 10       |
|    time_elapsed    | 9055     |
|    total timesteps | 96386    |
| train/             |          |
|    actor_loss      | 2.21     |
|    critic_loss     | 1.39     |
|    learning_rate   | 0.000905 |
|    n_updates       | 95704    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -10.6    |
| time/              |          |
|    episodes        | 392      |
|    fps             | 10       |
|    time_elapsed    | 9175     |
|    total timesteps | 97390    |
| train/             |          |
|    actor_loss      | 2.2      |
|    critic_loss     | 0.984    |
|    learning_rate   | 0.000904 |
|    n_updates       | 96708    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -11.6    |
| time/              |          |
|    episodes        | 396      |
|    fps             | 10       |
|    time_elapsed    | 9315     |
|    total timesteps | 98394    |
| train/             |          |
|    actor_loss      | 2.22     |
|    critic_loss     | 1.68     |
|    learning_rate   | 0.000903 |
|    n_updates       | 97712    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -11.3    |
| time/              |          |
|    episodes        | 400      |
|    fps             | 10       |
|    time_elapsed    | 9435     |
|    total timesteps | 99398    |
| train/             |          |
|    actor_loss      | 2.21     |
|    critic_loss     | 1.63     |
|    learning_rate   | 0.000902 |
|    n_updates       | 98716    |
---------------------------------
Eval num_timesteps=100000, episode_reward=-3.44 +/- 6.79
Episode length: 251.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 251      |
|    mean_reward     | -3.44    |
| time/              |          |
|    total_timesteps | 100000   |
| train/             |          |
|    actor_loss      | 2.21     |
|    critic_loss     | 1.4      |
|    learning_rate   | 0.000901 |
|    n_updates       | 99469    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -11.3    |
| time/              |          |
|    episodes        | 404      |
|    fps             | 10       |
|    time_elapsed    | 9576     |
|    total timesteps | 100402   |
| train/             |          |
|    actor_loss      | 2.2      |
|    critic_loss     | 1.13     |
|    learning_rate   | 0.000901 |
|    n_updates       | 99720    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -11.2    |
| time/              |          |
|    episodes        | 408      |
|    fps             | 10       |
|    time_elapsed    | 9698     |
|    total timesteps | 101406   |
| train/             |          |
|    actor_loss      | 2.18     |
|    critic_loss     | 1.15     |
|    learning_rate   | 0.0009   |
|    n_updates       | 100724   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -10.7    |
| time/              |          |
|    episodes        | 412      |
|    fps             | 10       |
|    time_elapsed    | 9819     |
|    total timesteps | 102410   |
| train/             |          |
|    actor_loss      | 2.18     |
|    critic_loss     | 1.03     |
|    learning_rate   | 0.000899 |
|    n_updates       | 101728   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -10.5    |
| time/              |          |
|    episodes        | 416      |
|    fps             | 10       |
|    time_elapsed    | 9941     |
|    total timesteps | 103414   |
| train/             |          |
|    actor_loss      | 2.16     |
|    critic_loss     | 1.25     |
|    learning_rate   | 0.000898 |
|    n_updates       | 102732   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -9.78    |
| time/              |          |
|    episodes        | 420      |
|    fps             | 10       |
|    time_elapsed    | 10063    |
|    total timesteps | 104418   |
| train/             |          |
|    actor_loss      | 2.17     |
|    critic_loss     | 1.48     |
|    learning_rate   | 0.000897 |
|    n_updates       | 103736   |
---------------------------------
Eval num_timesteps=105000, episode_reward=2.62 +/- 5.04
Episode length: 251.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 251      |
|    mean_reward     | 2.62     |
| time/              |          |
|    total_timesteps | 105000   |
| train/             |          |
|    actor_loss      | 2.15     |
|    critic_loss     | 1.22     |
|    learning_rate   | 0.000896 |
|    n_updates       | 104489   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -8.74    |
| time/              |          |
|    episodes        | 424      |
|    fps             | 10       |
|    time_elapsed    | 10203    |
|    total timesteps | 105422   |
| train/             |          |
|    actor_loss      | 2.18     |
|    critic_loss     | 1.56     |
|    learning_rate   | 0.000896 |
|    n_updates       | 104740   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -8.17    |
| time/              |          |
|    episodes        | 428      |
|    fps             | 10       |
|    time_elapsed    | 10325    |
|    total timesteps | 106426   |
| train/             |          |
|    actor_loss      | 2.17     |
|    critic_loss     | 1.19     |
|    learning_rate   | 0.000895 |
|    n_updates       | 105744   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -7.9     |
| time/              |          |
|    episodes        | 432      |
|    fps             | 10       |
|    time_elapsed    | 10447    |
|    total timesteps | 107430   |
| train/             |          |
|    actor_loss      | 2.16     |
|    critic_loss     | 1.3      |
|    learning_rate   | 0.000894 |
|    n_updates       | 106748   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -7.72    |
| time/              |          |
|    episodes        | 436      |
|    fps             | 10       |
|    time_elapsed    | 10568    |
|    total timesteps | 108434   |
| train/             |          |
|    actor_loss      | 2.17     |
|    critic_loss     | 1.56     |
|    learning_rate   | 0.000893 |
|    n_updates       | 107752   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 248      |
|    ep_rew_mean     | -8.23    |
| time/              |          |
|    episodes        | 440      |
|    fps             | 10       |
|    time_elapsed    | 10678    |
|    total timesteps | 109331   |
| train/             |          |
|    actor_loss      | 2.13     |
|    critic_loss     | 1.1      |
|    learning_rate   | 0.000892 |
|    n_updates       | 108649   |
---------------------------------
Eval num_timesteps=110000, episode_reward=5.70 +/- 2.47
Episode length: 251.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 251      |
|    mean_reward     | 5.7      |
| time/              |          |
|    total_timesteps | 110000   |
| train/             |          |
|    actor_loss      | 2.15     |
|    critic_loss     | 1.2      |
|    learning_rate   | 0.000891 |
|    n_updates       | 109402   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 248      |
|    ep_rew_mean     | -8.26    |
| time/              |          |
|    episodes        | 444      |
|    fps             | 10       |
|    time_elapsed    | 10819    |
|    total timesteps | 110335   |
| train/             |          |
|    actor_loss      | 2.15     |
|    critic_loss     | 1.22     |
|    learning_rate   | 0.000891 |
|    n_updates       | 109653   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 248      |
|    ep_rew_mean     | -8.21    |
| time/              |          |
|    episodes        | 448      |
|    fps             | 10       |
|    time_elapsed    | 10938    |
|    total timesteps | 111310   |
| train/             |          |
|    actor_loss      | 2.14     |
|    critic_loss     | 1.3      |
|    learning_rate   | 0.00089  |
|    n_updates       | 110628   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 248      |
|    ep_rew_mean     | -7.33    |
| time/              |          |
|    episodes        | 452      |
|    fps             | 10       |
|    time_elapsed    | 11060    |
|    total timesteps | 112314   |
| train/             |          |
|    actor_loss      | 2.11     |
|    critic_loss     | 1.14     |
|    learning_rate   | 0.000889 |
|    n_updates       | 111632   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 247      |
|    ep_rew_mean     | -7.01    |
| time/              |          |
|    episodes        | 456      |
|    fps             | 10       |
|    time_elapsed    | 11180    |
|    total timesteps | 113217   |
| train/             |          |
|    actor_loss      | 2.12     |
|    critic_loss     | 1.41     |
|    learning_rate   | 0.000888 |
|    n_updates       | 112636   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 247      |
|    ep_rew_mean     | -6.13    |
| time/              |          |
|    episodes        | 460      |
|    fps             | 10       |
|    time_elapsed    | 11291    |
|    total timesteps | 114221   |
| train/             |          |
|    actor_loss      | 2.12     |
|    critic_loss     | 1.34     |
|    learning_rate   | 0.000887 |
|    n_updates       | 113539   |
---------------------------------
Eval num_timesteps=115000, episode_reward=4.54 +/- 4.34
Episode length: 251.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 251      |
|    mean_reward     | 4.54     |
| time/              |          |
|    total_timesteps | 115000   |
| train/             |          |
|    actor_loss      | 2.1      |
|    critic_loss     | 0.978    |
|    learning_rate   | 0.000886 |
|    n_updates       | 114543   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 248      |
|    ep_rew_mean     | -7.22    |
| time/              |          |
|    episodes        | 464      |
|    fps             | 10       |
|    time_elapsed    | 11434    |
|    total timesteps | 115225   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 248      |
|    ep_rew_mean     | -7.78    |
| time/              |          |
|    episodes        | 468      |
|    fps             | 10       |
|    time_elapsed    | 11556    |
|    total timesteps | 116229   |
| train/             |          |
|    actor_loss      | 2.07     |
|    critic_loss     | 0.912    |
|    learning_rate   | 0.000885 |
|    n_updates       | 115547   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 248      |
|    ep_rew_mean     | -7.37    |
| time/              |          |
|    episodes        | 472      |
|    fps             | 10       |
|    time_elapsed    | 11680    |
|    total timesteps | 117233   |
| train/             |          |
|    actor_loss      | 2.1      |
|    critic_loss     | 1.4      |
|    learning_rate   | 0.000884 |
|    n_updates       | 116551   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -6.96    |
| time/              |          |
|    episodes        | 476      |
|    fps             | 10       |
|    time_elapsed    | 11802    |
|    total timesteps | 118237   |
| train/             |          |
|    actor_loss      | 2.11     |
|    critic_loss     | 1.11     |
|    learning_rate   | 0.000883 |
|    n_updates       | 117555   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -7.19    |
| time/              |          |
|    episodes        | 480      |
|    fps             | 9        |
|    time_elapsed    | 11925    |
|    total timesteps | 119241   |
| train/             |          |
|    actor_loss      | 2.1      |
|    critic_loss     | 1.38     |
|    learning_rate   | 0.000882 |
|    n_updates       | 118559   |
---------------------------------
Eval num_timesteps=120000, episode_reward=4.77 +/- 5.11
Episode length: 251.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 251      |
|    mean_reward     | 4.77     |
| time/              |          |
|    total_timesteps | 120000   |
| train/             |          |
|    actor_loss      | 2.11     |
|    critic_loss     | 1.27     |
|    learning_rate   | 0.000881 |
|    n_updates       | 119563   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -6.42    |
| time/              |          |
|    episodes        | 484      |
|    fps             | 9        |
|    time_elapsed    | 12068    |
|    total timesteps | 120245   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -6.17    |
| time/              |          |
|    episodes        | 488      |
|    fps             | 9        |
|    time_elapsed    | 12191    |
|    total timesteps | 121249   |
| train/             |          |
|    actor_loss      | 2.12     |
|    critic_loss     | 1.31     |
|    learning_rate   | 0.00088  |
|    n_updates       | 120567   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -5.76    |
| time/              |          |
|    episodes        | 492      |
|    fps             | 9        |
|    time_elapsed    | 12316    |
|    total timesteps | 122253   |
| train/             |          |
|    actor_loss      | 2.12     |
|    critic_loss     | 1.08     |
|    learning_rate   | 0.000879 |
|    n_updates       | 121571   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -5.27    |
| time/              |          |
|    episodes        | 496      |
|    fps             | 9        |
|    time_elapsed    | 12439    |
|    total timesteps | 123257   |
| train/             |          |
|    actor_loss      | 2.14     |
|    critic_loss     | 1.48     |
|    learning_rate   | 0.000878 |
|    n_updates       | 122575   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -5.75    |
| time/              |          |
|    episodes        | 500      |
|    fps             | 9        |
|    time_elapsed    | 12563    |
|    total timesteps | 124261   |
| train/             |          |
|    actor_loss      | 2.13     |
|    critic_loss     | 1.42     |
|    learning_rate   | 0.000877 |
|    n_updates       | 123579   |
---------------------------------
Eval num_timesteps=125000, episode_reward=2.42 +/- 4.42
Episode length: 251.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 251      |
|    mean_reward     | 2.42     |
| time/              |          |
|    total_timesteps | 125000   |
| train/             |          |
|    actor_loss      | 2.12     |
|    critic_loss     | 1.09     |
|    learning_rate   | 0.000876 |
|    n_updates       | 124332   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -6.46    |
| time/              |          |
|    episodes        | 504      |
|    fps             | 9        |
|    time_elapsed    | 12707    |
|    total timesteps | 125265   |
| train/             |          |
|    actor_loss      | 2.11     |
|    critic_loss     | 0.963    |
|    learning_rate   | 0.000876 |
|    n_updates       | 124583   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -6.71    |
| time/              |          |
|    episodes        | 508      |
|    fps             | 9        |
|    time_elapsed    | 12831    |
|    total timesteps | 126269   |
| train/             |          |
|    actor_loss      | 2.14     |
|    critic_loss     | 1.43     |
|    learning_rate   | 0.000875 |
|    n_updates       | 125587   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -8.43    |
| time/              |          |
|    episodes        | 512      |
|    fps             | 9        |
|    time_elapsed    | 12956    |
|    total timesteps | 127273   |
| train/             |          |
|    actor_loss      | 2.13     |
|    critic_loss     | 1.54     |
|    learning_rate   | 0.000874 |
|    n_updates       | 126591   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -7.92    |
| time/              |          |
|    episodes        | 516      |
|    fps             | 9        |
|    time_elapsed    | 13080    |
|    total timesteps | 128277   |
| train/             |          |
|    actor_loss      | 2.11     |
|    critic_loss     | 1.51     |
|    learning_rate   | 0.000873 |
|    n_updates       | 127595   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -7.71    |
| time/              |          |
|    episodes        | 520      |
|    fps             | 9        |
|    time_elapsed    | 13205    |
|    total timesteps | 129281   |
| train/             |          |
|    actor_loss      | 2.12     |
|    critic_loss     | 1.65     |
|    learning_rate   | 0.000872 |
|    n_updates       | 128599   |
---------------------------------
Eval num_timesteps=130000, episode_reward=-0.51 +/- 6.73
Episode length: 251.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 251      |
|    mean_reward     | -0.511   |
| time/              |          |
|    total_timesteps | 130000   |
| train/             |          |
|    actor_loss      | 2.1      |
|    critic_loss     | 1.18     |
|    learning_rate   | 0.000872 |
|    n_updates       | 129352   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -7.64    |
| time/              |          |
|    episodes        | 524      |
|    fps             | 9        |
|    time_elapsed    | 13349    |
|    total timesteps | 130285   |
| train/             |          |
|    actor_loss      | 2.11     |
|    critic_loss     | 1.37     |
|    learning_rate   | 0.000871 |
|    n_updates       | 129603   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -7.84    |
| time/              |          |
|    episodes        | 528      |
|    fps             | 9        |
|    time_elapsed    | 13473    |
|    total timesteps | 131289   |
| train/             |          |
|    actor_loss      | 2.13     |
|    critic_loss     | 1.64     |
|    learning_rate   | 0.00087  |
|    n_updates       | 130607   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -7.29    |
| time/              |          |
|    episodes        | 532      |
|    fps             | 9        |
|    time_elapsed    | 13596    |
|    total timesteps | 132293   |
| train/             |          |
|    actor_loss      | 2.12     |
|    critic_loss     | 1.15     |
|    learning_rate   | 0.000869 |
|    n_updates       | 131611   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -7.51    |
| time/              |          |
|    episodes        | 536      |
|    fps             | 9        |
|    time_elapsed    | 13721    |
|    total timesteps | 133297   |
| train/             |          |
|    actor_loss      | 2.13     |
|    critic_loss     | 1.46     |
|    learning_rate   | 0.000868 |
|    n_updates       | 132615   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -7.71    |
| time/              |          |
|    episodes        | 540      |
|    fps             | 9        |
|    time_elapsed    | 13845    |
|    total timesteps | 134301   |
| train/             |          |
|    actor_loss      | 2.12     |
|    critic_loss     | 1.43     |
|    learning_rate   | 0.000867 |
|    n_updates       | 133619   |
---------------------------------
Eval num_timesteps=135000, episode_reward=2.10 +/- 4.20
Episode length: 251.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 251      |
|    mean_reward     | 2.1      |
| time/              |          |
|    total_timesteps | 135000   |
| train/             |          |
|    actor_loss      | 2.14     |
|    critic_loss     | 1.63     |
|    learning_rate   | 0.000867 |
|    n_updates       | 134372   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -7.71    |
| time/              |          |
|    episodes        | 544      |
|    fps             | 9        |
|    time_elapsed    | 13989    |
|    total timesteps | 135305   |
| train/             |          |
|    actor_loss      | 2.1      |
|    critic_loss     | 0.93     |
|    learning_rate   | 0.000866 |
|    n_updates       | 134623   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -7.73    |
| time/              |          |
|    episodes        | 548      |
|    fps             | 9        |
|    time_elapsed    | 14114    |
|    total timesteps | 136309   |
| train/             |          |
|    actor_loss      | 2.09     |
|    critic_loss     | 1.37     |
|    learning_rate   | 0.000865 |
|    n_updates       | 135627   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -8.35    |
| time/              |          |
|    episodes        | 552      |
|    fps             | 9        |
|    time_elapsed    | 14238    |
|    total timesteps | 137313   |
| train/             |          |
|    actor_loss      | 2.09     |
|    critic_loss     | 1.23     |
|    learning_rate   | 0.000864 |
|    n_updates       | 136631   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -8.58    |
| time/              |          |
|    episodes        | 556      |
|    fps             | 9        |
|    time_elapsed    | 14363    |
|    total timesteps | 138317   |
| train/             |          |
|    actor_loss      | 2.09     |
|    critic_loss     | 1.14     |
|    learning_rate   | 0.000863 |
|    n_updates       | 137635   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -9.14    |
| time/              |          |
|    episodes        | 560      |
|    fps             | 9        |
|    time_elapsed    | 14488    |
|    total timesteps | 139321   |
| train/             |          |
|    actor_loss      | 2.12     |
|    critic_loss     | 1.36     |
|    learning_rate   | 0.000862 |
|    n_updates       | 138639   |
---------------------------------
Eval num_timesteps=140000, episode_reward=4.02 +/- 3.87
Episode length: 251.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 251      |
|    mean_reward     | 4.02     |
| time/              |          |
|    total_timesteps | 140000   |
| train/             |          |
|    actor_loss      | 2.1      |
|    critic_loss     | 1.11     |
|    learning_rate   | 0.000862 |
|    n_updates       | 139392   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -8.71    |
| time/              |          |
|    episodes        | 564      |
|    fps             | 9        |
|    time_elapsed    | 14631    |
|    total timesteps | 140264   |
| train/             |          |
|    actor_loss      | 2.12     |
|    critic_loss     | 1.53     |
|    learning_rate   | 0.000861 |
|    n_updates       | 139643   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -7.77    |
| time/              |          |
|    episodes        | 568      |
|    fps             | 9        |
|    time_elapsed    | 14748    |
|    total timesteps | 141268   |
| train/             |          |
|    actor_loss      | 2.09     |
|    critic_loss     | 1.15     |
|    learning_rate   | 0.00086  |
|    n_updates       | 140586   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -7.76    |
| time/              |          |
|    episodes        | 572      |
|    fps             | 9        |
|    time_elapsed    | 14873    |
|    total timesteps | 142272   |
| train/             |          |
|    actor_loss      | 2.11     |
|    critic_loss     | 1.31     |
|    learning_rate   | 0.000859 |
|    n_updates       | 141590   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -8.37    |
| time/              |          |
|    episodes        | 576      |
|    fps             | 9        |
|    time_elapsed    | 14997    |
|    total timesteps | 143276   |
| train/             |          |
|    actor_loss      | 2.08     |
|    critic_loss     | 1.08     |
|    learning_rate   | 0.000858 |
|    n_updates       | 142594   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -8.46    |
| time/              |          |
|    episodes        | 580      |
|    fps             | 9        |
|    time_elapsed    | 15122    |
|    total timesteps | 144280   |
| train/             |          |
|    actor_loss      | 2.1      |
|    critic_loss     | 0.949    |
|    learning_rate   | 0.000857 |
|    n_updates       | 143598   |
---------------------------------
Eval num_timesteps=145000, episode_reward=-3.53 +/- 7.45
Episode length: 251.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 251      |
|    mean_reward     | -3.53    |
| time/              |          |
|    total_timesteps | 145000   |
| train/             |          |
|    actor_loss      | 2.12     |
|    critic_loss     | 1.38     |
|    learning_rate   | 0.000857 |
|    n_updates       | 144351   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -8.91    |
| time/              |          |
|    episodes        | 584      |
|    fps             | 9        |
|    time_elapsed    | 15267    |
|    total timesteps | 145284   |
| train/             |          |
|    actor_loss      | 2.1      |
|    critic_loss     | 1.09     |
|    learning_rate   | 0.000856 |
|    n_updates       | 144602   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -9.09    |
| time/              |          |
|    episodes        | 588      |
|    fps             | 9        |
|    time_elapsed    | 15392    |
|    total timesteps | 146288   |
| train/             |          |
|    actor_loss      | 2.13     |
|    critic_loss     | 1.66     |
|    learning_rate   | 0.000855 |
|    n_updates       | 145606   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -9.97    |
| time/              |          |
|    episodes        | 592      |
|    fps             | 9        |
|    time_elapsed    | 15517    |
|    total timesteps | 147292   |
| train/             |          |
|    actor_loss      | 2.12     |
|    critic_loss     | 1.24     |
|    learning_rate   | 0.000854 |
|    n_updates       | 146610   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -9.62    |
| time/              |          |
|    episodes        | 596      |
|    fps             | 9        |
|    time_elapsed    | 15641    |
|    total timesteps | 148296   |
| train/             |          |
|    actor_loss      | 2.12     |
|    critic_loss     | 1.35     |
|    learning_rate   | 0.000853 |
|    n_updates       | 147614   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -8.94    |
| time/              |          |
|    episodes        | 600      |
|    fps             | 9        |
|    time_elapsed    | 15766    |
|    total timesteps | 149300   |
| train/             |          |
|    actor_loss      | 2.12     |
|    critic_loss     | 1.36     |
|    learning_rate   | 0.000852 |
|    n_updates       | 148618   |
---------------------------------
Eval num_timesteps=150000, episode_reward=5.06 +/- 4.67
Episode length: 251.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 251      |
|    mean_reward     | 5.06     |
| time/              |          |
|    total_timesteps | 150000   |
| train/             |          |
|    actor_loss      | 2.13     |
|    critic_loss     | 1.28     |
|    learning_rate   | 0.000852 |
|    n_updates       | 149371   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -8.25    |
| time/              |          |
|    episodes        | 604      |
|    fps             | 9        |
|    time_elapsed    | 15911    |
|    total timesteps | 150304   |
| train/             |          |
|    actor_loss      | 2.12     |
|    critic_loss     | 1.28     |
|    learning_rate   | 0.000851 |
|    n_updates       | 149622   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -8.76    |
| time/              |          |
|    episodes        | 608      |
|    fps             | 9        |
|    time_elapsed    | 16036    |
|    total timesteps | 151308   |
| train/             |          |
|    actor_loss      | 2.11     |
|    critic_loss     | 1.53     |
|    learning_rate   | 0.00085  |
|    n_updates       | 150626   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -7.38    |
| time/              |          |
|    episodes        | 612      |
|    fps             | 9        |
|    time_elapsed    | 16160    |
|    total timesteps | 152312   |
| train/             |          |
|    actor_loss      | 2.11     |
|    critic_loss     | 1.22     |
|    learning_rate   | 0.000849 |
|    n_updates       | 151630   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -8.02    |
| time/              |          |
|    episodes        | 616      |
|    fps             | 9        |
|    time_elapsed    | 16284    |
|    total timesteps | 153316   |
| train/             |          |
|    actor_loss      | 2.11     |
|    critic_loss     | 1.34     |
|    learning_rate   | 0.000848 |
|    n_updates       | 152634   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -8.5     |
| time/              |          |
|    episodes        | 620      |
|    fps             | 9        |
|    time_elapsed    | 16408    |
|    total timesteps | 154320   |
| train/             |          |
|    actor_loss      | 2.12     |
|    critic_loss     | 1.24     |
|    learning_rate   | 0.000847 |
|    n_updates       | 153638   |
---------------------------------
Eval num_timesteps=155000, episode_reward=0.73 +/- 8.03
Episode length: 251.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 251      |
|    mean_reward     | 0.73     |
| time/              |          |
|    total_timesteps | 155000   |
| train/             |          |
|    actor_loss      | 2.13     |
|    critic_loss     | 1.26     |
|    learning_rate   | 0.000847 |
|    n_updates       | 154391   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -8.27    |
| time/              |          |
|    episodes        | 624      |
|    fps             | 9        |
|    time_elapsed    | 16553    |
|    total timesteps | 155324   |
| train/             |          |
|    actor_loss      | 2.15     |
|    critic_loss     | 1.74     |
|    learning_rate   | 0.000846 |
|    n_updates       | 154642   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -8.52    |
| time/              |          |
|    episodes        | 628      |
|    fps             | 9        |
|    time_elapsed    | 16677    |
|    total timesteps | 156328   |
| train/             |          |
|    actor_loss      | 2.15     |
|    critic_loss     | 2.01     |
|    learning_rate   | 0.000845 |
|    n_updates       | 155646   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -9.05    |
| time/              |          |
|    episodes        | 632      |
|    fps             | 9        |
|    time_elapsed    | 16802    |
|    total timesteps | 157332   |
| train/             |          |
|    actor_loss      | 2.16     |
|    critic_loss     | 1.48     |
|    learning_rate   | 0.000844 |
|    n_updates       | 156650   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -8.84    |
| time/              |          |
|    episodes        | 636      |
|    fps             | 9        |
|    time_elapsed    | 16925    |
|    total timesteps | 158336   |
| train/             |          |
|    actor_loss      | 2.14     |
|    critic_loss     | 1.05     |
|    learning_rate   | 0.000843 |
|    n_updates       | 157654   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -8.82    |
| time/              |          |
|    episodes        | 640      |
|    fps             | 9        |
|    time_elapsed    | 17050    |
|    total timesteps | 159340   |
| train/             |          |
|    actor_loss      | 2.14     |
|    critic_loss     | 1.7      |
|    learning_rate   | 0.000843 |
|    n_updates       | 158658   |
---------------------------------
Eval num_timesteps=160000, episode_reward=2.41 +/- 5.57
Episode length: 251.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 251      |
|    mean_reward     | 2.41     |
| time/              |          |
|    total_timesteps | 160000   |
| train/             |          |
|    actor_loss      | 2.13     |
|    critic_loss     | 1.45     |
|    learning_rate   | 0.000842 |
|    n_updates       | 159411   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -9.05    |
| time/              |          |
|    episodes        | 644      |
|    fps             | 9        |
|    time_elapsed    | 17194    |
|    total timesteps | 160344   |
| train/             |          |
|    actor_loss      | 2.14     |
|    critic_loss     | 1.33     |
|    learning_rate   | 0.000842 |
|    n_updates       | 159662   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -9.27    |
| time/              |          |
|    episodes        | 648      |
|    fps             | 9        |
|    time_elapsed    | 17318    |
|    total timesteps | 161348   |
| train/             |          |
|    actor_loss      | 2.13     |
|    critic_loss     | 1.02     |
|    learning_rate   | 0.000841 |
|    n_updates       | 160666   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -8.4     |
| time/              |          |
|    episodes        | 652      |
|    fps             | 9        |
|    time_elapsed    | 17443    |
|    total timesteps | 162352   |
| train/             |          |
|    actor_loss      | 2.15     |
|    critic_loss     | 1.29     |
|    learning_rate   | 0.00084  |
|    n_updates       | 161670   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -8.2     |
| time/              |          |
|    episodes        | 656      |
|    fps             | 9        |
|    time_elapsed    | 17567    |
|    total timesteps | 163356   |
| train/             |          |
|    actor_loss      | 2.15     |
|    critic_loss     | 1.21     |
|    learning_rate   | 0.000839 |
|    n_updates       | 162674   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -8.2     |
| time/              |          |
|    episodes        | 660      |
|    fps             | 9        |
|    time_elapsed    | 17692    |
|    total timesteps | 164360   |
| train/             |          |
|    actor_loss      | 2.15     |
|    critic_loss     | 1.22     |
|    learning_rate   | 0.000838 |
|    n_updates       | 163678   |
---------------------------------
Eval num_timesteps=165000, episode_reward=4.49 +/- 2.07
Episode length: 251.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 251      |
|    mean_reward     | 4.49     |
| time/              |          |
|    total_timesteps | 165000   |
| train/             |          |
|    actor_loss      | 2.15     |
|    critic_loss     | 1.14     |
|    learning_rate   | 0.000837 |
|    n_updates       | 164564   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -7.96    |
| time/              |          |
|    episodes        | 664      |
|    fps             | 9        |
|    time_elapsed    | 17822    |
|    total timesteps | 165246   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -8.99    |
| time/              |          |
|    episodes        | 668      |
|    fps             | 9        |
|    time_elapsed    | 17946    |
|    total timesteps | 166250   |
| train/             |          |
|    actor_loss      | 2.14     |
|    critic_loss     | 1.43     |
|    learning_rate   | 0.000836 |
|    n_updates       | 165568   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -10.4    |
| time/              |          |
|    episodes        | 672      |
|    fps             | 9        |
|    time_elapsed    | 18071    |
|    total timesteps | 167254   |
| train/             |          |
|    actor_loss      | 2.14     |
|    critic_loss     | 1.48     |
|    learning_rate   | 0.000835 |
|    n_updates       | 166572   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -10.1    |
| time/              |          |
|    episodes        | 676      |
|    fps             | 9        |
|    time_elapsed    | 18196    |
|    total timesteps | 168258   |
| train/             |          |
|    actor_loss      | 2.14     |
|    critic_loss     | 1.35     |
|    learning_rate   | 0.000834 |
|    n_updates       | 167576   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -9.97    |
| time/              |          |
|    episodes        | 680      |
|    fps             | 9        |
|    time_elapsed    | 18319    |
|    total timesteps | 169262   |
| train/             |          |
|    actor_loss      | 2.12     |
|    critic_loss     | 1.27     |
|    learning_rate   | 0.000833 |
|    n_updates       | 168580   |
---------------------------------
Eval num_timesteps=170000, episode_reward=2.78 +/- 6.67
Episode length: 251.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 251      |
|    mean_reward     | 2.78     |
| time/              |          |
|    total_timesteps | 170000   |
| train/             |          |
|    actor_loss      | 2.14     |
|    critic_loss     | 1.22     |
|    learning_rate   | 0.000832 |
|    n_updates       | 169333   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -10.2    |
| time/              |          |
|    episodes        | 684      |
|    fps             | 9        |
|    time_elapsed    | 18464    |
|    total timesteps | 170266   |
| train/             |          |
|    actor_loss      | 2.15     |
|    critic_loss     | 1.55     |
|    learning_rate   | 0.000832 |
|    n_updates       | 169584   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -9.74    |
| time/              |          |
|    episodes        | 688      |
|    fps             | 9        |
|    time_elapsed    | 18589    |
|    total timesteps | 171270   |
| train/             |          |
|    actor_loss      | 2.16     |
|    critic_loss     | 1.62     |
|    learning_rate   | 0.000831 |
|    n_updates       | 170588   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -9.1     |
| time/              |          |
|    episodes        | 692      |
|    fps             | 9        |
|    time_elapsed    | 18714    |
|    total timesteps | 172274   |
| train/             |          |
|    actor_loss      | 2.17     |
|    critic_loss     | 1.58     |
|    learning_rate   | 0.00083  |
|    n_updates       | 171592   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -9.36    |
| time/              |          |
|    episodes        | 696      |
|    fps             | 9        |
|    time_elapsed    | 18839    |
|    total timesteps | 173278   |
| train/             |          |
|    actor_loss      | 2.19     |
|    critic_loss     | 1.47     |
|    learning_rate   | 0.000829 |
|    n_updates       | 172596   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -10.1    |
| time/              |          |
|    episodes        | 700      |
|    fps             | 9        |
|    time_elapsed    | 18965    |
|    total timesteps | 174282   |
| train/             |          |
|    actor_loss      | 2.19     |
|    critic_loss     | 1.55     |
|    learning_rate   | 0.000828 |
|    n_updates       | 173600   |
---------------------------------
Eval num_timesteps=175000, episode_reward=5.76 +/- 2.58
Episode length: 251.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 251      |
|    mean_reward     | 5.76     |
| time/              |          |
|    total_timesteps | 175000   |
| train/             |          |
|    actor_loss      | 2.2      |
|    critic_loss     | 1.18     |
|    learning_rate   | 0.000827 |
|    n_updates       | 174353   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -10.3    |
| time/              |          |
|    episodes        | 704      |
|    fps             | 9        |
|    time_elapsed    | 19108    |
|    total timesteps | 175286   |
| train/             |          |
|    actor_loss      | 2.19     |
|    critic_loss     | 1.24     |
|    learning_rate   | 0.000827 |
|    n_updates       | 174604   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -10.1    |
| time/              |          |
|    episodes        | 708      |
|    fps             | 9        |
|    time_elapsed    | 19233    |
|    total timesteps | 176290   |
| train/             |          |
|    actor_loss      | 2.24     |
|    critic_loss     | 1.38     |
|    learning_rate   | 0.000826 |
|    n_updates       | 175608   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -9.7     |
| time/              |          |
|    episodes        | 712      |
|    fps             | 9        |
|    time_elapsed    | 19347    |
|    total timesteps | 177209   |
| train/             |          |
|    actor_loss      | 2.24     |
|    critic_loss     | 1.43     |
|    learning_rate   | 0.000825 |
|    n_updates       | 176527   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 248      |
|    ep_rew_mean     | -10.2    |
| time/              |          |
|    episodes        | 716      |
|    fps             | 9        |
|    time_elapsed    | 19456    |
|    total timesteps | 178085   |
| train/             |          |
|    actor_loss      | 2.24     |
|    critic_loss     | 1.47     |
|    learning_rate   | 0.000824 |
|    n_updates       | 177403   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 248      |
|    ep_rew_mean     | -9.42    |
| time/              |          |
|    episodes        | 720      |
|    fps             | 9        |
|    time_elapsed    | 19580    |
|    total timesteps | 179089   |
| train/             |          |
|    actor_loss      | 2.25     |
|    critic_loss     | 1.59     |
|    learning_rate   | 0.000823 |
|    n_updates       | 178407   |
---------------------------------
Eval num_timesteps=180000, episode_reward=-0.51 +/- 7.29
Episode length: 251.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 251      |
|    mean_reward     | -0.511   |
| time/              |          |
|    total_timesteps | 180000   |
| train/             |          |
|    actor_loss      | 2.23     |
|    critic_loss     | 1.27     |
|    learning_rate   | 0.000822 |
|    n_updates       | 179411   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 248      |
|    ep_rew_mean     | -10.1    |
| time/              |          |
|    episodes        | 724      |
|    fps             | 9        |
|    time_elapsed    | 19725    |
|    total timesteps | 180093   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 248      |
|    ep_rew_mean     | -9.45    |
| time/              |          |
|    episodes        | 728      |
|    fps             | 9        |
|    time_elapsed    | 19850    |
|    total timesteps | 181097   |
| train/             |          |
|    actor_loss      | 2.22     |
|    critic_loss     | 1.5      |
|    learning_rate   | 0.000821 |
|    n_updates       | 180415   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 248      |
|    ep_rew_mean     | -9.43    |
| time/              |          |
|    episodes        | 732      |
|    fps             | 9        |
|    time_elapsed    | 19975    |
|    total timesteps | 182101   |
| train/             |          |
|    actor_loss      | 2.21     |
|    critic_loss     | 0.866    |
|    learning_rate   | 0.00082  |
|    n_updates       | 181419   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 248      |
|    ep_rew_mean     | -9.23    |
| time/              |          |
|    episodes        | 736      |
|    fps             | 9        |
|    time_elapsed    | 20100    |
|    total timesteps | 183105   |
| train/             |          |
|    actor_loss      | 2.22     |
|    critic_loss     | 1.08     |
|    learning_rate   | 0.000819 |
|    n_updates       | 182423   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 248      |
|    ep_rew_mean     | -9.6     |
| time/              |          |
|    episodes        | 740      |
|    fps             | 9        |
|    time_elapsed    | 20224    |
|    total timesteps | 184109   |
| train/             |          |
|    actor_loss      | 2.23     |
|    critic_loss     | 1.53     |
|    learning_rate   | 0.000818 |
|    n_updates       | 183427   |
---------------------------------
Eval num_timesteps=185000, episode_reward=2.19 +/- 2.90
Episode length: 251.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 251      |
|    mean_reward     | 2.19     |
| time/              |          |
|    total_timesteps | 185000   |
| train/             |          |
|    actor_loss      | 2.21     |
|    critic_loss     | 0.984    |
|    learning_rate   | 0.000817 |
|    n_updates       | 184431   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 248      |
|    ep_rew_mean     | -9.76    |
| time/              |          |
|    episodes        | 744      |
|    fps             | 9        |
|    time_elapsed    | 20369    |
|    total timesteps | 185113   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 248      |
|    ep_rew_mean     | -9.1     |
| time/              |          |
|    episodes        | 748      |
|    fps             | 9        |
|    time_elapsed    | 20494    |
|    total timesteps | 186117   |
| train/             |          |
|    actor_loss      | 2.22     |
|    critic_loss     | 1.19     |
|    learning_rate   | 0.000816 |
|    n_updates       | 185435   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 248      |
|    ep_rew_mean     | -9.48    |
| time/              |          |
|    episodes        | 752      |
|    fps             | 9        |
|    time_elapsed    | 20618    |
|    total timesteps | 187121   |
| train/             |          |
|    actor_loss      | 2.23     |
|    critic_loss     | 1.39     |
|    learning_rate   | 0.000815 |
|    n_updates       | 186439   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 248      |
|    ep_rew_mean     | -9.11    |
| time/              |          |
|    episodes        | 756      |
|    fps             | 9        |
|    time_elapsed    | 20743    |
|    total timesteps | 188125   |
| train/             |          |
|    actor_loss      | 2.23     |
|    critic_loss     | 1.14     |
|    learning_rate   | 0.000814 |
|    n_updates       | 187443   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 248      |
|    ep_rew_mean     | -8.5     |
| time/              |          |
|    episodes        | 760      |
|    fps             | 9        |
|    time_elapsed    | 20867    |
|    total timesteps | 189129   |
| train/             |          |
|    actor_loss      | 2.23     |
|    critic_loss     | 1.27     |
|    learning_rate   | 0.000813 |
|    n_updates       | 188447   |
---------------------------------
Eval num_timesteps=190000, episode_reward=3.55 +/- 4.03
Episode length: 251.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 251      |
|    mean_reward     | 3.55     |
| time/              |          |
|    total_timesteps | 190000   |
| train/             |          |
|    actor_loss      | 2.24     |
|    critic_loss     | 1.14     |
|    learning_rate   | 0.000812 |
|    n_updates       | 189451   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -8.99    |
| time/              |          |
|    episodes        | 764      |
|    fps             | 9        |
|    time_elapsed    | 21012    |
|    total timesteps | 190133   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -8.66    |
| time/              |          |
|    episodes        | 768      |
|    fps             | 9        |
|    time_elapsed    | 21136    |
|    total timesteps | 191137   |
| train/             |          |
|    actor_loss      | 2.25     |
|    critic_loss     | 1.42     |
|    learning_rate   | 0.000811 |
|    n_updates       | 190455   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -7.32    |
| time/              |          |
|    episodes        | 772      |
|    fps             | 9        |
|    time_elapsed    | 21260    |
|    total timesteps | 192141   |
| train/             |          |
|    actor_loss      | 2.23     |
|    critic_loss     | 1.05     |
|    learning_rate   | 0.00081  |
|    n_updates       | 191459   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -7.25    |
| time/              |          |
|    episodes        | 776      |
|    fps             | 9        |
|    time_elapsed    | 21386    |
|    total timesteps | 193145   |
| train/             |          |
|    actor_loss      | 2.25     |
|    critic_loss     | 1.45     |
|    learning_rate   | 0.000809 |
|    n_updates       | 192463   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -7.32    |
| time/              |          |
|    episodes        | 780      |
|    fps             | 9        |
|    time_elapsed    | 21510    |
|    total timesteps | 194149   |
| train/             |          |
|    actor_loss      | 2.28     |
|    critic_loss     | 1.48     |
|    learning_rate   | 0.000808 |
|    n_updates       | 193467   |
---------------------------------
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/xml/etree/ElementTree.py", line 789, in _get_writer
AttributeError: 'str' object has no attribute 'write'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "train.py", line 82, in <module>
  File "/home/shandilya/Desktop/Projects/NavigationController/learning/explore.py", line 208, in learn
  File "/home/shandilya/py36/lib/python3.6/site-packages/stable_baselines3/td3/td3.py", line 211, in learn
  File "/home/shandilya/py36/lib/python3.6/site-packages/stable_baselines3/common/off_policy_algorithm.py", line 359, in learn
  File "/home/shandilya/py36/lib/python3.6/site-packages/stable_baselines3/common/off_policy_algorithm.py", line 575, in collect_rollouts
  File "/home/shandilya/py36/lib/python3.6/site-packages/stable_baselines3/common/callbacks.py", line 88, in on_step
  File "/home/shandilya/py36/lib/python3.6/site-packages/stable_baselines3/common/callbacks.py", line 192, in _on_step
  File "/home/shandilya/py36/lib/python3.6/site-packages/stable_baselines3/common/callbacks.py", line 88, in on_step
  File "/home/shandilya/Desktop/Projects/NavigationController/utils/callbacks.py", line 317, in _on_step
  File "/home/shandilya/py36/lib/python3.6/site-packages/stable_baselines3/common/evaluation.py", line 86, in evaluate_policy
  File "/home/shandilya/py36/lib/python3.6/site-packages/stable_baselines3/common/vec_env/base_vec_env.py", line 162, in step
  File "/home/shandilya/py36/lib/python3.6/site-packages/stable_baselines3/common/vec_env/vec_transpose.py", line 83, in step_wait
  File "/home/shandilya/py36/lib/python3.6/site-packages/stable_baselines3/common/vec_env/dummy_vec_env.py", line 49, in step_wait
  File "/home/shandilya/py36/lib/python3.6/site-packages/stable_baselines3/common/monitor.py", line 79, in reset
  File "/home/shandilya/Desktop/Projects/NavigationController/simulations/maze_env.py", line 473, in reset
  File "/home/shandilya/Desktop/Projects/NavigationController/simulations/maze_env.py", line 220, in set_env
  File "/usr/local/lib/python3.6/xml/etree/ElementTree.py", line 759, in write
  File "/usr/local/lib/python3.6/contextlib.py", line 81, in __enter__
  File "/usr/local/lib/python3.6/xml/etree/ElementTree.py", line 796, in _get_writer
OSError: [Errno 24] Too many open files: '/tmp/tmpl7dwnlok.xml'
2021-12-16 12:47:18.528787: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/shandilya/.mujoco/mjpro150/bin
2021-12-16 12:47:18.528822: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
/home/shandilya/Desktop/Projects/NavigationController
Env Type: maze
Task: GoalRewardNoObstacle
Model: <class 'stable_baselines3.td3.td3.TD3'>
Using cpu device
Logging to assets/out/models/exp16/TD3_7
Terminated
2021-12-16 13:20:14.362251: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/shandilya/.mujoco/mjpro150/bin
2021-12-16 13:20:14.362284: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
/home/shandilya/Desktop/Projects/NavigationController
Env Type: maze
Task: GoalRewardNoObstacle
Model: <class 'stable_baselines3.td3.td3.TD3'>
Using cpu device
Logging to assets/out/models/exp16/TD3_8
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -11.6    |
| time/              |          |
|    episodes        | 4        |
|    fps             | 24       |
|    time_elapsed    | 41       |
|    total timesteps | 1004     |
| train/             |          |
|    actor_loss      | 0.0166   |
|    critic_loss     | 0.778    |
|    learning_rate   | 0.000999 |
|    n_updates       | 502      |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -7.61    |
| time/              |          |
|    episodes        | 8        |
|    fps             | 17       |
|    time_elapsed    | 112      |
|    total timesteps | 2008     |
| train/             |          |
|    actor_loss      | 0.226    |
|    critic_loss     | 1.36     |
|    learning_rate   | 0.000998 |
|    n_updates       | 1506     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -8.79    |
| time/              |          |
|    episodes        | 12       |
|    fps             | 16       |
|    time_elapsed    | 187      |
|    total timesteps | 3012     |
| train/             |          |
|    actor_loss      | 0.298    |
|    critic_loss     | 0.92     |
|    learning_rate   | 0.000997 |
|    n_updates       | 2510     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -9.44    |
| time/              |          |
|    episodes        | 16       |
|    fps             | 15       |
|    time_elapsed    | 260      |
|    total timesteps | 4016     |
| train/             |          |
|    actor_loss      | 0.375    |
|    critic_loss     | 1.16     |
|    learning_rate   | 0.000996 |
|    n_updates       | 3514     |
---------------------------------
Eval num_timesteps=5000, episode_reward=-30.93 +/- 19.82
Episode length: 251.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 251      |
|    mean_reward     | -30.9    |
| time/              |          |
|    total_timesteps | 5000     |
| train/             |          |
|    actor_loss      | 0.429    |
|    critic_loss     | 1.21     |
|    learning_rate   | 0.000995 |
|    n_updates       | 4518     |
---------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -9.85    |
| time/              |          |
|    episodes        | 20       |
|    fps             | 14       |
|    time_elapsed    | 354      |
|    total timesteps | 5020     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -10.6    |
| time/              |          |
|    episodes        | 24       |
|    fps             | 14       |
|    time_elapsed    | 428      |
|    total timesteps | 6024     |
| train/             |          |
|    actor_loss      | 0.505    |
|    critic_loss     | 1.57     |
|    learning_rate   | 0.000994 |
|    n_updates       | 5522     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -10.7    |
| time/              |          |
|    episodes        | 28       |
|    fps             | 13       |
|    time_elapsed    | 502      |
|    total timesteps | 7028     |
| train/             |          |
|    actor_loss      | 0.58     |
|    critic_loss     | 1.22     |
|    learning_rate   | 0.000993 |
|    n_updates       | 6526     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -12.9    |
| time/              |          |
|    episodes        | 32       |
|    fps             | 13       |
|    time_elapsed    | 576      |
|    total timesteps | 8032     |
| train/             |          |
|    actor_loss      | 0.692    |
|    critic_loss     | 1.82     |
|    learning_rate   | 0.000992 |
|    n_updates       | 7530     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -12.4    |
| time/              |          |
|    episodes        | 36       |
|    fps             | 13       |
|    time_elapsed    | 650      |
|    total timesteps | 9036     |
| train/             |          |
|    actor_loss      | 0.808    |
|    critic_loss     | 1.71     |
|    learning_rate   | 0.000991 |
|    n_updates       | 8534     |
---------------------------------
Eval num_timesteps=10000, episode_reward=-22.18 +/- 13.17
Episode length: 251.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 251      |
|    mean_reward     | -22.2    |
| time/              |          |
|    total_timesteps | 10000    |
| train/             |          |
|    actor_loss      | 0.889    |
|    critic_loss     | 1.76     |
|    learning_rate   | 0.00099  |
|    n_updates       | 9538     |
---------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -11.8    |
| time/              |          |
|    episodes        | 40       |
|    fps             | 13       |
|    time_elapsed    | 745      |
|    total timesteps | 10040    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -10.9    |
| time/              |          |
|    episodes        | 44       |
|    fps             | 13       |
|    time_elapsed    | 820      |
|    total timesteps | 11044    |
| train/             |          |
|    actor_loss      | 0.942    |
|    critic_loss     | 1.48     |
|    learning_rate   | 0.000989 |
|    n_updates       | 10542    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -10.8    |
| time/              |          |
|    episodes        | 48       |
|    fps             | 13       |
|    time_elapsed    | 895      |
|    total timesteps | 12048    |
| train/             |          |
|    actor_loss      | 1.01     |
|    critic_loss     | 1.16     |
|    learning_rate   | 0.000988 |
|    n_updates       | 11546    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -12.2    |
| time/              |          |
|    episodes        | 52       |
|    fps             | 13       |
|    time_elapsed    | 969      |
|    total timesteps | 13052    |
| train/             |          |
|    actor_loss      | 1.12     |
|    critic_loss     | 1.62     |
|    learning_rate   | 0.000987 |
|    n_updates       | 12550    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -12.8    |
| time/              |          |
|    episodes        | 56       |
|    fps             | 13       |
|    time_elapsed    | 1043     |
|    total timesteps | 14056    |
| train/             |          |
|    actor_loss      | 1.16     |
|    critic_loss     | 1.31     |
|    learning_rate   | 0.000986 |
|    n_updates       | 13554    |
---------------------------------
Eval num_timesteps=15000, episode_reward=-44.86 +/- 11.93
Episode length: 251.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 251      |
|    mean_reward     | -44.9    |
| time/              |          |
|    total_timesteps | 15000    |
| train/             |          |
|    actor_loss      | 1.25     |
|    critic_loss     | 1.42     |
|    learning_rate   | 0.000985 |
|    n_updates       | 14558    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -12.6    |
| time/              |          |
|    episodes        | 60       |
|    fps             | 13       |
|    time_elapsed    | 1136     |
|    total timesteps | 15060    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -12.8    |
| time/              |          |
|    episodes        | 64       |
|    fps             | 13       |
|    time_elapsed    | 1211     |
|    total timesteps | 16064    |
| train/             |          |
|    actor_loss      | 1.33     |
|    critic_loss     | 1.52     |
|    learning_rate   | 0.000984 |
|    n_updates       | 15562    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -13.7    |
| time/              |          |
|    episodes        | 68       |
|    fps             | 13       |
|    time_elapsed    | 1285     |
|    total timesteps | 17068    |
| train/             |          |
|    actor_loss      | 1.42     |
|    critic_loss     | 1.67     |
|    learning_rate   | 0.000983 |
|    n_updates       | 16566    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -12.6    |
| time/              |          |
|    episodes        | 72       |
|    fps             | 13       |
|    time_elapsed    | 1359     |
|    total timesteps | 18072    |
| train/             |          |
|    actor_loss      | 1.45     |
|    critic_loss     | 1.28     |
|    learning_rate   | 0.000982 |
|    n_updates       | 17570    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -12.2    |
| time/              |          |
|    episodes        | 76       |
|    fps             | 13       |
|    time_elapsed    | 1433     |
|    total timesteps | 19076    |
| train/             |          |
|    actor_loss      | 1.53     |
|    critic_loss     | 1.78     |
|    learning_rate   | 0.000981 |
|    n_updates       | 18574    |
---------------------------------
Eval num_timesteps=20000, episode_reward=-28.71 +/- 15.39
Episode length: 251.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 251      |
|    mean_reward     | -28.7    |
| time/              |          |
|    total_timesteps | 20000    |
| train/             |          |
|    actor_loss      | 1.57     |
|    critic_loss     | 1.35     |
|    learning_rate   | 0.00098  |
|    n_updates       | 19578    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -13.3    |
| time/              |          |
|    episodes        | 80       |
|    fps             | 13       |
|    time_elapsed    | 1526     |
|    total timesteps | 20080    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -12.8    |
| time/              |          |
|    episodes        | 84       |
|    fps             | 13       |
|    time_elapsed    | 1601     |
|    total timesteps | 21084    |
| train/             |          |
|    actor_loss      | 1.62     |
|    critic_loss     | 1.54     |
|    learning_rate   | 0.000979 |
|    n_updates       | 20582    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -12.9    |
| time/              |          |
|    episodes        | 88       |
|    fps             | 13       |
|    time_elapsed    | 1676     |
|    total timesteps | 22088    |
| train/             |          |
|    actor_loss      | 1.67     |
|    critic_loss     | 1.37     |
|    learning_rate   | 0.000978 |
|    n_updates       | 21586    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -13.4    |
| time/              |          |
|    episodes        | 92       |
|    fps             | 13       |
|    time_elapsed    | 1749     |
|    total timesteps | 23092    |
| train/             |          |
|    actor_loss      | 1.7      |
|    critic_loss     | 0.942    |
|    learning_rate   | 0.000977 |
|    n_updates       | 22590    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -13.5    |
| time/              |          |
|    episodes        | 96       |
|    fps             | 13       |
|    time_elapsed    | 1824     |
|    total timesteps | 24096    |
| train/             |          |
|    actor_loss      | 1.76     |
|    critic_loss     | 1.27     |
|    learning_rate   | 0.000976 |
|    n_updates       | 23594    |
---------------------------------
Eval num_timesteps=25000, episode_reward=-23.67 +/- 12.81
Episode length: 251.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 251      |
|    mean_reward     | -23.7    |
| time/              |          |
|    total_timesteps | 25000    |
| train/             |          |
|    actor_loss      | 1.87     |
|    critic_loss     | 1.94     |
|    learning_rate   | 0.000975 |
|    n_updates       | 24598    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -13.4    |
| time/              |          |
|    episodes        | 100      |
|    fps             | 13       |
|    time_elapsed    | 1918     |
|    total timesteps | 25100    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -13.6    |
| time/              |          |
|    episodes        | 104      |
|    fps             | 13       |
|    time_elapsed    | 1993     |
|    total timesteps | 26104    |
| train/             |          |
|    actor_loss      | 1.93     |
|    critic_loss     | 1.63     |
|    learning_rate   | 0.000974 |
|    n_updates       | 25602    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -13.5    |
| time/              |          |
|    episodes        | 108      |
|    fps             | 13       |
|    time_elapsed    | 2067     |
|    total timesteps | 27108    |
| train/             |          |
|    actor_loss      | 1.98     |
|    critic_loss     | 1.47     |
|    learning_rate   | 0.000973 |
|    n_updates       | 26606    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -13.3    |
| time/              |          |
|    episodes        | 112      |
|    fps             | 13       |
|    time_elapsed    | 2143     |
|    total timesteps | 28112    |
| train/             |          |
|    actor_loss      | 2.05     |
|    critic_loss     | 1.49     |
|    learning_rate   | 0.000972 |
|    n_updates       | 27610    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -12.8    |
| time/              |          |
|    episodes        | 116      |
|    fps             | 13       |
|    time_elapsed    | 2219     |
|    total timesteps | 29116    |
| train/             |          |
|    actor_loss      | 2.13     |
|    critic_loss     | 1.48     |
|    learning_rate   | 0.000971 |
|    n_updates       | 28614    |
---------------------------------
Eval num_timesteps=30000, episode_reward=-21.25 +/- 12.80
Episode length: 251.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 251      |
|    mean_reward     | -21.2    |
| time/              |          |
|    total_timesteps | 30000    |
| train/             |          |
|    actor_loss      | 2.18     |
|    critic_loss     | 1.66     |
|    learning_rate   | 0.00097  |
|    n_updates       | 29618    |
---------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -12.8    |
| time/              |          |
|    episodes        | 120      |
|    fps             | 13       |
|    time_elapsed    | 2314     |
|    total timesteps | 30120    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -13.2    |
| time/              |          |
|    episodes        | 124      |
|    fps             | 13       |
|    time_elapsed    | 2389     |
|    total timesteps | 31124    |
| train/             |          |
|    actor_loss      | 2.19     |
|    critic_loss     | 1.15     |
|    learning_rate   | 0.000969 |
|    n_updates       | 30622    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -12.6    |
| time/              |          |
|    episodes        | 128      |
|    fps             | 13       |
|    time_elapsed    | 2463     |
|    total timesteps | 32128    |
| train/             |          |
|    actor_loss      | 2.27     |
|    critic_loss     | 1.7      |
|    learning_rate   | 0.000968 |
|    n_updates       | 31626    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -11.1    |
| time/              |          |
|    episodes        | 132      |
|    fps             | 13       |
|    time_elapsed    | 2539     |
|    total timesteps | 33132    |
| train/             |          |
|    actor_loss      | 2.32     |
|    critic_loss     | 2.09     |
|    learning_rate   | 0.000967 |
|    n_updates       | 32630    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -11.4    |
| time/              |          |
|    episodes        | 136      |
|    fps             | 13       |
|    time_elapsed    | 2613     |
|    total timesteps | 34136    |
| train/             |          |
|    actor_loss      | 2.32     |
|    critic_loss     | 1.48     |
|    learning_rate   | 0.000966 |
|    n_updates       | 33634    |
---------------------------------
Eval num_timesteps=35000, episode_reward=-35.83 +/- 18.13
Episode length: 251.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 251      |
|    mean_reward     | -35.8    |
| time/              |          |
|    total_timesteps | 35000    |
| train/             |          |
|    actor_loss      | 2.32     |
|    critic_loss     | 1        |
|    learning_rate   | 0.000965 |
|    n_updates       | 34638    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -11.8    |
| time/              |          |
|    episodes        | 140      |
|    fps             | 12       |
|    time_elapsed    | 2708     |
|    total timesteps | 35140    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -12.6    |
| time/              |          |
|    episodes        | 144      |
|    fps             | 12       |
|    time_elapsed    | 2783     |
|    total timesteps | 36144    |
| train/             |          |
|    actor_loss      | 2.35     |
|    critic_loss     | 1.04     |
|    learning_rate   | 0.000964 |
|    n_updates       | 35642    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -12      |
| time/              |          |
|    episodes        | 148      |
|    fps             | 12       |
|    time_elapsed    | 2857     |
|    total timesteps | 37103    |
| train/             |          |
|    actor_loss      | 2.38     |
|    critic_loss     | 1.4      |
|    learning_rate   | 0.000964 |
|    n_updates       | 36601    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -10.7    |
| time/              |          |
|    episodes        | 152      |
|    fps             | 12       |
|    time_elapsed    | 2933     |
|    total timesteps | 38107    |
| train/             |          |
|    actor_loss      | 2.42     |
|    critic_loss     | 1.36     |
|    learning_rate   | 0.000963 |
|    n_updates       | 37605    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -10.2    |
| time/              |          |
|    episodes        | 156      |
|    fps             | 12       |
|    time_elapsed    | 3009     |
|    total timesteps | 39111    |
| train/             |          |
|    actor_loss      | 2.46     |
|    critic_loss     | 1.34     |
|    learning_rate   | 0.000962 |
|    n_updates       | 38609    |
---------------------------------
Eval num_timesteps=40000, episode_reward=-26.08 +/- 14.37
Episode length: 251.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 251      |
|    mean_reward     | -26.1    |
| time/              |          |
|    total_timesteps | 40000    |
| train/             |          |
|    actor_loss      | 2.51     |
|    critic_loss     | 1.84     |
|    learning_rate   | 0.000961 |
|    n_updates       | 39613    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -10      |
| time/              |          |
|    episodes        | 160      |
|    fps             | 12       |
|    time_elapsed    | 3106     |
|    total timesteps | 40115    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -10.6    |
| time/              |          |
|    episodes        | 164      |
|    fps             | 12       |
|    time_elapsed    | 3184     |
|    total timesteps | 41119    |
| train/             |          |
|    actor_loss      | 2.52     |
|    critic_loss     | 1.52     |
|    learning_rate   | 0.00096  |
|    n_updates       | 40617    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -9.98    |
| time/              |          |
|    episodes        | 168      |
|    fps             | 12       |
|    time_elapsed    | 3262     |
|    total timesteps | 42123    |
| train/             |          |
|    actor_loss      | 2.53     |
|    critic_loss     | 1.34     |
|    learning_rate   | 0.000959 |
|    n_updates       | 41621    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -10.7    |
| time/              |          |
|    episodes        | 172      |
|    fps             | 12       |
|    time_elapsed    | 3341     |
|    total timesteps | 43127    |
| train/             |          |
|    actor_loss      | 2.6      |
|    critic_loss     | 1.78     |
|    learning_rate   | 0.000958 |
|    n_updates       | 42625    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -11.1    |
| time/              |          |
|    episodes        | 176      |
|    fps             | 12       |
|    time_elapsed    | 3420     |
|    total timesteps | 44131    |
| train/             |          |
|    actor_loss      | 2.62     |
|    critic_loss     | 1.64     |
|    learning_rate   | 0.000957 |
|    n_updates       | 43629    |
---------------------------------
Eval num_timesteps=45000, episode_reward=-34.22 +/- 15.67
Episode length: 251.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 251      |
|    mean_reward     | -34.2    |
| time/              |          |
|    total_timesteps | 45000    |
| train/             |          |
|    actor_loss      | 2.68     |
|    critic_loss     | 2.24     |
|    learning_rate   | 0.000956 |
|    n_updates       | 44633    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -10.6    |
| time/              |          |
|    episodes        | 180      |
|    fps             | 12       |
|    time_elapsed    | 3519     |
|    total timesteps | 45135    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -11.5    |
| time/              |          |
|    episodes        | 184      |
|    fps             | 12       |
|    time_elapsed    | 3599     |
|    total timesteps | 46139    |
| train/             |          |
|    actor_loss      | 2.69     |
|    critic_loss     | 1.71     |
|    learning_rate   | 0.000955 |
|    n_updates       | 45637    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -11.3    |
| time/              |          |
|    episodes        | 188      |
|    fps             | 12       |
|    time_elapsed    | 3679     |
|    total timesteps | 47143    |
| train/             |          |
|    actor_loss      | 2.68     |
|    critic_loss     | 1.2      |
|    learning_rate   | 0.000954 |
|    n_updates       | 46641    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -11.3    |
| time/              |          |
|    episodes        | 192      |
|    fps             | 12       |
|    time_elapsed    | 3759     |
|    total timesteps | 48147    |
| train/             |          |
|    actor_loss      | 2.71     |
|    critic_loss     | 1.86     |
|    learning_rate   | 0.000953 |
|    n_updates       | 47645    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -11.5    |
| time/              |          |
|    episodes        | 196      |
|    fps             | 12       |
|    time_elapsed    | 3841     |
|    total timesteps | 49151    |
| train/             |          |
|    actor_loss      | 2.75     |
|    critic_loss     | 2.03     |
|    learning_rate   | 0.000952 |
|    n_updates       | 48649    |
---------------------------------
Eval num_timesteps=50000, episode_reward=-33.90 +/- 26.92
Episode length: 251.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 251      |
|    mean_reward     | -33.9    |
| time/              |          |
|    total_timesteps | 50000    |
| train/             |          |
|    actor_loss      | 2.78     |
|    critic_loss     | 1.52     |
|    learning_rate   | 0.000951 |
|    n_updates       | 49653    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -11.4    |
| time/              |          |
|    episodes        | 200      |
|    fps             | 12       |
|    time_elapsed    | 3941     |
|    total timesteps | 50155    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -11.8    |
| time/              |          |
|    episodes        | 204      |
|    fps             | 12       |
|    time_elapsed    | 4022     |
|    total timesteps | 51159    |
| train/             |          |
|    actor_loss      | 2.79     |
|    critic_loss     | 1.35     |
|    learning_rate   | 0.00095  |
|    n_updates       | 50657    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -12      |
| time/              |          |
|    episodes        | 208      |
|    fps             | 12       |
|    time_elapsed    | 4103     |
|    total timesteps | 52163    |
| train/             |          |
|    actor_loss      | 2.8      |
|    critic_loss     | 1.64     |
|    learning_rate   | 0.000949 |
|    n_updates       | 51661    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -12      |
| time/              |          |
|    episodes        | 212      |
|    fps             | 12       |
|    time_elapsed    | 4185     |
|    total timesteps | 53167    |
| train/             |          |
|    actor_loss      | 2.85     |
|    critic_loss     | 1.35     |
|    learning_rate   | 0.000948 |
|    n_updates       | 52665    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -12.8    |
| time/              |          |
|    episodes        | 216      |
|    fps             | 12       |
|    time_elapsed    | 4267     |
|    total timesteps | 54171    |
| train/             |          |
|    actor_loss      | 2.83     |
|    critic_loss     | 1.36     |
|    learning_rate   | 0.000947 |
|    n_updates       | 53669    |
---------------------------------
Eval num_timesteps=55000, episode_reward=-20.22 +/- 19.77
Episode length: 251.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 251      |
|    mean_reward     | -20.2    |
| time/              |          |
|    total_timesteps | 55000    |
| train/             |          |
|    actor_loss      | 2.86     |
|    critic_loss     | 1.25     |
|    learning_rate   | 0.000946 |
|    n_updates       | 54673    |
---------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -12.6    |
| time/              |          |
|    episodes        | 220      |
|    fps             | 12       |
|    time_elapsed    | 4370     |
|    total timesteps | 55175    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -11.4    |
| time/              |          |
|    episodes        | 224      |
|    fps             | 12       |
|    time_elapsed    | 4453     |
|    total timesteps | 56179    |
| train/             |          |
|    actor_loss      | 2.89     |
|    critic_loss     | 1        |
|    learning_rate   | 0.000945 |
|    n_updates       | 55677    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -11.5    |
| time/              |          |
|    episodes        | 228      |
|    fps             | 12       |
|    time_elapsed    | 4536     |
|    total timesteps | 57183    |
| train/             |          |
|    actor_loss      | 2.94     |
|    critic_loss     | 1.54     |
|    learning_rate   | 0.000944 |
|    n_updates       | 56681    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -13.4    |
| time/              |          |
|    episodes        | 232      |
|    fps             | 12       |
|    time_elapsed    | 4621     |
|    total timesteps | 58187    |
| train/             |          |
|    actor_loss      | 2.96     |
|    critic_loss     | 1.5      |
|    learning_rate   | 0.000943 |
|    n_updates       | 57685    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -12.3    |
| time/              |          |
|    episodes        | 236      |
|    fps             | 12       |
|    time_elapsed    | 4707     |
|    total timesteps | 59191    |
| train/             |          |
|    actor_loss      | 2.99     |
|    critic_loss     | 1.64     |
|    learning_rate   | 0.000942 |
|    n_updates       | 58689    |
---------------------------------
Eval num_timesteps=60000, episode_reward=-19.21 +/- 25.51
Episode length: 251.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 251      |
|    mean_reward     | -19.2    |
| time/              |          |
|    total_timesteps | 60000    |
| train/             |          |
|    actor_loss      | 2.98     |
|    critic_loss     | 1.14     |
|    learning_rate   | 0.000941 |
|    n_updates       | 59693    |
---------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -11.3    |
| time/              |          |
|    episodes        | 240      |
|    fps             | 12       |
|    time_elapsed    | 4814     |
|    total timesteps | 60195    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -10.8    |
| time/              |          |
|    episodes        | 244      |
|    fps             | 12       |
|    time_elapsed    | 4901     |
|    total timesteps | 61199    |
| train/             |          |
|    actor_loss      | 2.99     |
|    critic_loss     | 1.12     |
|    learning_rate   | 0.00094  |
|    n_updates       | 60697    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -12.4    |
| time/              |          |
|    episodes        | 248      |
|    fps             | 12       |
|    time_elapsed    | 4989     |
|    total timesteps | 62203    |
| train/             |          |
|    actor_loss      | 3.05     |
|    critic_loss     | 1.76     |
|    learning_rate   | 0.000939 |
|    n_updates       | 61701    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -12.9    |
| time/              |          |
|    episodes        | 252      |
|    fps             | 12       |
|    time_elapsed    | 5076     |
|    total timesteps | 63191    |
| train/             |          |
|    actor_loss      | 3.04     |
|    critic_loss     | 1.43     |
|    learning_rate   | 0.000938 |
|    n_updates       | 62689    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -13.9    |
| time/              |          |
|    episodes        | 256      |
|    fps             | 12       |
|    time_elapsed    | 5167     |
|    total timesteps | 64195    |
| train/             |          |
|    actor_loss      | 3.05     |
|    critic_loss     | 1.52     |
|    learning_rate   | 0.000937 |
|    n_updates       | 63693    |
---------------------------------
Eval num_timesteps=65000, episode_reward=-19.89 +/- 12.24
Episode length: 251.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 251      |
|    mean_reward     | -19.9    |
| time/              |          |
|    total_timesteps | 65000    |
| train/             |          |
|    actor_loss      | 3.06     |
|    critic_loss     | 1.38     |
|    learning_rate   | 0.000936 |
|    n_updates       | 64697    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -15      |
| time/              |          |
|    episodes        | 260      |
|    fps             | 12       |
|    time_elapsed    | 5278     |
|    total timesteps | 65199    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -14.1    |
| time/              |          |
|    episodes        | 264      |
|    fps             | 12       |
|    time_elapsed    | 5374     |
|    total timesteps | 66203    |
| train/             |          |
|    actor_loss      | 3.1      |
|    critic_loss     | 1.46     |
|    learning_rate   | 0.000935 |
|    n_updates       | 65701    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -14      |
| time/              |          |
|    episodes        | 268      |
|    fps             | 12       |
|    time_elapsed    | 5469     |
|    total timesteps | 67207    |
| train/             |          |
|    actor_loss      | 3.14     |
|    critic_loss     | 2.19     |
|    learning_rate   | 0.000934 |
|    n_updates       | 66705    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -14.6    |
| time/              |          |
|    episodes        | 272      |
|    fps             | 12       |
|    time_elapsed    | 5564     |
|    total timesteps | 68211    |
| train/             |          |
|    actor_loss      | 3.14     |
|    critic_loss     | 1.63     |
|    learning_rate   | 0.000933 |
|    n_updates       | 67709    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -14.6    |
| time/              |          |
|    episodes        | 276      |
|    fps             | 12       |
|    time_elapsed    | 5661     |
|    total timesteps | 69215    |
| train/             |          |
|    actor_loss      | 3.18     |
|    critic_loss     | 1.82     |
|    learning_rate   | 0.000932 |
|    n_updates       | 68713    |
---------------------------------
Eval num_timesteps=70000, episode_reward=-25.21 +/- 12.51
Episode length: 251.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 251      |
|    mean_reward     | -25.2    |
| time/              |          |
|    total_timesteps | 70000    |
| train/             |          |
|    actor_loss      | 3.15     |
|    critic_loss     | 1.26     |
|    learning_rate   | 0.000931 |
|    n_updates       | 69717    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -14.2    |
| time/              |          |
|    episodes        | 280      |
|    fps             | 12       |
|    time_elapsed    | 5779     |
|    total timesteps | 70219    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -13.6    |
| time/              |          |
|    episodes        | 284      |
|    fps             | 12       |
|    time_elapsed    | 5876     |
|    total timesteps | 71223    |
| train/             |          |
|    actor_loss      | 3.18     |
|    critic_loss     | 1.21     |
|    learning_rate   | 0.00093  |
|    n_updates       | 70721    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -13.7    |
| time/              |          |
|    episodes        | 288      |
|    fps             | 12       |
|    time_elapsed    | 5973     |
|    total timesteps | 72227    |
| train/             |          |
|    actor_loss      | 3.19     |
|    critic_loss     | 1.5      |
|    learning_rate   | 0.000929 |
|    n_updates       | 71725    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -13.8    |
| time/              |          |
|    episodes        | 292      |
|    fps             | 12       |
|    time_elapsed    | 6071     |
|    total timesteps | 73231    |
| train/             |          |
|    actor_loss      | 3.23     |
|    critic_loss     | 1.48     |
|    learning_rate   | 0.000928 |
|    n_updates       | 72729    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -12.9    |
| time/              |          |
|    episodes        | 296      |
|    fps             | 12       |
|    time_elapsed    | 6168     |
|    total timesteps | 74161    |
| train/             |          |
|    actor_loss      | 3.27     |
|    critic_loss     | 1.76     |
|    learning_rate   | 0.000927 |
|    n_updates       | 73733    |
---------------------------------
Eval num_timesteps=75000, episode_reward=-26.17 +/- 12.10
Episode length: 251.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 251      |
|    mean_reward     | -26.2    |
| time/              |          |
|    total_timesteps | 75000    |
| train/             |          |
|    actor_loss      | 3.3      |
|    critic_loss     | 2.21     |
|    learning_rate   | 0.000926 |
|    n_updates       | 74663    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -13.6    |
| time/              |          |
|    episodes        | 300      |
|    fps             | 11       |
|    time_elapsed    | 6279     |
|    total timesteps | 75165    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -12.3    |
| time/              |          |
|    episodes        | 304      |
|    fps             | 11       |
|    time_elapsed    | 6372     |
|    total timesteps | 76103    |
| train/             |          |
|    actor_loss      | 3.3      |
|    critic_loss     | 1.72     |
|    learning_rate   | 0.000925 |
|    n_updates       | 75601    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -12.1    |
| time/              |          |
|    episodes        | 308      |
|    fps             | 11       |
|    time_elapsed    | 6471     |
|    total timesteps | 77107    |
| train/             |          |
|    actor_loss      | 3.28     |
|    critic_loss     | 1.34     |
|    learning_rate   | 0.000924 |
|    n_updates       | 76605    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -13.1    |
| time/              |          |
|    episodes        | 312      |
|    fps             | 11       |
|    time_elapsed    | 6570     |
|    total timesteps | 78111    |
| train/             |          |
|    actor_loss      | 3.29     |
|    critic_loss     | 1.31     |
|    learning_rate   | 0.000923 |
|    n_updates       | 77609    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -13.3    |
| time/              |          |
|    episodes        | 316      |
|    fps             | 11       |
|    time_elapsed    | 6669     |
|    total timesteps | 79115    |
| train/             |          |
|    actor_loss      | 3.31     |
|    critic_loss     | 1.2      |
|    learning_rate   | 0.000922 |
|    n_updates       | 78613    |
---------------------------------
Eval num_timesteps=80000, episode_reward=-26.55 +/- 5.67
Episode length: 251.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 251      |
|    mean_reward     | -26.5    |
| time/              |          |
|    total_timesteps | 80000    |
| train/             |          |
|    actor_loss      | 3.33     |
|    critic_loss     | 1.74     |
|    learning_rate   | 0.000921 |
|    n_updates       | 79564    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -13.6    |
| time/              |          |
|    episodes        | 320      |
|    fps             | 11       |
|    time_elapsed    | 6783     |
|    total timesteps | 80066    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -14.1    |
| time/              |          |
|    episodes        | 324      |
|    fps             | 11       |
|    time_elapsed    | 6883     |
|    total timesteps | 81070    |
| train/             |          |
|    actor_loss      | 3.31     |
|    critic_loss     | 1.64     |
|    learning_rate   | 0.00092  |
|    n_updates       | 80568    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -14.4    |
| time/              |          |
|    episodes        | 328      |
|    fps             | 11       |
|    time_elapsed    | 6983     |
|    total timesteps | 82074    |
| train/             |          |
|    actor_loss      | 3.35     |
|    critic_loss     | 1.87     |
|    learning_rate   | 0.000919 |
|    n_updates       | 81572    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -12.6    |
| time/              |          |
|    episodes        | 332      |
|    fps             | 11       |
|    time_elapsed    | 7082     |
|    total timesteps | 83078    |
| train/             |          |
|    actor_loss      | 3.37     |
|    critic_loss     | 1.63     |
|    learning_rate   | 0.000918 |
|    n_updates       | 82576    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -14.1    |
| time/              |          |
|    episodes        | 336      |
|    fps             | 11       |
|    time_elapsed    | 7185     |
|    total timesteps | 84082    |
| train/             |          |
|    actor_loss      | 3.39     |
|    critic_loss     | 2.08     |
|    learning_rate   | 0.000917 |
|    n_updates       | 83580    |
---------------------------------
Eval num_timesteps=85000, episode_reward=-24.38 +/- 5.97
Episode length: 251.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 251      |
|    mean_reward     | -24.4    |
| time/              |          |
|    total_timesteps | 85000    |
| train/             |          |
|    actor_loss      | 3.39     |
|    critic_loss     | 1.78     |
|    learning_rate   | 0.000916 |
|    n_updates       | 84584    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -15.2    |
| time/              |          |
|    episodes        | 340      |
|    fps             | 11       |
|    time_elapsed    | 7305     |
|    total timesteps | 85086    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -15.6    |
| time/              |          |
|    episodes        | 344      |
|    fps             | 11       |
|    time_elapsed    | 7405     |
|    total timesteps | 86090    |
| train/             |          |
|    actor_loss      | 3.42     |
|    critic_loss     | 1.75     |
|    learning_rate   | 0.000915 |
|    n_updates       | 85588    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -15.5    |
| time/              |          |
|    episodes        | 348      |
|    fps             | 11       |
|    time_elapsed    | 7505     |
|    total timesteps | 87094    |
| train/             |          |
|    actor_loss      | 3.42     |
|    critic_loss     | 1.78     |
|    learning_rate   | 0.000914 |
|    n_updates       | 86592    |
---------------------------------
Terminated
2021-12-16 15:33:05.392618: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/shandilya/.mujoco/mjpro150/bin
2021-12-16 15:33:05.392668: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
/home/shandilya/Desktop/Projects/NavigationController
Env Type: maze
Task: GoalRewardNoObstacle
Model: <class 'stable_baselines3.td3.td3.TD3'>
Using cpu device
Logging to assets/out/models/exp16/TD3_9
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | 0.0329   |
| time/              |          |
|    episodes        | 4        |
|    fps             | 23       |
|    time_elapsed    | 43       |
|    total timesteps | 1004     |
| train/             |          |
|    actor_loss      | -0.04    |
|    critic_loss     | 0.765    |
|    learning_rate   | 0.000999 |
|    n_updates       | 502      |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -1.73    |
| time/              |          |
|    episodes        | 8        |
|    fps             | 16       |
|    time_elapsed    | 119      |
|    total timesteps | 2008     |
| train/             |          |
|    actor_loss      | 0.00689  |
|    critic_loss     | 1.2      |
|    learning_rate   | 0.000998 |
|    n_updates       | 1506     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -4.35    |
| time/              |          |
|    episodes        | 12       |
|    fps             | 15       |
|    time_elapsed    | 196      |
|    total timesteps | 3012     |
| train/             |          |
|    actor_loss      | 0.0256   |
|    critic_loss     | 0.913    |
|    learning_rate   | 0.000997 |
|    n_updates       | 2510     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -1.58    |
| time/              |          |
|    episodes        | 16       |
|    fps             | 14       |
|    time_elapsed    | 271      |
|    total timesteps | 4016     |
| train/             |          |
|    actor_loss      | 0.0623   |
|    critic_loss     | 0.705    |
|    learning_rate   | 0.000996 |
|    n_updates       | 3514     |
---------------------------------
Eval num_timesteps=5000, episode_reward=10.64 +/- 0.98
Episode length: 251.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 251      |
|    mean_reward     | 10.6     |
| time/              |          |
|    total_timesteps | 5000     |
| train/             |          |
|    actor_loss      | 0.112    |
|    critic_loss     | 1        |
|    learning_rate   | 0.000995 |
|    n_updates       | 4518     |
---------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -8.08    |
| time/              |          |
|    episodes        | 20       |
|    fps             | 13       |
|    time_elapsed    | 369      |
|    total timesteps | 5020     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -7.49    |
| time/              |          |
|    episodes        | 24       |
|    fps             | 13       |
|    time_elapsed    | 446      |
|    total timesteps | 6024     |
| train/             |          |
|    actor_loss      | 0.185    |
|    critic_loss     | 0.955    |
|    learning_rate   | 0.000994 |
|    n_updates       | 5522     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -9.15    |
| time/              |          |
|    episodes        | 28       |
|    fps             | 13       |
|    time_elapsed    | 523      |
|    total timesteps | 7028     |
| train/             |          |
|    actor_loss      | 0.232    |
|    critic_loss     | 0.705    |
|    learning_rate   | 0.000993 |
|    n_updates       | 6526     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -8.8     |
| time/              |          |
|    episodes        | 32       |
|    fps             | 13       |
|    time_elapsed    | 600      |
|    total timesteps | 8032     |
| train/             |          |
|    actor_loss      | 0.286    |
|    critic_loss     | 1.2      |
|    learning_rate   | 0.000992 |
|    n_updates       | 7530     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -7.9     |
| time/              |          |
|    episodes        | 36       |
|    fps             | 13       |
|    time_elapsed    | 677      |
|    total timesteps | 9036     |
| train/             |          |
|    actor_loss      | 0.34     |
|    critic_loss     | 1.1      |
|    learning_rate   | 0.000991 |
|    n_updates       | 8534     |
---------------------------------
Eval num_timesteps=10000, episode_reward=10.41 +/- 1.83
Episode length: 251.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 251      |
|    mean_reward     | 10.4     |
| time/              |          |
|    total_timesteps | 10000    |
| train/             |          |
|    actor_loss      | 0.433    |
|    critic_loss     | 1.7      |
|    learning_rate   | 0.00099  |
|    n_updates       | 9538     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -7.24    |
| time/              |          |
|    episodes        | 40       |
|    fps             | 12       |
|    time_elapsed    | 774      |
|    total timesteps | 10040    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -6.55    |
| time/              |          |
|    episodes        | 44       |
|    fps             | 12       |
|    time_elapsed    | 851      |
|    total timesteps | 11044    |
| train/             |          |
|    actor_loss      | 0.46     |
|    critic_loss     | 1.06     |
|    learning_rate   | 0.000989 |
|    n_updates       | 10542    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -5.34    |
| time/              |          |
|    episodes        | 48       |
|    fps             | 12       |
|    time_elapsed    | 928      |
|    total timesteps | 12048    |
| train/             |          |
|    actor_loss      | 0.522    |
|    critic_loss     | 1.25     |
|    learning_rate   | 0.000988 |
|    n_updates       | 11546    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -4.53    |
| time/              |          |
|    episodes        | 52       |
|    fps             | 12       |
|    time_elapsed    | 1006     |
|    total timesteps | 13052    |
| train/             |          |
|    actor_loss      | 0.546    |
|    critic_loss     | 1.2      |
|    learning_rate   | 0.000987 |
|    n_updates       | 12550    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -3.52    |
| time/              |          |
|    episodes        | 56       |
|    fps             | 12       |
|    time_elapsed    | 1083     |
|    total timesteps | 14056    |
| train/             |          |
|    actor_loss      | 0.575    |
|    critic_loss     | 1.15     |
|    learning_rate   | 0.000986 |
|    n_updates       | 13554    |
---------------------------------
Eval num_timesteps=15000, episode_reward=10.07 +/- 0.65
Episode length: 251.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 251      |
|    mean_reward     | 10.1     |
| time/              |          |
|    total_timesteps | 15000    |
| train/             |          |
|    actor_loss      | 0.575    |
|    critic_loss     | 0.964    |
|    learning_rate   | 0.000985 |
|    n_updates       | 14558    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -3.22    |
| time/              |          |
|    episodes        | 60       |
|    fps             | 12       |
|    time_elapsed    | 1181     |
|    total timesteps | 15060    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -4.14    |
| time/              |          |
|    episodes        | 64       |
|    fps             | 12       |
|    time_elapsed    | 1260     |
|    total timesteps | 16064    |
| train/             |          |
|    actor_loss      | 0.596    |
|    critic_loss     | 1.36     |
|    learning_rate   | 0.000984 |
|    n_updates       | 15562    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -4.24    |
| time/              |          |
|    episodes        | 68       |
|    fps             | 12       |
|    time_elapsed    | 1339     |
|    total timesteps | 17068    |
| train/             |          |
|    actor_loss      | 0.604    |
|    critic_loss     | 0.905    |
|    learning_rate   | 0.000983 |
|    n_updates       | 16566    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -3.79    |
| time/              |          |
|    episodes        | 72       |
|    fps             | 12       |
|    time_elapsed    | 1417     |
|    total timesteps | 18072    |
| train/             |          |
|    actor_loss      | 0.597    |
|    critic_loss     | 0.713    |
|    learning_rate   | 0.000982 |
|    n_updates       | 17570    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -4.17    |
| time/              |          |
|    episodes        | 76       |
|    fps             | 12       |
|    time_elapsed    | 1495     |
|    total timesteps | 19076    |
| train/             |          |
|    actor_loss      | 0.617    |
|    critic_loss     | 0.955    |
|    learning_rate   | 0.000981 |
|    n_updates       | 18574    |
---------------------------------
Eval num_timesteps=20000, episode_reward=10.67 +/- 1.24
Episode length: 251.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 251      |
|    mean_reward     | 10.7     |
| time/              |          |
|    total_timesteps | 20000    |
| train/             |          |
|    actor_loss      | 0.648    |
|    critic_loss     | 1.16     |
|    learning_rate   | 0.00098  |
|    n_updates       | 19578    |
---------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -3.87    |
| time/              |          |
|    episodes        | 80       |
|    fps             | 12       |
|    time_elapsed    | 1593     |
|    total timesteps | 20080    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -4.81    |
| time/              |          |
|    episodes        | 84       |
|    fps             | 12       |
|    time_elapsed    | 1671     |
|    total timesteps | 21084    |
| train/             |          |
|    actor_loss      | 0.65     |
|    critic_loss     | 1.2      |
|    learning_rate   | 0.000979 |
|    n_updates       | 20582    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -4.12    |
| time/              |          |
|    episodes        | 88       |
|    fps             | 12       |
|    time_elapsed    | 1748     |
|    total timesteps | 22088    |
| train/             |          |
|    actor_loss      | 0.68     |
|    critic_loss     | 1.05     |
|    learning_rate   | 0.000978 |
|    n_updates       | 21586    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -4.28    |
| time/              |          |
|    episodes        | 92       |
|    fps             | 12       |
|    time_elapsed    | 1826     |
|    total timesteps | 23092    |
| train/             |          |
|    actor_loss      | 0.675    |
|    critic_loss     | 0.56     |
|    learning_rate   | 0.000977 |
|    n_updates       | 22590    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -4.21    |
| time/              |          |
|    episodes        | 96       |
|    fps             | 12       |
|    time_elapsed    | 1904     |
|    total timesteps | 24096    |
| train/             |          |
|    actor_loss      | 0.667    |
|    critic_loss     | 0.758    |
|    learning_rate   | 0.000976 |
|    n_updates       | 23594    |
---------------------------------
Eval num_timesteps=25000, episode_reward=10.05 +/- 0.67
Episode length: 251.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 251      |
|    mean_reward     | 10       |
| time/              |          |
|    total_timesteps | 25000    |
| train/             |          |
|    actor_loss      | 0.695    |
|    critic_loss     | 0.863    |
|    learning_rate   | 0.000975 |
|    n_updates       | 24598    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -3.85    |
| time/              |          |
|    episodes        | 100      |
|    fps             | 12       |
|    time_elapsed    | 2000     |
|    total timesteps | 25100    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -3.46    |
| time/              |          |
|    episodes        | 104      |
|    fps             | 12       |
|    time_elapsed    | 2077     |
|    total timesteps | 26104    |
| train/             |          |
|    actor_loss      | 0.712    |
|    critic_loss     | 1.2      |
|    learning_rate   | 0.000974 |
|    n_updates       | 25602    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -3.01    |
| time/              |          |
|    episodes        | 108      |
|    fps             | 12       |
|    time_elapsed    | 2156     |
|    total timesteps | 27108    |
| train/             |          |
|    actor_loss      | 0.734    |
|    critic_loss     | 1.2      |
|    learning_rate   | 0.000973 |
|    n_updates       | 26606    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -3.06    |
| time/              |          |
|    episodes        | 112      |
|    fps             | 12       |
|    time_elapsed    | 2233     |
|    total timesteps | 28112    |
| train/             |          |
|    actor_loss      | 0.745    |
|    critic_loss     | 1.25     |
|    learning_rate   | 0.000972 |
|    n_updates       | 27610    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -3.53    |
| time/              |          |
|    episodes        | 116      |
|    fps             | 12       |
|    time_elapsed    | 2311     |
|    total timesteps | 29116    |
| train/             |          |
|    actor_loss      | 0.738    |
|    critic_loss     | 0.909    |
|    learning_rate   | 0.000971 |
|    n_updates       | 28614    |
---------------------------------
Eval num_timesteps=30000, episode_reward=10.52 +/- 0.98
Episode length: 251.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 251      |
|    mean_reward     | 10.5     |
| time/              |          |
|    total_timesteps | 30000    |
| train/             |          |
|    actor_loss      | 0.762    |
|    critic_loss     | 1.06     |
|    learning_rate   | 0.00097  |
|    n_updates       | 29618    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -2.06    |
| time/              |          |
|    episodes        | 120      |
|    fps             | 12       |
|    time_elapsed    | 2409     |
|    total timesteps | 30120    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -2.17    |
| time/              |          |
|    episodes        | 124      |
|    fps             | 12       |
|    time_elapsed    | 2486     |
|    total timesteps | 31124    |
| train/             |          |
|    actor_loss      | 0.753    |
|    critic_loss     | 0.659    |
|    learning_rate   | 0.000969 |
|    n_updates       | 30622    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -1.89    |
| time/              |          |
|    episodes        | 128      |
|    fps             | 12       |
|    time_elapsed    | 2564     |
|    total timesteps | 32128    |
| train/             |          |
|    actor_loss      | 0.75     |
|    critic_loss     | 1.21     |
|    learning_rate   | 0.000968 |
|    n_updates       | 31626    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -1.89    |
| time/              |          |
|    episodes        | 132      |
|    fps             | 12       |
|    time_elapsed    | 2641     |
|    total timesteps | 33132    |
| train/             |          |
|    actor_loss      | 0.738    |
|    critic_loss     | 1.01     |
|    learning_rate   | 0.000967 |
|    n_updates       | 32630    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -1.91    |
| time/              |          |
|    episodes        | 136      |
|    fps             | 12       |
|    time_elapsed    | 2720     |
|    total timesteps | 34136    |
| train/             |          |
|    actor_loss      | 0.761    |
|    critic_loss     | 1.16     |
|    learning_rate   | 0.000966 |
|    n_updates       | 33634    |
---------------------------------
Eval num_timesteps=35000, episode_reward=10.57 +/- 1.20
Episode length: 251.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 251      |
|    mean_reward     | 10.6     |
| time/              |          |
|    total_timesteps | 35000    |
| train/             |          |
|    actor_loss      | 0.741    |
|    critic_loss     | 0.661    |
|    learning_rate   | 0.000965 |
|    n_updates       | 34638    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -1.56    |
| time/              |          |
|    episodes        | 140      |
|    fps             | 12       |
|    time_elapsed    | 2818     |
|    total timesteps | 35140    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -1.23    |
| time/              |          |
|    episodes        | 144      |
|    fps             | 12       |
|    time_elapsed    | 2897     |
|    total timesteps | 36144    |
| train/             |          |
|    actor_loss      | 0.749    |
|    critic_loss     | 0.912    |
|    learning_rate   | 0.000964 |
|    n_updates       | 35642    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -2.26    |
| time/              |          |
|    episodes        | 148      |
|    fps             | 12       |
|    time_elapsed    | 2977     |
|    total timesteps | 37148    |
| train/             |          |
|    actor_loss      | 0.758    |
|    critic_loss     | 1.15     |
|    learning_rate   | 0.000963 |
|    n_updates       | 36646    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -2.68    |
| time/              |          |
|    episodes        | 152      |
|    fps             | 12       |
|    time_elapsed    | 3056     |
|    total timesteps | 38152    |
| train/             |          |
|    actor_loss      | 0.781    |
|    critic_loss     | 1.4      |
|    learning_rate   | 0.000962 |
|    n_updates       | 37650    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -3.06    |
| time/              |          |
|    episodes        | 156      |
|    fps             | 12       |
|    time_elapsed    | 3136     |
|    total timesteps | 39156    |
| train/             |          |
|    actor_loss      | 0.773    |
|    critic_loss     | 0.905    |
|    learning_rate   | 0.000961 |
|    n_updates       | 38654    |
---------------------------------
Eval num_timesteps=40000, episode_reward=10.01 +/- 0.50
Episode length: 251.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 251      |
|    mean_reward     | 10       |
| time/              |          |
|    total_timesteps | 40000    |
| train/             |          |
|    actor_loss      | 0.757    |
|    critic_loss     | 1.01     |
|    learning_rate   | 0.00096  |
|    n_updates       | 39658    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -3.44    |
| time/              |          |
|    episodes        | 160      |
|    fps             | 12       |
|    time_elapsed    | 3236     |
|    total timesteps | 40160    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -2.56    |
| time/              |          |
|    episodes        | 164      |
|    fps             | 12       |
|    time_elapsed    | 3318     |
|    total timesteps | 41164    |
| train/             |          |
|    actor_loss      | 0.787    |
|    critic_loss     | 1.25     |
|    learning_rate   | 0.000959 |
|    n_updates       | 40662    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -2.12    |
| time/              |          |
|    episodes        | 168      |
|    fps             | 12       |
|    time_elapsed    | 3399     |
|    total timesteps | 42168    |
| train/             |          |
|    actor_loss      | 0.793    |
|    critic_loss     | 0.959    |
|    learning_rate   | 0.000959 |
|    n_updates       | 41666    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -2.17    |
| time/              |          |
|    episodes        | 172      |
|    fps             | 12       |
|    time_elapsed    | 3482     |
|    total timesteps | 43172    |
| train/             |          |
|    actor_loss      | 0.784    |
|    critic_loss     | 0.958    |
|    learning_rate   | 0.000958 |
|    n_updates       | 42670    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -1.67    |
| time/              |          |
|    episodes        | 176      |
|    fps             | 12       |
|    time_elapsed    | 3565     |
|    total timesteps | 44176    |
| train/             |          |
|    actor_loss      | 0.808    |
|    critic_loss     | 1.01     |
|    learning_rate   | 0.000957 |
|    n_updates       | 43674    |
---------------------------------
Eval num_timesteps=45000, episode_reward=11.02 +/- 1.19
Episode length: 251.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 251      |
|    mean_reward     | 11       |
| time/              |          |
|    total_timesteps | 45000    |
| train/             |          |
|    actor_loss      | 0.768    |
|    critic_loss     | 0.764    |
|    learning_rate   | 0.000956 |
|    n_updates       | 44678    |
---------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -1.57    |
| time/              |          |
|    episodes        | 180      |
|    fps             | 12       |
|    time_elapsed    | 3668     |
|    total timesteps | 45180    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -1.21    |
| time/              |          |
|    episodes        | 184      |
|    fps             | 12       |
|    time_elapsed    | 3752     |
|    total timesteps | 46184    |
| train/             |          |
|    actor_loss      | 0.762    |
|    critic_loss     | 1.11     |
|    learning_rate   | 0.000955 |
|    n_updates       | 45682    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -1.21    |
| time/              |          |
|    episodes        | 188      |
|    fps             | 12       |
|    time_elapsed    | 3835     |
|    total timesteps | 47188    |
| train/             |          |
|    actor_loss      | 0.774    |
|    critic_loss     | 0.914    |
|    learning_rate   | 0.000954 |
|    n_updates       | 46686    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -0.4     |
| time/              |          |
|    episodes        | 192      |
|    fps             | 12       |
|    time_elapsed    | 3919     |
|    total timesteps | 48192    |
| train/             |          |
|    actor_loss      | 0.769    |
|    critic_loss     | 0.909    |
|    learning_rate   | 0.000953 |
|    n_updates       | 47690    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -0.159   |
| time/              |          |
|    episodes        | 196      |
|    fps             | 12       |
|    time_elapsed    | 4002     |
|    total timesteps | 49196    |
| train/             |          |
|    actor_loss      | 0.765    |
|    critic_loss     | 0.762    |
|    learning_rate   | 0.000952 |
|    n_updates       | 48694    |
---------------------------------
Eval num_timesteps=50000, episode_reward=10.40 +/- 1.22
Episode length: 251.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 251      |
|    mean_reward     | 10.4     |
| time/              |          |
|    total_timesteps | 50000    |
| train/             |          |
|    actor_loss      | 0.774    |
|    critic_loss     | 1.06     |
|    learning_rate   | 0.000951 |
|    n_updates       | 49698    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -0.0718  |
| time/              |          |
|    episodes        | 200      |
|    fps             | 12       |
|    time_elapsed    | 4107     |
|    total timesteps | 50200    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -0.574   |
| time/              |          |
|    episodes        | 204      |
|    fps             | 12       |
|    time_elapsed    | 4190     |
|    total timesteps | 51204    |
| train/             |          |
|    actor_loss      | 0.783    |
|    critic_loss     | 0.961    |
|    learning_rate   | 0.00095  |
|    n_updates       | 50702    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -1.03    |
| time/              |          |
|    episodes        | 208      |
|    fps             | 12       |
|    time_elapsed    | 4275     |
|    total timesteps | 52208    |
| train/             |          |
|    actor_loss      | 0.767    |
|    critic_loss     | 1.01     |
|    learning_rate   | 0.000949 |
|    n_updates       | 51706    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -0.618   |
| time/              |          |
|    episodes        | 212      |
|    fps             | 12       |
|    time_elapsed    | 4360     |
|    total timesteps | 53212    |
| train/             |          |
|    actor_loss      | 0.753    |
|    critic_loss     | 0.71     |
|    learning_rate   | 0.000948 |
|    n_updates       | 52710    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -0.41    |
| time/              |          |
|    episodes        | 216      |
|    fps             | 12       |
|    time_elapsed    | 4445     |
|    total timesteps | 54216    |
| train/             |          |
|    actor_loss      | 0.752    |
|    critic_loss     | 0.859    |
|    learning_rate   | 0.000947 |
|    n_updates       | 53714    |
---------------------------------
Eval num_timesteps=55000, episode_reward=10.39 +/- 1.14
Episode length: 251.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 251      |
|    mean_reward     | 10.4     |
| time/              |          |
|    total_timesteps | 55000    |
| train/             |          |
|    actor_loss      | 0.759    |
|    critic_loss     | 1.21     |
|    learning_rate   | 0.000946 |
|    n_updates       | 54718    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -0.272   |
| time/              |          |
|    episodes        | 220      |
|    fps             | 12       |
|    time_elapsed    | 4551     |
|    total timesteps | 55220    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | 0.392    |
| time/              |          |
|    episodes        | 224      |
|    fps             | 12       |
|    time_elapsed    | 4637     |
|    total timesteps | 56224    |
| train/             |          |
|    actor_loss      | 0.756    |
|    critic_loss     | 0.909    |
|    learning_rate   | 0.000945 |
|    n_updates       | 55722    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | 1.15     |
| time/              |          |
|    episodes        | 228      |
|    fps             | 12       |
|    time_elapsed    | 4723     |
|    total timesteps | 57228    |
| train/             |          |
|    actor_loss      | 0.738    |
|    critic_loss     | 0.661    |
|    learning_rate   | 0.000944 |
|    n_updates       | 56726    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | 1.32     |
| time/              |          |
|    episodes        | 232      |
|    fps             | 12       |
|    time_elapsed    | 4811     |
|    total timesteps | 58232    |
| train/             |          |
|    actor_loss      | 0.746    |
|    critic_loss     | 1.16     |
|    learning_rate   | 0.000943 |
|    n_updates       | 57730    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | 1.33     |
| time/              |          |
|    episodes        | 236      |
|    fps             | 12       |
|    time_elapsed    | 4899     |
|    total timesteps | 59236    |
| train/             |          |
|    actor_loss      | 0.736    |
|    critic_loss     | 0.657    |
|    learning_rate   | 0.000942 |
|    n_updates       | 58734    |
---------------------------------
Eval num_timesteps=60000, episode_reward=10.54 +/- 0.72
Episode length: 251.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 251      |
|    mean_reward     | 10.5     |
| time/              |          |
|    total_timesteps | 60000    |
| train/             |          |
|    actor_loss      | 0.737    |
|    critic_loss     | 0.707    |
|    learning_rate   | 0.000941 |
|    n_updates       | 59738    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | 0.54     |
| time/              |          |
|    episodes        | 240      |
|    fps             | 12       |
|    time_elapsed    | 5010     |
|    total timesteps | 60240    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | 0.0369   |
| time/              |          |
|    episodes        | 244      |
|    fps             | 12       |
|    time_elapsed    | 5102     |
|    total timesteps | 61244    |
| train/             |          |
|    actor_loss      | 0.72     |
|    critic_loss     | 0.562    |
|    learning_rate   | 0.00094  |
|    n_updates       | 60742    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | 0.66     |
| time/              |          |
|    episodes        | 248      |
|    fps             | 11       |
|    time_elapsed    | 5193     |
|    total timesteps | 62248    |
| train/             |          |
|    actor_loss      | 0.725    |
|    critic_loss     | 0.959    |
|    learning_rate   | 0.000939 |
|    n_updates       | 61746    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | 0.966    |
| time/              |          |
|    episodes        | 252      |
|    fps             | 11       |
|    time_elapsed    | 5286     |
|    total timesteps | 63252    |
| train/             |          |
|    actor_loss      | 0.726    |
|    critic_loss     | 1.16     |
|    learning_rate   | 0.000938 |
|    n_updates       | 62750    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | 0.92     |
| time/              |          |
|    episodes        | 256      |
|    fps             | 11       |
|    time_elapsed    | 5379     |
|    total timesteps | 64256    |
| train/             |          |
|    actor_loss      | 0.697    |
|    critic_loss     | 0.511    |
|    learning_rate   | 0.000937 |
|    n_updates       | 63754    |
---------------------------------
Eval num_timesteps=65000, episode_reward=11.18 +/- 1.74
Episode length: 251.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 251      |
|    mean_reward     | 11.2     |
| time/              |          |
|    total_timesteps | 65000    |
| train/             |          |
|    actor_loss      | 0.706    |
|    critic_loss     | 0.955    |
|    learning_rate   | 0.000936 |
|    n_updates       | 64507    |
---------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | 1.05     |
| time/              |          |
|    episodes        | 260      |
|    fps             | 11       |
|    time_elapsed    | 5497     |
|    total timesteps | 65260    |
| train/             |          |
|    actor_loss      | 0.718    |
|    critic_loss     | 1.16     |
|    learning_rate   | 0.000936 |
|    n_updates       | 64758    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | 0.495    |
| time/              |          |
|    episodes        | 264      |
|    fps             | 11       |
|    time_elapsed    | 5595     |
|    total timesteps | 66264    |
| train/             |          |
|    actor_loss      | 0.722    |
|    critic_loss     | 1.06     |
|    learning_rate   | 0.000935 |
|    n_updates       | 65762    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | 0.0826   |
| time/              |          |
|    episodes        | 268      |
|    fps             | 11       |
|    time_elapsed    | 5693     |
|    total timesteps | 67268    |
| train/             |          |
|    actor_loss      | 0.689    |
|    critic_loss     | 0.757    |
|    learning_rate   | 0.000934 |
|    n_updates       | 66766    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | 0.518    |
| time/              |          |
|    episodes        | 272      |
|    fps             | 11       |
|    time_elapsed    | 5791     |
|    total timesteps | 68272    |
| train/             |          |
|    actor_loss      | 0.673    |
|    critic_loss     | 0.816    |
|    learning_rate   | 0.000933 |
|    n_updates       | 67770    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | 0.576    |
| time/              |          |
|    episodes        | 276      |
|    fps             | 11       |
|    time_elapsed    | 5890     |
|    total timesteps | 69276    |
| train/             |          |
|    actor_loss      | 0.673    |
|    critic_loss     | 0.609    |
|    learning_rate   | 0.000932 |
|    n_updates       | 68774    |
---------------------------------
Eval num_timesteps=70000, episode_reward=10.18 +/- 0.71
Episode length: 251.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 251      |
|    mean_reward     | 10.2     |
| time/              |          |
|    total_timesteps | 70000    |
| train/             |          |
|    actor_loss      | 0.656    |
|    critic_loss     | 0.412    |
|    learning_rate   | 0.000931 |
|    n_updates       | 69527    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | 0.637    |
| time/              |          |
|    episodes        | 280      |
|    fps             | 11       |
|    time_elapsed    | 6010     |
|    total timesteps | 70280    |
| train/             |          |
|    actor_loss      | 0.664    |
|    critic_loss     | 0.901    |
|    learning_rate   | 0.000931 |
|    n_updates       | 69778    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | 1.11     |
| time/              |          |
|    episodes        | 284      |
|    fps             | 11       |
|    time_elapsed    | 6110     |
|    total timesteps | 71284    |
| train/             |          |
|    actor_loss      | 0.695    |
|    critic_loss     | 1.3      |
|    learning_rate   | 0.00093  |
|    n_updates       | 70782    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -0.218   |
| time/              |          |
|    episodes        | 288      |
|    fps             | 11       |
|    time_elapsed    | 6211     |
|    total timesteps | 72288    |
| train/             |          |
|    actor_loss      | 0.697    |
|    critic_loss     | 0.91     |
|    learning_rate   | 0.000929 |
|    n_updates       | 71786    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -0.269   |
| time/              |          |
|    episodes        | 292      |
|    fps             | 11       |
|    time_elapsed    | 6310     |
|    total timesteps | 73292    |
| train/             |          |
|    actor_loss      | 0.678    |
|    critic_loss     | 0.958    |
|    learning_rate   | 0.000928 |
|    n_updates       | 72790    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -0.471   |
| time/              |          |
|    episodes        | 296      |
|    fps             | 11       |
|    time_elapsed    | 6411     |
|    total timesteps | 74296    |
| train/             |          |
|    actor_loss      | 0.699    |
|    critic_loss     | 1.16     |
|    learning_rate   | 0.000927 |
|    n_updates       | 73794    |
---------------------------------
Eval num_timesteps=75000, episode_reward=10.84 +/- 0.79
Episode length: 251.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 251      |
|    mean_reward     | 10.8     |
| time/              |          |
|    total_timesteps | 75000    |
| train/             |          |
|    actor_loss      | 0.666    |
|    critic_loss     | 0.857    |
|    learning_rate   | 0.000926 |
|    n_updates       | 74547    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -0.637   |
| time/              |          |
|    episodes        | 300      |
|    fps             | 11       |
|    time_elapsed    | 6533     |
|    total timesteps | 75300    |
| train/             |          |
|    actor_loss      | 0.66     |
|    critic_loss     | 0.76     |
|    learning_rate   | 0.000926 |
|    n_updates       | 74798    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -1.29    |
| time/              |          |
|    episodes        | 304      |
|    fps             | 11       |
|    time_elapsed    | 6634     |
|    total timesteps | 76304    |
| train/             |          |
|    actor_loss      | 0.665    |
|    critic_loss     | 1.01     |
|    learning_rate   | 0.000925 |
|    n_updates       | 75802    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -1.07    |
| time/              |          |
|    episodes        | 308      |
|    fps             | 11       |
|    time_elapsed    | 6737     |
|    total timesteps | 77308    |
| train/             |          |
|    actor_loss      | 0.652    |
|    critic_loss     | 0.91     |
|    learning_rate   | 0.000924 |
|    n_updates       | 76806    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -1.69    |
| time/              |          |
|    episodes        | 312      |
|    fps             | 11       |
|    time_elapsed    | 6839     |
|    total timesteps | 78312    |
| train/             |          |
|    actor_loss      | 0.657    |
|    critic_loss     | 0.958    |
|    learning_rate   | 0.000923 |
|    n_updates       | 77810    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -1.85    |
| time/              |          |
|    episodes        | 316      |
|    fps             | 11       |
|    time_elapsed    | 6940     |
|    total timesteps | 79316    |
| train/             |          |
|    actor_loss      | 0.651    |
|    critic_loss     | 0.814    |
|    learning_rate   | 0.000922 |
|    n_updates       | 78814    |
---------------------------------
Eval num_timesteps=80000, episode_reward=10.01 +/- 0.44
Episode length: 251.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 251      |
|    mean_reward     | 10       |
| time/              |          |
|    total_timesteps | 80000    |
| train/             |          |
|    actor_loss      | 0.643    |
|    critic_loss     | 0.56     |
|    learning_rate   | 0.000921 |
|    n_updates       | 79567    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -1.89    |
| time/              |          |
|    episodes        | 320      |
|    fps             | 11       |
|    time_elapsed    | 7063     |
|    total timesteps | 80320    |
| train/             |          |
|    actor_loss      | 0.631    |
|    critic_loss     | 0.761    |
|    learning_rate   | 0.000921 |
|    n_updates       | 79818    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -2.57    |
| time/              |          |
|    episodes        | 324      |
|    fps             | 11       |
|    time_elapsed    | 7166     |
|    total timesteps | 81324    |
| train/             |          |
|    actor_loss      | 0.63     |
|    critic_loss     | 0.76     |
|    learning_rate   | 0.00092  |
|    n_updates       | 80822    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -2.48    |
| time/              |          |
|    episodes        | 328      |
|    fps             | 11       |
|    time_elapsed    | 7268     |
|    total timesteps | 82328    |
| train/             |          |
|    actor_loss      | 0.615    |
|    critic_loss     | 0.711    |
|    learning_rate   | 0.000919 |
|    n_updates       | 81826    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -2.25    |
| time/              |          |
|    episodes        | 332      |
|    fps             | 11       |
|    time_elapsed    | 7371     |
|    total timesteps | 83332    |
| train/             |          |
|    actor_loss      | 0.624    |
|    critic_loss     | 1.11     |
|    learning_rate   | 0.000918 |
|    n_updates       | 82830    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -2.53    |
| time/              |          |
|    episodes        | 336      |
|    fps             | 11       |
|    time_elapsed    | 7474     |
|    total timesteps | 84336    |
| train/             |          |
|    actor_loss      | 0.592    |
|    critic_loss     | 0.661    |
|    learning_rate   | 0.000917 |
|    n_updates       | 83834    |
---------------------------------
Eval num_timesteps=85000, episode_reward=9.75 +/- 0.19
Episode length: 251.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 251      |
|    mean_reward     | 9.75     |
| time/              |          |
|    total_timesteps | 85000    |
| train/             |          |
|    actor_loss      | 0.587    |
|    critic_loss     | 0.719    |
|    learning_rate   | 0.000916 |
|    n_updates       | 84587    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -2.41    |
| time/              |          |
|    episodes        | 340      |
|    fps             | 11       |
|    time_elapsed    | 7597     |
|    total timesteps | 85340    |
| train/             |          |
|    actor_loss      | 0.581    |
|    critic_loss     | 0.762    |
|    learning_rate   | 0.000916 |
|    n_updates       | 84838    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -2.13    |
| time/              |          |
|    episodes        | 344      |
|    fps             | 11       |
|    time_elapsed    | 7701     |
|    total timesteps | 86344    |
| train/             |          |
|    actor_loss      | 0.587    |
|    critic_loss     | 0.658    |
|    learning_rate   | 0.000915 |
|    n_updates       | 85842    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -2.48    |
| time/              |          |
|    episodes        | 348      |
|    fps             | 11       |
|    time_elapsed    | 7804     |
|    total timesteps | 87348    |
| train/             |          |
|    actor_loss      | 0.591    |
|    critic_loss     | 0.96     |
|    learning_rate   | 0.000914 |
|    n_updates       | 86846    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -4.01    |
| time/              |          |
|    episodes        | 352      |
|    fps             | 11       |
|    time_elapsed    | 7908     |
|    total timesteps | 88352    |
| train/             |          |
|    actor_loss      | 0.607    |
|    critic_loss     | 1.1      |
|    learning_rate   | 0.000913 |
|    n_updates       | 87850    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -4.01    |
| time/              |          |
|    episodes        | 356      |
|    fps             | 11       |
|    time_elapsed    | 8012     |
|    total timesteps | 89356    |
| train/             |          |
|    actor_loss      | 0.595    |
|    critic_loss     | 0.708    |
|    learning_rate   | 0.000912 |
|    n_updates       | 88854    |
---------------------------------
Eval num_timesteps=90000, episode_reward=11.23 +/- 1.54
Episode length: 251.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 251      |
|    mean_reward     | 11.2     |
| time/              |          |
|    total_timesteps | 90000    |
| train/             |          |
|    actor_loss      | 0.602    |
|    critic_loss     | 0.808    |
|    learning_rate   | 0.000911 |
|    n_updates       | 89607    |
---------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -3.82    |
| time/              |          |
|    episodes        | 360      |
|    fps             | 11       |
|    time_elapsed    | 8136     |
|    total timesteps | 90360    |
| train/             |          |
|    actor_loss      | 0.613    |
|    critic_loss     | 1.3      |
|    learning_rate   | 0.000911 |
|    n_updates       | 89858    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -3.92    |
| time/              |          |
|    episodes        | 364      |
|    fps             | 11       |
|    time_elapsed    | 8241     |
|    total timesteps | 91364    |
| train/             |          |
|    actor_loss      | 0.601    |
|    critic_loss     | 0.805    |
|    learning_rate   | 0.00091  |
|    n_updates       | 90862    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -3.68    |
| time/              |          |
|    episodes        | 368      |
|    fps             | 11       |
|    time_elapsed    | 8345     |
|    total timesteps | 92368    |
| train/             |          |
|    actor_loss      | 0.614    |
|    critic_loss     | 0.855    |
|    learning_rate   | 0.000909 |
|    n_updates       | 91866    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -4.85    |
| time/              |          |
|    episodes        | 372      |
|    fps             | 11       |
|    time_elapsed    | 8449     |
|    total timesteps | 93372    |
| train/             |          |
|    actor_loss      | 0.595    |
|    critic_loss     | 0.761    |
|    learning_rate   | 0.000908 |
|    n_updates       | 92870    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -4.68    |
| time/              |          |
|    episodes        | 376      |
|    fps             | 11       |
|    time_elapsed    | 8554     |
|    total timesteps | 94376    |
| train/             |          |
|    actor_loss      | 0.62     |
|    critic_loss     | 0.711    |
|    learning_rate   | 0.000907 |
|    n_updates       | 93874    |
---------------------------------
Eval num_timesteps=95000, episode_reward=10.24 +/- 1.01
Episode length: 251.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 251      |
|    mean_reward     | 10.2     |
| time/              |          |
|    total_timesteps | 95000    |
| train/             |          |
|    actor_loss      | 0.624    |
|    critic_loss     | 0.91     |
|    learning_rate   | 0.000906 |
|    n_updates       | 94627    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -5.24    |
| time/              |          |
|    episodes        | 380      |
|    fps             | 10       |
|    time_elapsed    | 8681     |
|    total timesteps | 95380    |
| train/             |          |
|    actor_loss      | 0.621    |
|    critic_loss     | 0.957    |
|    learning_rate   | 0.000906 |
|    n_updates       | 94878    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -4.93    |
| time/              |          |
|    episodes        | 384      |
|    fps             | 10       |
|    time_elapsed    | 8786     |
|    total timesteps | 96384    |
| train/             |          |
|    actor_loss      | 0.637    |
|    critic_loss     | 0.961    |
|    learning_rate   | 0.000905 |
|    n_updates       | 95882    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -3.62    |
| time/              |          |
|    episodes        | 388      |
|    fps             | 10       |
|    time_elapsed    | 8891     |
|    total timesteps | 97388    |
| train/             |          |
|    actor_loss      | 0.617    |
|    critic_loss     | 0.808    |
|    learning_rate   | 0.000904 |
|    n_updates       | 96886    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -3.9     |
| time/              |          |
|    episodes        | 392      |
|    fps             | 10       |
|    time_elapsed    | 8997     |
|    total timesteps | 98392    |
| train/             |          |
|    actor_loss      | 0.627    |
|    critic_loss     | 1.4      |
|    learning_rate   | 0.000903 |
|    n_updates       | 97890    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -4.42    |
| time/              |          |
|    episodes        | 396      |
|    fps             | 10       |
|    time_elapsed    | 9103     |
|    total timesteps | 99396    |
| train/             |          |
|    actor_loss      | 0.629    |
|    critic_loss     | 0.958    |
|    learning_rate   | 0.000902 |
|    n_updates       | 98894    |
---------------------------------
Eval num_timesteps=100000, episode_reward=10.40 +/- 1.46
Episode length: 251.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 251      |
|    mean_reward     | 10.4     |
| time/              |          |
|    total_timesteps | 100000   |
| train/             |          |
|    actor_loss      | 0.633    |
|    critic_loss     | 0.911    |
|    learning_rate   | 0.000901 |
|    n_updates       | 99647    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -4.18    |
| time/              |          |
|    episodes        | 400      |
|    fps             | 10       |
|    time_elapsed    | 9230     |
|    total timesteps | 100400   |
| train/             |          |
|    actor_loss      | 0.624    |
|    critic_loss     | 0.806    |
|    learning_rate   | 0.000901 |
|    n_updates       | 99898    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -3.02    |
| time/              |          |
|    episodes        | 404      |
|    fps             | 10       |
|    time_elapsed    | 9336     |
|    total timesteps | 101404   |
| train/             |          |
|    actor_loss      | 0.636    |
|    critic_loss     | 1.16     |
|    learning_rate   | 0.0009   |
|    n_updates       | 100902   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -3.64    |
| time/              |          |
|    episodes        | 408      |
|    fps             | 10       |
|    time_elapsed    | 9441     |
|    total timesteps | 102408   |
| train/             |          |
|    actor_loss      | 0.632    |
|    critic_loss     | 1.31     |
|    learning_rate   | 0.000899 |
|    n_updates       | 101906   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -2.64    |
| time/              |          |
|    episodes        | 412      |
|    fps             | 10       |
|    time_elapsed    | 9548     |
|    total timesteps | 103412   |
| train/             |          |
|    actor_loss      | 0.601    |
|    critic_loss     | 0.662    |
|    learning_rate   | 0.000898 |
|    n_updates       | 102910   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -2.97    |
| time/              |          |
|    episodes        | 416      |
|    fps             | 10       |
|    time_elapsed    | 9656     |
|    total timesteps | 104416   |
| train/             |          |
|    actor_loss      | 0.614    |
|    critic_loss     | 0.958    |
|    learning_rate   | 0.000897 |
|    n_updates       | 103914   |
---------------------------------
Eval num_timesteps=105000, episode_reward=10.20 +/- 1.58
Episode length: 251.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 251      |
|    mean_reward     | 10.2     |
| time/              |          |
|    total_timesteps | 105000   |
| train/             |          |
|    actor_loss      | 0.586    |
|    critic_loss     | 0.763    |
|    learning_rate   | 0.000896 |
|    n_updates       | 104667   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -3.29    |
| time/              |          |
|    episodes        | 420      |
|    fps             | 10       |
|    time_elapsed    | 9784     |
|    total timesteps | 105420   |
| train/             |          |
|    actor_loss      | 0.606    |
|    critic_loss     | 1.11     |
|    learning_rate   | 0.000896 |
|    n_updates       | 104918   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -3.57    |
| time/              |          |
|    episodes        | 424      |
|    fps             | 10       |
|    time_elapsed    | 9893     |
|    total timesteps | 106424   |
| train/             |          |
|    actor_loss      | 0.599    |
|    critic_loss     | 0.908    |
|    learning_rate   | 0.000895 |
|    n_updates       | 105922   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -4.01    |
| time/              |          |
|    episodes        | 428      |
|    fps             | 10       |
|    time_elapsed    | 10001    |
|    total timesteps | 107428   |
| train/             |          |
|    actor_loss      | 0.597    |
|    critic_loss     | 0.909    |
|    learning_rate   | 0.000894 |
|    n_updates       | 106926   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -4.31    |
| time/              |          |
|    episodes        | 432      |
|    fps             | 10       |
|    time_elapsed    | 10111    |
|    total timesteps | 108432   |
| train/             |          |
|    actor_loss      | 0.578    |
|    critic_loss     | 1.16     |
|    learning_rate   | 0.000893 |
|    n_updates       | 107930   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -4.08    |
| time/              |          |
|    episodes        | 436      |
|    fps             | 10       |
|    time_elapsed    | 10221    |
|    total timesteps | 109436   |
| train/             |          |
|    actor_loss      | 0.582    |
|    critic_loss     | 1.01     |
|    learning_rate   | 0.000892 |
|    n_updates       | 108934   |
---------------------------------
Eval num_timesteps=110000, episode_reward=10.53 +/- 1.27
Episode length: 251.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 251      |
|    mean_reward     | 10.5     |
| time/              |          |
|    total_timesteps | 110000   |
| train/             |          |
|    actor_loss      | 0.564    |
|    critic_loss     | 0.96     |
|    learning_rate   | 0.000891 |
|    n_updates       | 109687   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -4       |
| time/              |          |
|    episodes        | 440      |
|    fps             | 10       |
|    time_elapsed    | 10351    |
|    total timesteps | 110440   |
| train/             |          |
|    actor_loss      | 0.563    |
|    critic_loss     | 0.809    |
|    learning_rate   | 0.000891 |
|    n_updates       | 109938   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -5.64    |
| time/              |          |
|    episodes        | 444      |
|    fps             | 10       |
|    time_elapsed    | 10461    |
|    total timesteps | 111444   |
| train/             |          |
|    actor_loss      | 0.608    |
|    critic_loss     | 1.45     |
|    learning_rate   | 0.00089  |
|    n_updates       | 110942   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -5.05    |
| time/              |          |
|    episodes        | 448      |
|    fps             | 10       |
|    time_elapsed    | 10572    |
|    total timesteps | 112448   |
| train/             |          |
|    actor_loss      | 0.647    |
|    critic_loss     | 1.16     |
|    learning_rate   | 0.000889 |
|    n_updates       | 111946   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -4.19    |
| time/              |          |
|    episodes        | 452      |
|    fps             | 10       |
|    time_elapsed    | 10683    |
|    total timesteps | 113452   |
| train/             |          |
|    actor_loss      | 0.669    |
|    critic_loss     | 1.3      |
|    learning_rate   | 0.000888 |
|    n_updates       | 112950   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -4.13    |
| time/              |          |
|    episodes        | 456      |
|    fps             | 10       |
|    time_elapsed    | 10795    |
|    total timesteps | 114456   |
| train/             |          |
|    actor_loss      | 0.656    |
|    critic_loss     | 0.909    |
|    learning_rate   | 0.000887 |
|    n_updates       | 113954   |
---------------------------------
Eval num_timesteps=115000, episode_reward=10.93 +/- 1.31
Episode length: 251.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 251      |
|    mean_reward     | 10.9     |
| time/              |          |
|    total_timesteps | 115000   |
| train/             |          |
|    actor_loss      | 0.673    |
|    critic_loss     | 1        |
|    learning_rate   | 0.000886 |
|    n_updates       | 114707   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -3.82    |
| time/              |          |
|    episodes        | 460      |
|    fps             | 10       |
|    time_elapsed    | 10927    |
|    total timesteps | 115460   |
| train/             |          |
|    actor_loss      | 0.661    |
|    critic_loss     | 0.86     |
|    learning_rate   | 0.000886 |
|    n_updates       | 114958   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -3.52    |
| time/              |          |
|    episodes        | 464      |
|    fps             | 10       |
|    time_elapsed    | 11040    |
|    total timesteps | 116464   |
| train/             |          |
|    actor_loss      | 0.646    |
|    critic_loss     | 0.761    |
|    learning_rate   | 0.000885 |
|    n_updates       | 115962   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -3.99    |
| time/              |          |
|    episodes        | 468      |
|    fps             | 10       |
|    time_elapsed    | 11153    |
|    total timesteps | 117468   |
| train/             |          |
|    actor_loss      | 0.665    |
|    critic_loss     | 1.06     |
|    learning_rate   | 0.000884 |
|    n_updates       | 116966   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -3.46    |
| time/              |          |
|    episodes        | 472      |
|    fps             | 10       |
|    time_elapsed    | 11265    |
|    total timesteps | 118472   |
| train/             |          |
|    actor_loss      | 0.657    |
|    critic_loss     | 0.911    |
|    learning_rate   | 0.000883 |
|    n_updates       | 117970   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -4.39    |
| time/              |          |
|    episodes        | 476      |
|    fps             | 10       |
|    time_elapsed    | 11378    |
|    total timesteps | 119476   |
| train/             |          |
|    actor_loss      | 0.64     |
|    critic_loss     | 0.561    |
|    learning_rate   | 0.000882 |
|    n_updates       | 118974   |
---------------------------------
Eval num_timesteps=120000, episode_reward=10.10 +/- 0.12
Episode length: 251.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 251      |
|    mean_reward     | 10.1     |
| time/              |          |
|    total_timesteps | 120000   |
| train/             |          |
|    actor_loss      | 0.677    |
|    critic_loss     | 1.26     |
|    learning_rate   | 0.000881 |
|    n_updates       | 119727   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -4.24    |
| time/              |          |
|    episodes        | 480      |
|    fps             | 10       |
|    time_elapsed    | 11512    |
|    total timesteps | 120480   |
| train/             |          |
|    actor_loss      | 0.672    |
|    critic_loss     | 0.814    |
|    learning_rate   | 0.000881 |
|    n_updates       | 119978   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -4.17    |
| time/              |          |
|    episodes        | 484      |
|    fps             | 10       |
|    time_elapsed    | 11626    |
|    total timesteps | 121484   |
| train/             |          |
|    actor_loss      | 0.695    |
|    critic_loss     | 1.31     |
|    learning_rate   | 0.00088  |
|    n_updates       | 120982   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -4.85    |
| time/              |          |
|    episodes        | 488      |
|    fps             | 10       |
|    time_elapsed    | 11739    |
|    total timesteps | 122488   |
| train/             |          |
|    actor_loss      | 0.686    |
|    critic_loss     | 0.812    |
|    learning_rate   | 0.000879 |
|    n_updates       | 121986   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -4.84    |
| time/              |          |
|    episodes        | 492      |
|    fps             | 10       |
|    time_elapsed    | 11855    |
|    total timesteps | 123492   |
| train/             |          |
|    actor_loss      | 0.721    |
|    critic_loss     | 1.01     |
|    learning_rate   | 0.000878 |
|    n_updates       | 122990   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -4.37    |
| time/              |          |
|    episodes        | 496      |
|    fps             | 10       |
|    time_elapsed    | 11970    |
|    total timesteps | 124496   |
| train/             |          |
|    actor_loss      | 0.716    |
|    critic_loss     | 0.96     |
|    learning_rate   | 0.000877 |
|    n_updates       | 123994   |
---------------------------------
Eval num_timesteps=125000, episode_reward=10.94 +/- 1.96
Episode length: 251.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 251      |
|    mean_reward     | 10.9     |
| time/              |          |
|    total_timesteps | 125000   |
| train/             |          |
|    actor_loss      | 0.716    |
|    critic_loss     | 0.958    |
|    learning_rate   | 0.000876 |
|    n_updates       | 124747   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -4.86    |
| time/              |          |
|    episodes        | 500      |
|    fps             | 10       |
|    time_elapsed    | 12104    |
|    total timesteps | 125500   |
| train/             |          |
|    actor_loss      | 0.702    |
|    critic_loss     | 0.817    |
|    learning_rate   | 0.000876 |
|    n_updates       | 124998   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -5.51    |
| time/              |          |
|    episodes        | 504      |
|    fps             | 10       |
|    time_elapsed    | 12218    |
|    total timesteps | 126504   |
| train/             |          |
|    actor_loss      | 0.72     |
|    critic_loss     | 1.26     |
|    learning_rate   | 0.000875 |
|    n_updates       | 126002   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -4.87    |
| time/              |          |
|    episodes        | 508      |
|    fps             | 10       |
|    time_elapsed    | 12332    |
|    total timesteps | 127508   |
| train/             |          |
|    actor_loss      | 0.728    |
|    critic_loss     | 1.01     |
|    learning_rate   | 0.000874 |
|    n_updates       | 127006   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -5.99    |
| time/              |          |
|    episodes        | 512      |
|    fps             | 10       |
|    time_elapsed    | 12446    |
|    total timesteps | 128512   |
| train/             |          |
|    actor_loss      | 0.714    |
|    critic_loss     | 0.813    |
|    learning_rate   | 0.000873 |
|    n_updates       | 128010   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -5.74    |
| time/              |          |
|    episodes        | 516      |
|    fps             | 10       |
|    time_elapsed    | 12560    |
|    total timesteps | 129516   |
| train/             |          |
|    actor_loss      | 0.724    |
|    critic_loss     | 0.711    |
|    learning_rate   | 0.000872 |
|    n_updates       | 129014   |
---------------------------------
Eval num_timesteps=130000, episode_reward=10.53 +/- 1.02
Episode length: 251.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 251      |
|    mean_reward     | 10.5     |
| time/              |          |
|    total_timesteps | 130000   |
| train/             |          |
|    actor_loss      | 0.742    |
|    critic_loss     | 0.754    |
|    learning_rate   | 0.000872 |
|    n_updates       | 129516   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -5.83    |
| time/              |          |
|    episodes        | 520      |
|    fps             | 10       |
|    time_elapsed    | 12695    |
|    total timesteps | 130520   |
| train/             |          |
|    actor_loss      | 0.727    |
|    critic_loss     | 0.959    |
|    learning_rate   | 0.000871 |
|    n_updates       | 130018   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -5.59    |
| time/              |          |
|    episodes        | 524      |
|    fps             | 10       |
|    time_elapsed    | 12810    |
|    total timesteps | 131524   |
| train/             |          |
|    actor_loss      | 0.752    |
|    critic_loss     | 1.06     |
|    learning_rate   | 0.00087  |
|    n_updates       | 131022   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -5.75    |
| time/              |          |
|    episodes        | 528      |
|    fps             | 10       |
|    time_elapsed    | 12924    |
|    total timesteps | 132528   |
| train/             |          |
|    actor_loss      | 0.745    |
|    critic_loss     | 0.861    |
|    learning_rate   | 0.000869 |
|    n_updates       | 132026   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -5.7     |
| time/              |          |
|    episodes        | 532      |
|    fps             | 10       |
|    time_elapsed    | 13038    |
|    total timesteps | 133532   |
| train/             |          |
|    actor_loss      | 0.763    |
|    critic_loss     | 1.2      |
|    learning_rate   | 0.000868 |
|    n_updates       | 133030   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -5.59    |
| time/              |          |
|    episodes        | 536      |
|    fps             | 10       |
|    time_elapsed    | 13152    |
|    total timesteps | 134536   |
| train/             |          |
|    actor_loss      | 0.765    |
|    critic_loss     | 0.66     |
|    learning_rate   | 0.000867 |
|    n_updates       | 134034   |
---------------------------------
Eval num_timesteps=135000, episode_reward=9.85 +/- 0.22
Episode length: 251.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 251      |
|    mean_reward     | 9.85     |
| time/              |          |
|    total_timesteps | 135000   |
| train/             |          |
|    actor_loss      | 0.757    |
|    critic_loss     | 1.21     |
|    learning_rate   | 0.000867 |
|    n_updates       | 134536   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -5.29    |
| time/              |          |
|    episodes        | 540      |
|    fps             | 10       |
|    time_elapsed    | 13287    |
|    total timesteps | 135540   |
| train/             |          |
|    actor_loss      | 0.753    |
|    critic_loss     | 0.711    |
|    learning_rate   | 0.000866 |
|    n_updates       | 135038   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -4.07    |
| time/              |          |
|    episodes        | 544      |
|    fps             | 10       |
|    time_elapsed    | 13401    |
|    total timesteps | 136544   |
| train/             |          |
|    actor_loss      | 0.75     |
|    critic_loss     | 1.06     |
|    learning_rate   | 0.000865 |
|    n_updates       | 136042   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -4.92    |
| time/              |          |
|    episodes        | 548      |
|    fps             | 10       |
|    time_elapsed    | 13515    |
|    total timesteps | 137548   |
| train/             |          |
|    actor_loss      | 0.738    |
|    critic_loss     | 0.716    |
|    learning_rate   | 0.000864 |
|    n_updates       | 137046   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -4.44    |
| time/              |          |
|    episodes        | 552      |
|    fps             | 10       |
|    time_elapsed    | 13628    |
|    total timesteps | 138552   |
| train/             |          |
|    actor_loss      | 0.735    |
|    critic_loss     | 0.766    |
|    learning_rate   | 0.000863 |
|    n_updates       | 138050   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -4.49    |
| time/              |          |
|    episodes        | 556      |
|    fps             | 10       |
|    time_elapsed    | 13742    |
|    total timesteps | 139556   |
| train/             |          |
|    actor_loss      | 0.734    |
|    critic_loss     | 0.807    |
|    learning_rate   | 0.000862 |
|    n_updates       | 139054   |
---------------------------------
Eval num_timesteps=140000, episode_reward=10.07 +/- 0.55
Episode length: 251.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 251      |
|    mean_reward     | 10.1     |
| time/              |          |
|    total_timesteps | 140000   |
| train/             |          |
|    actor_loss      | 0.716    |
|    critic_loss     | 0.711    |
|    learning_rate   | 0.000862 |
|    n_updates       | 139556   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -4.43    |
| time/              |          |
|    episodes        | 560      |
|    fps             | 10       |
|    time_elapsed    | 13878    |
|    total timesteps | 140560   |
| train/             |          |
|    actor_loss      | 0.738    |
|    critic_loss     | 0.962    |
|    learning_rate   | 0.000861 |
|    n_updates       | 140058   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -4.24    |
| time/              |          |
|    episodes        | 564      |
|    fps             | 10       |
|    time_elapsed    | 13992    |
|    total timesteps | 141564   |
| train/             |          |
|    actor_loss      | 0.724    |
|    critic_loss     | 0.809    |
|    learning_rate   | 0.00086  |
|    n_updates       | 141062   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -3.8     |
| time/              |          |
|    episodes        | 568      |
|    fps             | 10       |
|    time_elapsed    | 14106    |
|    total timesteps | 142568   |
| train/             |          |
|    actor_loss      | 0.747    |
|    critic_loss     | 1.46     |
|    learning_rate   | 0.000859 |
|    n_updates       | 142066   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -4.43    |
| time/              |          |
|    episodes        | 572      |
|    fps             | 10       |
|    time_elapsed    | 14221    |
|    total timesteps | 143572   |
| train/             |          |
|    actor_loss      | 0.717    |
|    critic_loss     | 0.859    |
|    learning_rate   | 0.000858 |
|    n_updates       | 143070   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -3.34    |
| time/              |          |
|    episodes        | 576      |
|    fps             | 10       |
|    time_elapsed    | 14335    |
|    total timesteps | 144576   |
| train/             |          |
|    actor_loss      | 0.73     |
|    critic_loss     | 1.16     |
|    learning_rate   | 0.000857 |
|    n_updates       | 144074   |
---------------------------------
Eval num_timesteps=145000, episode_reward=10.47 +/- 1.16
Episode length: 251.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 251      |
|    mean_reward     | 10.5     |
| time/              |          |
|    total_timesteps | 145000   |
| train/             |          |
|    actor_loss      | 0.746    |
|    critic_loss     | 1.25     |
|    learning_rate   | 0.000857 |
|    n_updates       | 144576   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -3.11    |
| time/              |          |
|    episodes        | 580      |
|    fps             | 10       |
|    time_elapsed    | 14470    |
|    total timesteps | 145580   |
| train/             |          |
|    actor_loss      | 0.726    |
|    critic_loss     | 0.666    |
|    learning_rate   | 0.000856 |
|    n_updates       | 145078   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -3.25    |
| time/              |          |
|    episodes        | 584      |
|    fps             | 10       |
|    time_elapsed    | 14584    |
|    total timesteps | 146584   |
| train/             |          |
|    actor_loss      | 0.728    |
|    critic_loss     | 0.96     |
|    learning_rate   | 0.000855 |
|    n_updates       | 146082   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -3.87    |
| time/              |          |
|    episodes        | 588      |
|    fps             | 10       |
|    time_elapsed    | 14699    |
|    total timesteps | 147588   |
| train/             |          |
|    actor_loss      | 0.717    |
|    critic_loss     | 1.01     |
|    learning_rate   | 0.000854 |
|    n_updates       | 147086   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -3.85    |
| time/              |          |
|    episodes        | 592      |
|    fps             | 10       |
|    time_elapsed    | 14813    |
|    total timesteps | 148592   |
| train/             |          |
|    actor_loss      | 0.737    |
|    critic_loss     | 1.25     |
|    learning_rate   | 0.000853 |
|    n_updates       | 148090   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -3.85    |
| time/              |          |
|    episodes        | 596      |
|    fps             | 10       |
|    time_elapsed    | 14927    |
|    total timesteps | 149596   |
| train/             |          |
|    actor_loss      | 0.702    |
|    critic_loss     | 0.811    |
|    learning_rate   | 0.000852 |
|    n_updates       | 149094   |
---------------------------------
Eval num_timesteps=150000, episode_reward=11.03 +/- 1.62
Episode length: 251.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 251      |
|    mean_reward     | 11       |
| time/              |          |
|    total_timesteps | 150000   |
| train/             |          |
|    actor_loss      | 0.703    |
|    critic_loss     | 0.809    |
|    learning_rate   | 0.000852 |
|    n_updates       | 149596   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -3.57    |
| time/              |          |
|    episodes        | 600      |
|    fps             | 9        |
|    time_elapsed    | 15062    |
|    total timesteps | 150600   |
| train/             |          |
|    actor_loss      | 0.676    |
|    critic_loss     | 0.415    |
|    learning_rate   | 0.000851 |
|    n_updates       | 150098   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -3       |
| time/              |          |
|    episodes        | 604      |
|    fps             | 9        |
|    time_elapsed    | 15177    |
|    total timesteps | 151604   |
| train/             |          |
|    actor_loss      | 0.699    |
|    critic_loss     | 1.4      |
|    learning_rate   | 0.00085  |
|    n_updates       | 151102   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -3.93    |
| time/              |          |
|    episodes        | 608      |
|    fps             | 9        |
|    time_elapsed    | 15292    |
|    total timesteps | 152608   |
| train/             |          |
|    actor_loss      | 0.691    |
|    critic_loss     | 0.911    |
|    learning_rate   | 0.000849 |
|    n_updates       | 152106   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -3.56    |
| time/              |          |
|    episodes        | 612      |
|    fps             | 9        |
|    time_elapsed    | 15406    |
|    total timesteps | 153612   |
| train/             |          |
|    actor_loss      | 0.677    |
|    critic_loss     | 0.713    |
|    learning_rate   | 0.000848 |
|    n_updates       | 153110   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -3.77    |
| time/              |          |
|    episodes        | 616      |
|    fps             | 9        |
|    time_elapsed    | 15519    |
|    total timesteps | 154616   |
| train/             |          |
|    actor_loss      | 0.69     |
|    critic_loss     | 1.01     |
|    learning_rate   | 0.000847 |
|    n_updates       | 154114   |
---------------------------------
Eval num_timesteps=155000, episode_reward=10.20 +/- 1.21
Episode length: 251.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 251      |
|    mean_reward     | 10.2     |
| time/              |          |
|    total_timesteps | 155000   |
| train/             |          |
|    actor_loss      | 0.675    |
|    critic_loss     | 0.711    |
|    learning_rate   | 0.000847 |
|    n_updates       | 154616   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -3.62    |
| time/              |          |
|    episodes        | 620      |
|    fps             | 9        |
|    time_elapsed    | 15653    |
|    total timesteps | 155620   |
| train/             |          |
|    actor_loss      | 0.693    |
|    critic_loss     | 1.11     |
|    learning_rate   | 0.000846 |
|    n_updates       | 155118   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -3.44    |
| time/              |          |
|    episodes        | 624      |
|    fps             | 9        |
|    time_elapsed    | 15767    |
|    total timesteps | 156624   |
| train/             |          |
|    actor_loss      | 0.663    |
|    critic_loss     | 0.762    |
|    learning_rate   | 0.000845 |
|    n_updates       | 156122   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -2.87    |
| time/              |          |
|    episodes        | 628      |
|    fps             | 9        |
|    time_elapsed    | 15882    |
|    total timesteps | 157628   |
| train/             |          |
|    actor_loss      | 0.693    |
|    critic_loss     | 1.2      |
|    learning_rate   | 0.000844 |
|    n_updates       | 157126   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -2.47    |
| time/              |          |
|    episodes        | 632      |
|    fps             | 9        |
|    time_elapsed    | 15997    |
|    total timesteps | 158632   |
| train/             |          |
|    actor_loss      | 0.708    |
|    critic_loss     | 1        |
|    learning_rate   | 0.000843 |
|    n_updates       | 158130   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -2.92    |
| time/              |          |
|    episodes        | 636      |
|    fps             | 9        |
|    time_elapsed    | 16111    |
|    total timesteps | 159636   |
| train/             |          |
|    actor_loss      | 0.719    |
|    critic_loss     | 1.16     |
|    learning_rate   | 0.000842 |
|    n_updates       | 159134   |
---------------------------------
Eval num_timesteps=160000, episode_reward=10.30 +/- 0.48
Episode length: 251.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 251      |
|    mean_reward     | 10.3     |
| time/              |          |
|    total_timesteps | 160000   |
| train/             |          |
|    actor_loss      | 0.709    |
|    critic_loss     | 0.665    |
|    learning_rate   | 0.000842 |
|    n_updates       | 159636   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -3.14    |
| time/              |          |
|    episodes        | 640      |
|    fps             | 9        |
|    time_elapsed    | 16247    |
|    total timesteps | 160640   |
| train/             |          |
|    actor_loss      | 0.722    |
|    critic_loss     | 1.31     |
|    learning_rate   | 0.000841 |
|    n_updates       | 160138   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -3.9     |
| time/              |          |
|    episodes        | 644      |
|    fps             | 9        |
|    time_elapsed    | 16361    |
|    total timesteps | 161644   |
| train/             |          |
|    actor_loss      | 0.712    |
|    critic_loss     | 0.701    |
|    learning_rate   | 0.00084  |
|    n_updates       | 161142   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -2.89    |
| time/              |          |
|    episodes        | 648      |
|    fps             | 9        |
|    time_elapsed    | 16475    |
|    total timesteps | 162648   |
| train/             |          |
|    actor_loss      | 0.699    |
|    critic_loss     | 0.661    |
|    learning_rate   | 0.000839 |
|    n_updates       | 162146   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -2.54    |
| time/              |          |
|    episodes        | 652      |
|    fps             | 9        |
|    time_elapsed    | 16591    |
|    total timesteps | 163652   |
| train/             |          |
|    actor_loss      | 0.7      |
|    critic_loss     | 0.763    |
|    learning_rate   | 0.000838 |
|    n_updates       | 163150   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -3.04    |
| time/              |          |
|    episodes        | 656      |
|    fps             | 9        |
|    time_elapsed    | 16705    |
|    total timesteps | 164656   |
| train/             |          |
|    actor_loss      | 0.715    |
|    critic_loss     | 0.862    |
|    learning_rate   | 0.000837 |
|    n_updates       | 164154   |
---------------------------------
Eval num_timesteps=165000, episode_reward=9.99 +/- 0.85
Episode length: 251.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 251      |
|    mean_reward     | 9.99     |
| time/              |          |
|    total_timesteps | 165000   |
| train/             |          |
|    actor_loss      | 0.701    |
|    critic_loss     | 0.909    |
|    learning_rate   | 0.000837 |
|    n_updates       | 164656   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -2.46    |
| time/              |          |
|    episodes        | 660      |
|    fps             | 9        |
|    time_elapsed    | 16838    |
|    total timesteps | 165660   |
| train/             |          |
|    actor_loss      | 0.725    |
|    critic_loss     | 1.45     |
|    learning_rate   | 0.000836 |
|    n_updates       | 165158   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -2.15    |
| time/              |          |
|    episodes        | 664      |
|    fps             | 9        |
|    time_elapsed    | 16953    |
|    total timesteps | 166664   |
| train/             |          |
|    actor_loss      | 0.711    |
|    critic_loss     | 1.01     |
|    learning_rate   | 0.000835 |
|    n_updates       | 166162   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -2.01    |
| time/              |          |
|    episodes        | 668      |
|    fps             | 9        |
|    time_elapsed    | 17067    |
|    total timesteps | 167668   |
| train/             |          |
|    actor_loss      | 0.722    |
|    critic_loss     | 1.21     |
|    learning_rate   | 0.000834 |
|    n_updates       | 167166   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -0.911   |
| time/              |          |
|    episodes        | 672      |
|    fps             | 9        |
|    time_elapsed    | 17182    |
|    total timesteps | 168672   |
| train/             |          |
|    actor_loss      | 0.751    |
|    critic_loss     | 1.21     |
|    learning_rate   | 0.000833 |
|    n_updates       | 168170   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -1.2     |
| time/              |          |
|    episodes        | 676      |
|    fps             | 9        |
|    time_elapsed    | 17296    |
|    total timesteps | 169676   |
| train/             |          |
|    actor_loss      | 0.75     |
|    critic_loss     | 1.01     |
|    learning_rate   | 0.000832 |
|    n_updates       | 169174   |
---------------------------------
Eval num_timesteps=170000, episode_reward=10.16 +/- 0.43
Episode length: 251.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 251      |
|    mean_reward     | 10.2     |
| time/              |          |
|    total_timesteps | 170000   |
| train/             |          |
|    actor_loss      | 0.76     |
|    critic_loss     | 1.06     |
|    learning_rate   | 0.000832 |
|    n_updates       | 169676   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -0.913   |
| time/              |          |
|    episodes        | 680      |
|    fps             | 9        |
|    time_elapsed    | 17430    |
|    total timesteps | 170680   |
| train/             |          |
|    actor_loss      | 0.762    |
|    critic_loss     | 1.01     |
|    learning_rate   | 0.000831 |
|    n_updates       | 170178   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -0.898   |
| time/              |          |
|    episodes        | 684      |
|    fps             | 9        |
|    time_elapsed    | 17544    |
|    total timesteps | 171684   |
| train/             |          |
|    actor_loss      | 0.764    |
|    critic_loss     | 0.759    |
|    learning_rate   | 0.00083  |
|    n_updates       | 171182   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | 0.208    |
| time/              |          |
|    episodes        | 688      |
|    fps             | 9        |
|    time_elapsed    | 17657    |
|    total timesteps | 172688   |
| train/             |          |
|    actor_loss      | 0.76     |
|    critic_loss     | 1.06     |
|    learning_rate   | 0.000829 |
|    n_updates       | 172186   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -0.368   |
| time/              |          |
|    episodes        | 692      |
|    fps             | 9        |
|    time_elapsed    | 17772    |
|    total timesteps | 173692   |
| train/             |          |
|    actor_loss      | 0.737    |
|    critic_loss     | 0.915    |
|    learning_rate   | 0.000828 |
|    n_updates       | 173190   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | 0.0303   |
| time/              |          |
|    episodes        | 696      |
|    fps             | 9        |
|    time_elapsed    | 17886    |
|    total timesteps | 174696   |
| train/             |          |
|    actor_loss      | 0.722    |
|    critic_loss     | 0.96     |
|    learning_rate   | 0.000827 |
|    n_updates       | 174194   |
---------------------------------
Eval num_timesteps=175000, episode_reward=10.92 +/- 1.06
Episode length: 251.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 251      |
|    mean_reward     | 10.9     |
| time/              |          |
|    total_timesteps | 175000   |
| train/             |          |
|    actor_loss      | 0.724    |
|    critic_loss     | 1.25     |
|    learning_rate   | 0.000827 |
|    n_updates       | 174696   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | 0.165    |
| time/              |          |
|    episodes        | 700      |
|    fps             | 9        |
|    time_elapsed    | 18021    |
|    total timesteps | 175700   |
| train/             |          |
|    actor_loss      | 0.737    |
|    critic_loss     | 1.01     |
|    learning_rate   | 0.000826 |
|    n_updates       | 175198   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -0.235   |
| time/              |          |
|    episodes        | 704      |
|    fps             | 9        |
|    time_elapsed    | 18135    |
|    total timesteps | 176704   |
| train/             |          |
|    actor_loss      | 0.744    |
|    critic_loss     | 1.06     |
|    learning_rate   | 0.000825 |
|    n_updates       | 176202   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | 0.665    |
| time/              |          |
|    episodes        | 708      |
|    fps             | 9        |
|    time_elapsed    | 18249    |
|    total timesteps | 177708   |
| train/             |          |
|    actor_loss      | 0.767    |
|    critic_loss     | 1.11     |
|    learning_rate   | 0.000824 |
|    n_updates       | 177206   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | 1.25     |
| time/              |          |
|    episodes        | 712      |
|    fps             | 9        |
|    time_elapsed    | 18363    |
|    total timesteps | 178712   |
| train/             |          |
|    actor_loss      | 0.715    |
|    critic_loss     | 0.763    |
|    learning_rate   | 0.000823 |
|    n_updates       | 178210   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | 1.96     |
| time/              |          |
|    episodes        | 716      |
|    fps             | 9        |
|    time_elapsed    | 18477    |
|    total timesteps | 179716   |
| train/             |          |
|    actor_loss      | 0.714    |
|    critic_loss     | 1.11     |
|    learning_rate   | 0.000822 |
|    n_updates       | 179214   |
---------------------------------
Eval num_timesteps=180000, episode_reward=10.20 +/- 0.39
Episode length: 251.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 251      |
|    mean_reward     | 10.2     |
| time/              |          |
|    total_timesteps | 180000   |
| train/             |          |
|    actor_loss      | 0.73     |
|    critic_loss     | 1.21     |
|    learning_rate   | 0.000822 |
|    n_updates       | 179716   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | 1.8      |
| time/              |          |
|    episodes        | 720      |
|    fps             | 9        |
|    time_elapsed    | 18613    |
|    total timesteps | 180720   |
| train/             |          |
|    actor_loss      | 0.727    |
|    critic_loss     | 0.808    |
|    learning_rate   | 0.000821 |
|    n_updates       | 180218   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | 1.2      |
| time/              |          |
|    episodes        | 724      |
|    fps             | 9        |
|    time_elapsed    | 18727    |
|    total timesteps | 181724   |
| train/             |          |
|    actor_loss      | 0.717    |
|    critic_loss     | 0.811    |
|    learning_rate   | 0.00082  |
|    n_updates       | 181222   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | 1.4      |
| time/              |          |
|    episodes        | 728      |
|    fps             | 9        |
|    time_elapsed    | 18841    |
|    total timesteps | 182728   |
| train/             |          |
|    actor_loss      | 0.689    |
|    critic_loss     | 0.71     |
|    learning_rate   | 0.000819 |
|    n_updates       | 182226   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | 1.64     |
| time/              |          |
|    episodes        | 732      |
|    fps             | 9        |
|    time_elapsed    | 18955    |
|    total timesteps | 183732   |
| train/             |          |
|    actor_loss      | 0.693    |
|    critic_loss     | 0.763    |
|    learning_rate   | 0.000818 |
|    n_updates       | 183230   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | 1.91     |
| time/              |          |
|    episodes        | 736      |
|    fps             | 9        |
|    time_elapsed    | 19070    |
|    total timesteps | 184736   |
| train/             |          |
|    actor_loss      | 0.689    |
|    critic_loss     | 0.712    |
|    learning_rate   | 0.000817 |
|    n_updates       | 184234   |
---------------------------------
Eval num_timesteps=185000, episode_reward=9.45 +/- 0.22
Episode length: 251.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 251      |
|    mean_reward     | 9.45     |
| time/              |          |
|    total_timesteps | 185000   |
| train/             |          |
|    actor_loss      | 0.696    |
|    critic_loss     | 0.863    |
|    learning_rate   | 0.000817 |
|    n_updates       | 184736   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | 1.03     |
| time/              |          |
|    episodes        | 740      |
|    fps             | 9        |
|    time_elapsed    | 19205    |
|    total timesteps | 185740   |
| train/             |          |
|    actor_loss      | 0.709    |
|    critic_loss     | 1.16     |
|    learning_rate   | 0.000816 |
|    n_updates       | 185238   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | 2.38     |
| time/              |          |
|    episodes        | 744      |
|    fps             | 9        |
|    time_elapsed    | 19319    |
|    total timesteps | 186744   |
| train/             |          |
|    actor_loss      | 0.706    |
|    critic_loss     | 0.863    |
|    learning_rate   | 0.000815 |
|    n_updates       | 186242   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | 1.8      |
| time/              |          |
|    episodes        | 748      |
|    fps             | 9        |
|    time_elapsed    | 19434    |
|    total timesteps | 187748   |
| train/             |          |
|    actor_loss      | 0.692    |
|    critic_loss     | 0.862    |
|    learning_rate   | 0.000814 |
|    n_updates       | 187246   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | 0.923    |
| time/              |          |
|    episodes        | 752      |
|    fps             | 9        |
|    time_elapsed    | 19548    |
|    total timesteps | 188752   |
| train/             |          |
|    actor_loss      | 0.653    |
|    critic_loss     | 0.71     |
|    learning_rate   | 0.000813 |
|    n_updates       | 188250   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | 1.08     |
| time/              |          |
|    episodes        | 756      |
|    fps             | 9        |
|    time_elapsed    | 19662    |
|    total timesteps | 189756   |
| train/             |          |
|    actor_loss      | 0.663    |
|    critic_loss     | 1.11     |
|    learning_rate   | 0.000812 |
|    n_updates       | 189254   |
---------------------------------
Eval num_timesteps=190000, episode_reward=8.84 +/- 4.18
Episode length: 251.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 251      |
|    mean_reward     | 8.84     |
| time/              |          |
|    total_timesteps | 190000   |
| train/             |          |
|    actor_loss      | 0.68     |
|    critic_loss     | 1.36     |
|    learning_rate   | 0.000812 |
|    n_updates       | 189505   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | 0.319    |
| time/              |          |
|    episodes        | 760      |
|    fps             | 9        |
|    time_elapsed    | 19797    |
|    total timesteps | 190760   |
| train/             |          |
|    actor_loss      | 0.668    |
|    critic_loss     | 0.959    |
|    learning_rate   | 0.000811 |
|    n_updates       | 190258   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -0.444   |
| time/              |          |
|    episodes        | 764      |
|    fps             | 9        |
|    time_elapsed    | 19912    |
|    total timesteps | 191764   |
| train/             |          |
|    actor_loss      | 0.66     |
|    critic_loss     | 0.81     |
|    learning_rate   | 0.00081  |
|    n_updates       | 191262   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -0.494   |
| time/              |          |
|    episodes        | 768      |
|    fps             | 9        |
|    time_elapsed    | 20025    |
|    total timesteps | 192768   |
| train/             |          |
|    actor_loss      | 0.653    |
|    critic_loss     | 1.06     |
|    learning_rate   | 0.000809 |
|    n_updates       | 192266   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -0.445   |
| time/              |          |
|    episodes        | 772      |
|    fps             | 9        |
|    time_elapsed    | 20140    |
|    total timesteps | 193772   |
| train/             |          |
|    actor_loss      | 0.665    |
|    critic_loss     | 0.907    |
|    learning_rate   | 0.000808 |
|    n_updates       | 193270   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -0.744   |
| time/              |          |
|    episodes        | 776      |
|    fps             | 9        |
|    time_elapsed    | 20253    |
|    total timesteps | 194776   |
| train/             |          |
|    actor_loss      | 0.662    |
|    critic_loss     | 1.16     |
|    learning_rate   | 0.000807 |
|    n_updates       | 194274   |
---------------------------------
Eval num_timesteps=195000, episode_reward=10.36 +/- 0.96
Episode length: 251.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 251      |
|    mean_reward     | 10.4     |
| time/              |          |
|    total_timesteps | 195000   |
| train/             |          |
|    actor_loss      | 0.674    |
|    critic_loss     | 0.964    |
|    learning_rate   | 0.000807 |
|    n_updates       | 194525   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -1.12    |
| time/              |          |
|    episodes        | 780      |
|    fps             | 9        |
|    time_elapsed    | 20388    |
|    total timesteps | 195780   |
| train/             |          |
|    actor_loss      | 0.662    |
|    critic_loss     | 0.912    |
|    learning_rate   | 0.000806 |
|    n_updates       | 195278   |
---------------------------------
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/xml/etree/ElementTree.py", line 789, in _get_writer
AttributeError: 'str' object has no attribute 'write'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "train.py", line 82, in <module>
  File "/home/shandilya/Desktop/Projects/NavigationController/learning/explore.py", line 208, in learn
  File "/home/shandilya/py36/lib/python3.6/site-packages/stable_baselines3/td3/td3.py", line 211, in learn
  File "/home/shandilya/py36/lib/python3.6/site-packages/stable_baselines3/common/off_policy_algorithm.py", line 359, in learn
  File "/home/shandilya/py36/lib/python3.6/site-packages/stable_baselines3/common/off_policy_algorithm.py", line 566, in collect_rollouts
  File "/home/shandilya/py36/lib/python3.6/site-packages/stable_baselines3/common/vec_env/base_vec_env.py", line 162, in step
  File "/home/shandilya/py36/lib/python3.6/site-packages/stable_baselines3/common/vec_env/vec_transpose.py", line 83, in step_wait
  File "/home/shandilya/py36/lib/python3.6/site-packages/stable_baselines3/common/vec_env/dummy_vec_env.py", line 49, in step_wait
  File "/home/shandilya/py36/lib/python3.6/site-packages/stable_baselines3/common/monitor.py", line 79, in reset
  File "/home/shandilya/Desktop/Projects/NavigationController/simulations/maze_env.py", line 475, in reset
  File "/home/shandilya/Desktop/Projects/NavigationController/simulations/maze_env.py", line 220, in set_env
  File "/usr/local/lib/python3.6/xml/etree/ElementTree.py", line 759, in write
  File "/usr/local/lib/python3.6/contextlib.py", line 81, in __enter__
  File "/usr/local/lib/python3.6/xml/etree/ElementTree.py", line 796, in _get_writer
OSError: [Errno 24] Too many open files: '/tmp/tmp0sil52jw.xml'
