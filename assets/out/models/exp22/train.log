2021-12-23 11:50:36.663070: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/shandilya/.mujoco/mjpro150/bin
2021-12-23 11:50:36.663285: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
/home/shandilya/Desktop/Projects/NavigationController
Env Type: maze
Task: GoalRewardNoObstacle
Model: <class 'utils.rtd3_utils.RTD3'>
Policy: <class 'utils.rtd3_utils.RecurrentTD3Policy'>
Replay Buffer: <class 'utils.rtd3_utils.EpisodicDictReplayBuffer'>
Using cpu device
2880
2880
Logging to assets/out/models/exp22/TD3_1
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 132      |
|    ep_rew_mean     | -10      |
| time/              |          |
|    episodes        | 4        |
|    fps             | 43       |
|    time_elapsed    | 12       |
|    total timesteps | 528      |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 131      |
|    ep_rew_mean     | -10      |
| time/              |          |
|    episodes        | 8        |
|    fps             | 51       |
|    time_elapsed    | 20       |
|    total timesteps | 1046     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 95.5     |
|    ep_rew_mean     | -10      |
| time/              |          |
|    episodes        | 12       |
|    fps             | 19       |
|    time_elapsed    | 58       |
|    total timesteps | 1146     |
| train/             |          |
|    actor_loss      | 0.707    |
|    critic_loss     | 8.05     |
|    learning_rate   | 0.000999 |
|    n_updates       | 194      |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 78.6     |
|    ep_rew_mean     | -10      |
| time/              |          |
|    episodes        | 16       |
|    fps             | 15       |
|    time_elapsed    | 80       |
|    total timesteps | 1258     |
| train/             |          |
|    actor_loss      | 0.0381   |
|    critic_loss     | 0.306    |
|    learning_rate   | 0.000999 |
|    n_updates       | 295      |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 67.7     |
|    ep_rew_mean     | -10      |
| time/              |          |
|    episodes        | 20       |
|    fps             | 13       |
|    time_elapsed    | 103      |
|    total timesteps | 1354     |
| train/             |          |
|    actor_loss      | -0.104   |
|    critic_loss     | 0.949    |
|    learning_rate   | 0.000999 |
|    n_updates       | 404      |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 60.7     |
|    ep_rew_mean     | -10      |
| time/              |          |
|    episodes        | 24       |
|    fps             | 11       |
|    time_elapsed    | 124      |
|    total timesteps | 1457     |
| train/             |          |
|    actor_loss      | 0.11     |
|    critic_loss     | 0.1      |
|    learning_rate   | 0.000999 |
|    n_updates       | 504      |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 55.8     |
|    ep_rew_mean     | -10      |
| time/              |          |
|    episodes        | 28       |
|    fps             | 10       |
|    time_elapsed    | 147      |
|    total timesteps | 1561     |
| train/             |          |
|    actor_loss      | 0.105    |
|    critic_loss     | 0.00782  |
|    learning_rate   | 0.000998 |
|    n_updates       | 609      |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 52.2     |
|    ep_rew_mean     | -10      |
| time/              |          |
|    episodes        | 32       |
|    fps             | 9        |
|    time_elapsed    | 168      |
|    total timesteps | 1669     |
| train/             |          |
|    actor_loss      | 0.246    |
|    critic_loss     | 0.00825  |
|    learning_rate   | 0.000998 |
|    n_updates       | 711      |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 49.1     |
|    ep_rew_mean     | -10      |
| time/              |          |
|    episodes        | 36       |
|    fps             | 9        |
|    time_elapsed    | 190      |
|    total timesteps | 1766     |
| train/             |          |
|    actor_loss      | 0.426    |
|    critic_loss     | 0.0107   |
|    learning_rate   | 0.000998 |
|    n_updates       | 811      |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 46.8     |
|    ep_rew_mean     | -10      |
| time/              |          |
|    episodes        | 40       |
|    fps             | 8        |
|    time_elapsed    | 213      |
|    total timesteps | 1872     |
| train/             |          |
|    actor_loss      | 0.444    |
|    critic_loss     | 0.0125   |
|    learning_rate   | 0.000998 |
|    n_updates       | 921      |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 45.2     |
|    ep_rew_mean     | -10      |
| time/              |          |
|    episodes        | 44       |
|    fps             | 8        |
|    time_elapsed    | 237      |
|    total timesteps | 1987     |
| train/             |          |
|    actor_loss      | 0.455    |
|    critic_loss     | 0.0091   |
|    learning_rate   | 0.000998 |
|    n_updates       | 1028     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 43.4     |
|    ep_rew_mean     | -10      |
| time/              |          |
|    episodes        | 48       |
|    fps             | 8        |
|    time_elapsed    | 259      |
|    total timesteps | 2085     |
| train/             |          |
|    actor_loss      | 0.598    |
|    critic_loss     | 0.0223   |
|    learning_rate   | 0.000998 |
|    n_updates       | 1132     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 42.2     |
|    ep_rew_mean     | -10      |
| time/              |          |
|    episodes        | 52       |
|    fps             | 7        |
|    time_elapsed    | 282      |
|    total timesteps | 2194     |
| train/             |          |
|    actor_loss      | 0.57     |
|    critic_loss     | 0.0203   |
|    learning_rate   | 0.000998 |
|    n_updates       | 1241     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 41.1     |
|    ep_rew_mean     | -10      |
| time/              |          |
|    episodes        | 56       |
|    fps             | 7        |
|    time_elapsed    | 305      |
|    total timesteps | 2303     |
| train/             |          |
|    actor_loss      | 0.579    |
|    critic_loss     | 0.00736  |
|    learning_rate   | 0.000998 |
|    n_updates       | 1351     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 40.1     |
|    ep_rew_mean     | -10      |
| time/              |          |
|    episodes        | 60       |
|    fps             | 7        |
|    time_elapsed    | 327      |
|    total timesteps | 2404     |
| train/             |          |
|    actor_loss      | 0.181    |
|    critic_loss     | 0.0777   |
|    learning_rate   | 0.000998 |
|    n_updates       | 1452     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 39.3     |
|    ep_rew_mean     | -10      |
| time/              |          |
|    episodes        | 64       |
|    fps             | 7        |
|    time_elapsed    | 351      |
|    total timesteps | 2517     |
| train/             |          |
|    actor_loss      | 0.207    |
|    critic_loss     | 0.227    |
|    learning_rate   | 0.000998 |
|    n_updates       | 1567     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 38.6     |
|    ep_rew_mean     | -10      |
| time/              |          |
|    episodes        | 68       |
|    fps             | 7        |
|    time_elapsed    | 372      |
|    total timesteps | 2623     |
| train/             |          |
|    actor_loss      | 0.516    |
|    critic_loss     | 0.0399   |
|    learning_rate   | 0.000997 |
|    n_updates       | 1664     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 37.9     |
|    ep_rew_mean     | -10      |
| time/              |          |
|    episodes        | 72       |
|    fps             | 6        |
|    time_elapsed    | 394      |
|    total timesteps | 2727     |
| train/             |          |
|    actor_loss      | 0.628    |
|    critic_loss     | 0.0122   |
|    learning_rate   | 0.000997 |
|    n_updates       | 1771     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 37.2     |
|    ep_rew_mean     | -10      |
| time/              |          |
|    episodes        | 76       |
|    fps             | 6        |
|    time_elapsed    | 416      |
|    total timesteps | 2824     |
| train/             |          |
|    actor_loss      | 0.829    |
|    critic_loss     | 0.0266   |
|    learning_rate   | 0.000997 |
|    n_updates       | 1872     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 36.6     |
|    ep_rew_mean     | -10      |
| time/              |          |
|    episodes        | 80       |
|    fps             | 6        |
|    time_elapsed    | 437      |
|    total timesteps | 2925     |
| train/             |          |
|    actor_loss      | 1.17     |
|    critic_loss     | 0.0292   |
|    learning_rate   | 0.000997 |
|    n_updates       | 1973     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 36       |
|    ep_rew_mean     | -10      |
| time/              |          |
|    episodes        | 84       |
|    fps             | 6        |
|    time_elapsed    | 459      |
|    total timesteps | 3028     |
| train/             |          |
|    actor_loss      | 1.76     |
|    critic_loss     | 0.136    |
|    learning_rate   | 0.000997 |
|    n_updates       | 2076     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 35.6     |
|    ep_rew_mean     | -10      |
| time/              |          |
|    episodes        | 88       |
|    fps             | 6        |
|    time_elapsed    | 481      |
|    total timesteps | 3130     |
| train/             |          |
|    actor_loss      | 2.56     |
|    critic_loss     | 4.2      |
|    learning_rate   | 0.000997 |
|    n_updates       | 2176     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 35.2     |
|    ep_rew_mean     | -10      |
| time/              |          |
|    episodes        | 92       |
|    fps             | 6        |
|    time_elapsed    | 503      |
|    total timesteps | 3237     |
| train/             |          |
|    actor_loss      | 3.01     |
|    critic_loss     | 0.995    |
|    learning_rate   | 0.000997 |
|    n_updates       | 2285     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 34.8     |
|    ep_rew_mean     | -10      |
| time/              |          |
|    episodes        | 96       |
|    fps             | 6        |
|    time_elapsed    | 525      |
|    total timesteps | 3336     |
| train/             |          |
|    actor_loss      | 3.62     |
|    critic_loss     | 1.05     |
|    learning_rate   | 0.000997 |
|    n_updates       | 2385     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 34.4     |
|    ep_rew_mean     | -10      |
| time/              |          |
|    episodes        | 100      |
|    fps             | 6        |
|    time_elapsed    | 545      |
|    total timesteps | 3435     |
| train/             |          |
|    actor_loss      | 4.1      |
|    critic_loss     | 0.515    |
|    learning_rate   | 0.000997 |
|    n_updates       | 2482     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 30       |
|    ep_rew_mean     | -10      |
| time/              |          |
|    episodes        | 104      |
|    fps             | 6        |
|    time_elapsed    | 566      |
|    total timesteps | 3530     |
| train/             |          |
|    actor_loss      | 4.42     |
|    critic_loss     | 0.925    |
|    learning_rate   | 0.000997 |
|    n_updates       | 2578     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 25.8     |
|    ep_rew_mean     | -10      |
| time/              |          |
|    episodes        | 108      |
|    fps             | 6        |
|    time_elapsed    | 587      |
|    total timesteps | 3628     |
| train/             |          |
|    actor_loss      | 4.95     |
|    critic_loss     | 4.66     |
|    learning_rate   | 0.000996 |
|    n_updates       | 2677     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 25.9     |
|    ep_rew_mean     | -10      |
| time/              |          |
|    episodes        | 112      |
|    fps             | 6        |
|    time_elapsed    | 610      |
|    total timesteps | 3735     |
| train/             |          |
|    actor_loss      | 5.8      |
|    critic_loss     | 37.6     |
|    learning_rate   | 0.000996 |
|    n_updates       | 2784     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 25.8     |
|    ep_rew_mean     | -10      |
| time/              |          |
|    episodes        | 116      |
|    fps             | 6        |
|    time_elapsed    | 630      |
|    total timesteps | 3834     |
| train/             |          |
|    actor_loss      | 5.9      |
|    critic_loss     | 1.59     |
|    learning_rate   | 0.000996 |
|    n_updates       | 2882     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 25.9     |
|    ep_rew_mean     | -10      |
| time/              |          |
|    episodes        | 120      |
|    fps             | 6        |
|    time_elapsed    | 652      |
|    total timesteps | 3939     |
| train/             |          |
|    actor_loss      | 6.2      |
|    critic_loss     | 1.36     |
|    learning_rate   | 0.000996 |
|    n_updates       | 2984     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 25.8     |
|    ep_rew_mean     | -10      |
| time/              |          |
|    episodes        | 124      |
|    fps             | 5        |
|    time_elapsed    | 675      |
|    total timesteps | 4040     |
| train/             |          |
|    actor_loss      | 6.72     |
|    critic_loss     | 1.27     |
|    learning_rate   | 0.000996 |
|    n_updates       | 3087     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 25.9     |
|    ep_rew_mean     | -10      |
| time/              |          |
|    episodes        | 128      |
|    fps             | 5        |
|    time_elapsed    | 699      |
|    total timesteps | 4155     |
| train/             |          |
|    actor_loss      | 7.55     |
|    critic_loss     | 0.652    |
|    learning_rate   | 0.000996 |
|    n_updates       | 3197     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 25.9     |
|    ep_rew_mean     | -10      |
| time/              |          |
|    episodes        | 132      |
|    fps             | 5        |
|    time_elapsed    | 723      |
|    total timesteps | 4257     |
| train/             |          |
|    actor_loss      | 7.28     |
|    critic_loss     | 1.08     |
|    learning_rate   | 0.000996 |
|    n_updates       | 3298     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 26       |
|    ep_rew_mean     | -10      |
| time/              |          |
|    episodes        | 136      |
|    fps             | 5        |
|    time_elapsed    | 748      |
|    total timesteps | 4362     |
| train/             |          |
|    actor_loss      | 7.03     |
|    critic_loss     | 1.06     |
|    learning_rate   | 0.000996 |
|    n_updates       | 3408     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 26       |
|    ep_rew_mean     | -10      |
| time/              |          |
|    episodes        | 140      |
|    fps             | 5        |
|    time_elapsed    | 773      |
|    total timesteps | 4472     |
| train/             |          |
|    actor_loss      | 7.19     |
|    critic_loss     | 0.55     |
|    learning_rate   | 0.000996 |
|    n_updates       | 3518     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 25.9     |
|    ep_rew_mean     | -10      |
| time/              |          |
|    episodes        | 144      |
|    fps             | 5        |
|    time_elapsed    | 797      |
|    total timesteps | 4577     |
| train/             |          |
|    actor_loss      | 6.8      |
|    critic_loss     | 0.698    |
|    learning_rate   | 0.000995 |
|    n_updates       | 3620     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 25.9     |
|    ep_rew_mean     | -10      |
| time/              |          |
|    episodes        | 148      |
|    fps             | 5        |
|    time_elapsed    | 819      |
|    total timesteps | 4670     |
| train/             |          |
|    actor_loss      | 6.69     |
|    critic_loss     | 0.851    |
|    learning_rate   | 0.000995 |
|    n_updates       | 3719     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 25.7     |
|    ep_rew_mean     | -10      |
| time/              |          |
|    episodes        | 152      |
|    fps             | 5        |
|    time_elapsed    | 842      |
|    total timesteps | 4768     |
| train/             |          |
|    actor_loss      | 6.46     |
|    critic_loss     | 0.369    |
|    learning_rate   | 0.000995 |
|    n_updates       | 3813     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 25.7     |
|    ep_rew_mean     | -10      |
| time/              |          |
|    episodes        | 156      |
|    fps             | 5        |
|    time_elapsed    | 867      |
|    total timesteps | 4869     |
| train/             |          |
|    actor_loss      | 6.12     |
|    critic_loss     | 0.259    |
|    learning_rate   | 0.000995 |
|    n_updates       | 3917     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 25.7     |
|    ep_rew_mean     | -10      |
| time/              |          |
|    episodes        | 160      |
|    fps             | 5        |
|    time_elapsed    | 891      |
|    total timesteps | 4972     |
| train/             |          |
|    actor_loss      | 5.8      |
|    critic_loss     | 1.12     |
|    learning_rate   | 0.000995 |
|    n_updates       | 4013     |
---------------------------------
Terminated
2021-12-23 12:05:50.732739: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/shandilya/.mujoco/mjpro150/bin
2021-12-23 12:05:50.732773: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
/home/shandilya/Desktop/Projects/NavigationController
Env Type: maze
Task: GoalRewardNoObstacle
Model: <class 'utils.rtd3_utils.RTD3'>
Policy: <class 'utils.rtd3_utils.RecurrentTD3Policy'>
Replay Buffer: <class 'utils.rtd3_utils.EpisodicDictReplayBuffer'>
Using cpu device
2880
2880
Logging to assets/out/models/exp22/TD3_2
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 132      |
|    ep_rew_mean     | -10      |
| time/              |          |
|    episodes        | 4        |
|    fps             | 56       |
|    time_elapsed    | 9        |
|    total timesteps | 528      |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 132      |
|    ep_rew_mean     | -10      |
| time/              |          |
|    episodes        | 8        |
|    fps             | 60       |
|    time_elapsed    | 17       |
|    total timesteps | 1056     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 255      |
|    ep_rew_mean     | -5.74    |
| time/              |          |
|    episodes        | 12       |
|    fps             | 6        |
|    time_elapsed    | 464      |
|    total timesteps | 3060     |
| train/             |          |
|    actor_loss      | 1.01     |
|    critic_loss     | 0.565    |
|    learning_rate   | 0.000997 |
|    n_updates       | 1615     |
---------------------------------
Eval num_timesteps=5000, episode_reward=-0.06 +/- 0.79
Episode length: 501.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 501      |
|    mean_reward     | -0.0621  |
| time/              |          |
|    total_timesteps | 5000     |
| train/             |          |
|    actor_loss      | 0.0956   |
|    critic_loss     | 0.0207   |
|    learning_rate   | 0.000995 |
|    n_updates       | 3619     |
---------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 316      |
|    ep_rew_mean     | -4.02    |
| time/              |          |
|    episodes        | 16       |
|    fps             | 3        |
|    time_elapsed    | 1311     |
|    total timesteps | 5064     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 353      |
|    ep_rew_mean     | -2.9     |
| time/              |          |
|    episodes        | 20       |
|    fps             | 3        |
|    time_elapsed    | 2111     |
|    total timesteps | 7068     |
| train/             |          |
|    actor_loss      | 0.0437   |
|    critic_loss     | 0.00135  |
|    learning_rate   | 0.000993 |
|    n_updates       | 5623     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 378      |
|    ep_rew_mean     | -1.95    |
| time/              |          |
|    episodes        | 24       |
|    fps             | 3        |
|    time_elapsed    | 2896     |
|    total timesteps | 9072     |
| train/             |          |
|    actor_loss      | 0.0154   |
|    critic_loss     | 0.000184 |
|    learning_rate   | 0.000992 |
|    n_updates       | 7627     |
---------------------------------
Eval num_timesteps=10000, episode_reward=0.17 +/- 0.52
Episode length: 501.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 501      |
|    mean_reward     | 0.17     |
| time/              |          |
|    total_timesteps | 10000    |
| train/             |          |
|    actor_loss      | 0.00851  |
|    critic_loss     | 0.000118 |
|    learning_rate   | 0.000991 |
|    n_updates       | 8629     |
---------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 394      |
|    ep_rew_mean     | -1.76    |
| time/              |          |
|    episodes        | 28       |
|    fps             | 2        |
|    time_elapsed    | 3722     |
|    total timesteps | 11041    |
| train/             |          |
|    actor_loss      | 0.0025   |
|    critic_loss     | 0.000101 |
|    learning_rate   | 0.00099  |
|    n_updates       | 9596     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 408      |
|    ep_rew_mean     | -0.862   |
| time/              |          |
|    episodes        | 32       |
|    fps             | 2        |
|    time_elapsed    | 4503     |
|    total timesteps | 13045    |
| train/             |          |
|    actor_loss      | 0.0017   |
|    critic_loss     | 6.49e-06 |
|    learning_rate   | 0.000988 |
|    n_updates       | 11600    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 416      |
|    ep_rew_mean     | -0.64    |
| time/              |          |
|    episodes        | 36       |
|    fps             | 2        |
|    time_elapsed    | 5256     |
|    total timesteps | 14975    |
| train/             |          |
|    actor_loss      | -0.003   |
|    critic_loss     | 1.36e-05 |
|    learning_rate   | 0.000986 |
|    n_updates       | 13530    |
---------------------------------
Eval num_timesteps=15000, episode_reward=0.11 +/- 0.51
Episode length: 501.00 +/- 0.00
----------------------------------
| eval/              |           |
|    mean_ep_length  | 501       |
|    mean_reward     | 0.106     |
| time/              |           |
|    total_timesteps | 15000     |
| train/             |           |
|    actor_loss      | -0.000659 |
|    critic_loss     | 1.07e-05  |
|    learning_rate   | 0.000985  |
|    n_updates       | 14031     |
----------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 424      |
|    ep_rew_mean     | 0.283    |
| time/              |          |
|    episodes        | 40       |
|    fps             | 2        |
|    time_elapsed    | 6095     |
|    total timesteps | 16979    |
| train/             |          |
|    actor_loss      | -0.00249 |
|    critic_loss     | 0.000359 |
|    learning_rate   | 0.000984 |
|    n_updates       | 15534    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 431      |
|    ep_rew_mean     | 0.513    |
| time/              |          |
|    episodes        | 44       |
|    fps             | 2        |
|    time_elapsed    | 6876     |
|    total timesteps | 18983    |
| train/             |          |
|    actor_loss      | -0.00172 |
|    critic_loss     | 6.83e-06 |
|    learning_rate   | 0.000982 |
|    n_updates       | 17538    |
---------------------------------
Eval num_timesteps=20000, episode_reward=-0.51 +/- 0.38
Episode length: 501.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 501      |
|    mean_reward     | -0.51    |
| time/              |          |
|    total_timesteps | 20000    |
| train/             |          |
|    actor_loss      | -0.00507 |
|    critic_loss     | 5.89e-05 |
|    learning_rate   | 0.00098  |
|    n_updates       | 19041    |
---------------------------------
Terminated
2021-12-23 14:12:19.964764: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/shandilya/.mujoco/mjpro150/bin
2021-12-23 14:12:19.964806: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
/home/shandilya/Desktop/Projects/NavigationController
Env Type: maze
Task: GoalRewardNoObstacle
Model: <class 'utils.rtd3_utils.RTD3'>
Policy: <class 'utils.rtd3_utils.RecurrentTD3Policy'>
Replay Buffer: <class 'utils.rtd3_utils.EpisodicDictReplayBuffer'>
Using cpu device
2880
2880
Logging to assets/out/models/exp22/TD3_3
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 144      |
|    ep_rew_mean     | -10      |
| time/              |          |
|    episodes        | 4        |
|    fps             | 56       |
|    time_elapsed    | 10       |
|    total timesteps | 577      |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 133      |
|    ep_rew_mean     | -10      |
| time/              |          |
|    episodes        | 8        |
|    fps             | 59       |
|    time_elapsed    | 17       |
|    total timesteps | 1065     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 256      |
|    ep_rew_mean     | -4.55    |
| time/              |          |
|    episodes        | 12       |
|    fps             | 8        |
|    time_elapsed    | 383      |
|    total timesteps | 3069     |
| train/             |          |
|    actor_loss      | 0.101    |
|    critic_loss     | 0.000658 |
|    learning_rate   | 0.000997 |
|    n_updates       | 1611     |
---------------------------------
Eval num_timesteps=5000, episode_reward=-0.05 +/- 0.50
Episode length: 501.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 501      |
|    mean_reward     | -0.0547  |
| time/              |          |
|    total_timesteps | 5000     |
| train/             |          |
|    actor_loss      | 0.0329   |
|    critic_loss     | 0.00163  |
|    learning_rate   | 0.000995 |
|    n_updates       | 3615     |
---------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 317      |
|    ep_rew_mean     | -3.26    |
| time/              |          |
|    episodes        | 16       |
|    fps             | 4        |
|    time_elapsed    | 1025     |
|    total timesteps | 5073     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 354      |
|    ep_rew_mean     | -2.03    |
| time/              |          |
|    episodes        | 20       |
|    fps             | 4        |
|    time_elapsed    | 1710     |
|    total timesteps | 7077     |
| train/             |          |
|    actor_loss      | 0.00841  |
|    critic_loss     | 0.000122 |
|    learning_rate   | 0.000993 |
|    n_updates       | 5619     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 378      |
|    ep_rew_mean     | -1.37    |
| time/              |          |
|    episodes        | 24       |
|    fps             | 3        |
|    time_elapsed    | 2406     |
|    total timesteps | 9081     |
| train/             |          |
|    actor_loss      | 0.0158   |
|    critic_loss     | 0.000248 |
|    learning_rate   | 0.000992 |
|    n_updates       | 7623     |
---------------------------------
Eval num_timesteps=10000, episode_reward=0.22 +/- 0.79
Episode length: 501.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 501      |
|    mean_reward     | 0.218    |
| time/              |          |
|    total_timesteps | 10000    |
| train/             |          |
|    actor_loss      | 0.00428  |
|    critic_loss     | 4e-05    |
|    learning_rate   | 0.000991 |
|    n_updates       | 8625     |
---------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 396      |
|    ep_rew_mean     | -0.681   |
| time/              |          |
|    episodes        | 28       |
|    fps             | 3        |
|    time_elapsed    | 3194     |
|    total timesteps | 11085    |
| train/             |          |
|    actor_loss      | 0.00187  |
|    critic_loss     | 7.53e-06 |
|    learning_rate   | 0.00099  |
|    n_updates       | 9627     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 409      |
|    ep_rew_mean     | 0.164    |
| time/              |          |
|    episodes        | 32       |
|    fps             | 3        |
|    time_elapsed    | 3916     |
|    total timesteps | 13089    |
| train/             |          |
|    actor_loss      | 0.000309 |
|    critic_loss     | 3.28e-07 |
|    learning_rate   | 0.000988 |
|    n_updates       | 11631    |
---------------------------------
Eval num_timesteps=15000, episode_reward=0.08 +/- 0.59
Episode length: 501.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 501      |
|    mean_reward     | 0.0763   |
| time/              |          |
|    total_timesteps | 15000    |
| train/             |          |
|    actor_loss      | 0.000106 |
|    critic_loss     | 1.5e-08  |
|    learning_rate   | 0.000986 |
|    n_updates       | 13635    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 419      |
|    ep_rew_mean     | 0.952    |
| time/              |          |
|    episodes        | 36       |
|    fps             | 3        |
|    time_elapsed    | 4698     |
|    total timesteps | 15093    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 385      |
|    ep_rew_mean     | 0.0954   |
| time/              |          |
|    episodes        | 40       |
|    fps             | 3        |
|    time_elapsed    | 4952     |
|    total timesteps | 15399    |
| train/             |          |
|    actor_loss      | 5.67e-06 |
|    critic_loss     | 1.94e-09 |
|    learning_rate   | 0.000985 |
|    n_updates       | 14363    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 357      |
|    ep_rew_mean     | -0.63    |
| time/              |          |
|    episodes        | 44       |
|    fps             | 3        |
|    time_elapsed    | 5063     |
|    total timesteps | 15697    |
| train/             |          |
|    actor_loss      | 2.49e-05 |
|    critic_loss     | 6.15e-10 |
|    learning_rate   | 0.000985 |
|    n_updates       | 14667    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 333      |
|    ep_rew_mean     | -1.23    |
| time/              |          |
|    episodes        | 48       |
|    fps             | 3        |
|    time_elapsed    | 5175     |
|    total timesteps | 16007    |
| train/             |          |
|    actor_loss      | 4.72e-07 |
|    critic_loss     | 4.4e-10  |
|    learning_rate   | 0.000984 |
|    n_updates       | 14973    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 314      |
|    ep_rew_mean     | -1.74    |
| time/              |          |
|    episodes        | 52       |
|    fps             | 3        |
|    time_elapsed    | 5287     |
|    total timesteps | 16314    |
| train/             |          |
|    actor_loss      | 1.44e-05 |
|    critic_loss     | 1.27e-09 |
|    learning_rate   | 0.000984 |
|    n_updates       | 15283    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 297      |
|    ep_rew_mean     | -2.17    |
| time/              |          |
|    episodes        | 56       |
|    fps             | 3        |
|    time_elapsed    | 5394     |
|    total timesteps | 16610    |
| train/             |          |
|    actor_loss      | 6.28e-06 |
|    critic_loss     | 1.42e-10 |
|    learning_rate   | 0.000984 |
|    n_updates       | 15579    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 282      |
|    ep_rew_mean     | -2.54    |
| time/              |          |
|    episodes        | 60       |
|    fps             | 3        |
|    time_elapsed    | 5501     |
|    total timesteps | 16908    |
| train/             |          |
|    actor_loss      | 2.06e-05 |
|    critic_loss     | 3.64e-08 |
|    learning_rate   | 0.000983 |
|    n_updates       | 15872    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 269      |
|    ep_rew_mean     | -2.87    |
| time/              |          |
|    episodes        | 64       |
|    fps             | 3        |
|    time_elapsed    | 5601     |
|    total timesteps | 17215    |
| train/             |          |
|    actor_loss      | 0.00751  |
|    critic_loss     | 7.48e-05 |
|    learning_rate   | 0.000983 |
|    n_updates       | 16182    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 258      |
|    ep_rew_mean     | -3.15    |
| time/              |          |
|    episodes        | 68       |
|    fps             | 3        |
|    time_elapsed    | 5702     |
|    total timesteps | 17517    |
| train/             |          |
|    actor_loss      | 0.0102   |
|    critic_loss     | 0.000138 |
|    learning_rate   | 0.000983 |
|    n_updates       | 16488    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 247      |
|    ep_rew_mean     | -3.41    |
| time/              |          |
|    episodes        | 72       |
|    fps             | 3        |
|    time_elapsed    | 5798     |
|    total timesteps | 17816    |
| train/             |          |
|    actor_loss      | 0.0116   |
|    critic_loss     | 0.00126  |
|    learning_rate   | 0.000982 |
|    n_updates       | 16786    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 239      |
|    ep_rew_mean     | -3.63    |
| time/              |          |
|    episodes        | 76       |
|    fps             | 3        |
|    time_elapsed    | 5904     |
|    total timesteps | 18130    |
| train/             |          |
|    actor_loss      | -0.0155  |
|    critic_loss     | 0.0147   |
|    learning_rate   | 0.000982 |
|    n_updates       | 17099    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 231      |
|    ep_rew_mean     | -3.84    |
| time/              |          |
|    episodes        | 80       |
|    fps             | 3        |
|    time_elapsed    | 6011     |
|    total timesteps | 18445    |
| train/             |          |
|    actor_loss      | -0.00395 |
|    critic_loss     | 0.00999  |
|    learning_rate   | 0.000982 |
|    n_updates       | 17412    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 223      |
|    ep_rew_mean     | -4.03    |
| time/              |          |
|    episodes        | 84       |
|    fps             | 3        |
|    time_elapsed    | 6099     |
|    total timesteps | 18759    |
| train/             |          |
|    actor_loss      | -0.011   |
|    critic_loss     | 0.0124   |
|    learning_rate   | 0.000982 |
|    n_updates       | 17719    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 217      |
|    ep_rew_mean     | -4.21    |
| time/              |          |
|    episodes        | 88       |
|    fps             | 3        |
|    time_elapsed    | 6208     |
|    total timesteps | 19078    |
| train/             |          |
|    actor_loss      | -0.00226 |
|    critic_loss     | 1.04e-05 |
|    learning_rate   | 0.000981 |
|    n_updates       | 18048    |
---------------------------------
Terminated
2021-12-23 16:00:44.174968: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/shandilya/.mujoco/mjpro150/bin
2021-12-23 16:00:44.175004: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
/home/shandilya/Desktop/Projects/NavigationController
Env Type: maze
Task: GoalRewardNoObstacle
Model: <class 'utils.rtd3_utils.RTD3'>
Policy: <class 'utils.rtd3_utils.RecurrentTD3Policy'>
Replay Buffer: <class 'utils.rtd3_utils.EpisodicDictReplayBuffer'>
Using cpu device
2880
2880
Logging to assets/out/models/exp22/TD3_9
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 82.5     |
|    ep_rew_mean     | -10      |
| time/              |          |
|    episodes        | 4        |
|    fps             | 6        |
|    time_elapsed    | 49       |
|    total timesteps | 330      |
| train/             |          |
|    actor_loss      | -0.922   |
|    critic_loss     | 12.7     |
|    learning_rate   | 0.001    |
|    n_updates       | 159      |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 54.2     |
|    ep_rew_mean     | -10      |
| time/              |          |
|    episodes        | 8        |
|    fps             | 5        |
|    time_elapsed    | 79       |
|    total timesteps | 434      |
| train/             |          |
|    actor_loss      | 0.898    |
|    critic_loss     | 2.31     |
|    learning_rate   | 0.001    |
|    n_updates       | 263      |
---------------------------------
Terminated
2021-12-23 16:02:28.193096: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/shandilya/.mujoco/mjpro150/bin
2021-12-23 16:02:28.193139: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
/home/shandilya/Desktop/Projects/NavigationController
Env Type: maze
Task: GoalRewardNoObstacle
Model: <class 'utils.rtd3_utils.RTD3'>
Policy: <class 'utils.rtd3_utils.RecurrentTD3Policy'>
Replay Buffer: <class 'utils.rtd3_utils.EpisodicDictReplayBuffer'>
Using cpu device
2880
2880
Logging to assets/out/models/exp22/TD3_10
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 81.8     |
|    ep_rew_mean     | -10      |
| time/              |          |
|    episodes        | 4        |
|    fps             | 6        |
|    time_elapsed    | 52       |
|    total timesteps | 327      |
| train/             |          |
|    actor_loss      | 0.361    |
|    critic_loss     | 8.68     |
|    learning_rate   | 0.001    |
|    n_updates       | 168      |
---------------------------------
Terminated
2021-12-23 16:03:39.559471: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/shandilya/.mujoco/mjpro150/bin
2021-12-23 16:03:39.559515: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
/home/shandilya/Desktop/Projects/NavigationController
Env Type: maze
Task: GoalRewardNoObstacle
Model: <class 'utils.rtd3_utils.RTD3'>
Policy: <class 'utils.rtd3_utils.RecurrentTD3Policy'>
Replay Buffer: <class 'utils.rtd3_utils.EpisodicDictReplayBuffer'>
Using cpu device
2880
2880
Logging to assets/out/models/exp22/TD3_11
Traceback (most recent call last):
  File "train.py", line 82, in <module>
    model.learn(args.timesteps)
  File "/home/shandilya/Desktop/Projects/NavigationController/learning/explore.py", line 207, in learn
    callback = self.rl_callback
  File "/home/shandilya/Desktop/Projects/NavigationController/utils/rtd3_utils.py", line 1106, in learn
    reset_num_timesteps=reset_num_timesteps,
  File "/home/shandilya/py36/lib/python3.6/site-packages/stable_baselines3/common/off_policy_algorithm.py", line 369, in learn
    self.train(batch_size=self.batch_size, gradient_steps=gradient_steps)
  File "/home/shandilya/Desktop/Projects/NavigationController/utils/rtd3_utils.py", line 1082, in train
    self.update_policy(steps, batch_size, replay_data)
  File "/home/shandilya/Desktop/Projects/NavigationController/utils/rtd3_utils.py", line 1045, in update_policy
    actions, hidden_state= self.actor(replay_data.observations[i], hidden_state)
IndexError: list index out of range
2021-12-23 16:05:43.682889: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/shandilya/.mujoco/mjpro150/bin
2021-12-23 16:05:43.682933: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
/home/shandilya/Desktop/Projects/NavigationController
Env Type: maze
Task: GoalRewardNoObstacle
Model: <class 'utils.rtd3_utils.RTD3'>
Policy: <class 'utils.rtd3_utils.RecurrentTD3Policy'>
Replay Buffer: <class 'utils.rtd3_utils.EpisodicDictReplayBuffer'>
Using cpu device
2880
2880
Logging to assets/out/models/exp22/TD3_12
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 86.8     |
|    ep_rew_mean     | -10      |
| time/              |          |
|    episodes        | 4        |
|    fps             | 6        |
|    time_elapsed    | 56       |
|    total timesteps | 347      |
| train/             |          |
|    actor_loss      | 1.34     |
|    critic_loss     | 27.2     |
|    learning_rate   | 0.001    |
|    n_updates       | 172      |
---------------------------------
Terminated
2021-12-23 16:07:06.784240: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/shandilya/.mujoco/mjpro150/bin
2021-12-23 16:07:06.784284: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
/home/shandilya/Desktop/Projects/NavigationController
Env Type: maze
Task: GoalRewardNoObstacle
Model: <class 'utils.rtd3_utils.RTD3'>
Policy: <class 'utils.rtd3_utils.RecurrentTD3Policy'>
Replay Buffer: <class 'utils.rtd3_utils.EpisodicDictReplayBuffer'>
Using cpu device
2880
2880
Logging to assets/out/models/exp22/TD3_13
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 93       |
|    ep_rew_mean     | -10      |
| time/              |          |
|    episodes        | 4        |
|    fps             | 6        |
|    time_elapsed    | 54       |
|    total timesteps | 372      |
| train/             |          |
|    actor_loss      | 0.0983   |
|    critic_loss     | 4.61     |
|    learning_rate   | 0.001    |
|    n_updates       | 171      |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 58.5     |
|    ep_rew_mean     | -10      |
| time/              |          |
|    episodes        | 8        |
|    fps             | 5        |
|    time_elapsed    | 83       |
|    total timesteps | 468      |
| train/             |          |
|    actor_loss      | 0.431    |
|    critic_loss     | 0.000103 |
|    learning_rate   | 0.001    |
|    n_updates       | 271      |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 46.8     |
|    ep_rew_mean     | -10      |
| time/              |          |
|    episodes        | 12       |
|    fps             | 5        |
|    time_elapsed    | 110      |
|    total timesteps | 562      |
| train/             |          |
|    actor_loss      | 3.17     |
|    critic_loss     | 1.79     |
|    learning_rate   | 0.000999 |
|    n_updates       | 363      |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 41.6     |
|    ep_rew_mean     | -10      |
| time/              |          |
|    episodes        | 16       |
|    fps             | 4        |
|    time_elapsed    | 139      |
|    total timesteps | 666      |
| train/             |          |
|    actor_loss      | 17.4     |
|    critic_loss     | 61.3     |
|    learning_rate   | 0.000999 |
|    n_updates       | 462      |
---------------------------------
Terminated
2021-12-23 16:09:38.040254: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/shandilya/.mujoco/mjpro150/bin
2021-12-23 16:09:38.040295: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
/home/shandilya/Desktop/Projects/NavigationController
Env Type: maze
Task: GoalRewardNoObstacle
Model: <class 'utils.rtd3_utils.RTD3'>
Policy: <class 'utils.rtd3_utils.RecurrentTD3Policy'>
Replay Buffer: <class 'utils.rtd3_utils.EpisodicDictReplayBuffer'>
Using cpu device
2880
2880
Logging to assets/out/models/exp22/TD3_14
Terminated
2021-12-23 16:10:25.794384: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/shandilya/.mujoco/mjpro150/bin
2021-12-23 16:10:25.794428: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
/home/shandilya/Desktop/Projects/NavigationController
Env Type: maze
Task: GoalRewardNoObstacle
Model: <class 'utils.rtd3_utils.RTD3'>
Policy: <class 'utils.rtd3_utils.RecurrentTD3Policy'>
Replay Buffer: <class 'utils.rtd3_utils.EpisodicDictReplayBuffer'>
Using cpu device
2880
2880
Logging to assets/out/models/exp22/TD3_15
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 139      |
|    ep_rew_mean     | -10      |
| time/              |          |
|    episodes        | 4        |
|    fps             | 37       |
|    time_elapsed    | 14       |
|    total timesteps | 557      |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 135      |
|    ep_rew_mean     | -10      |
| time/              |          |
|    episodes        | 8        |
|    fps             | 39       |
|    time_elapsed    | 27       |
|    total timesteps | 1081     |
---------------------------------
Traceback (most recent call last):
  File "train.py", line 82, in <module>
    model.learn(args.timesteps)
  File "/home/shandilya/Desktop/Projects/NavigationController/learning/explore.py", line 207, in learn
    callback = self.rl_callback
  File "/home/shandilya/Desktop/Projects/NavigationController/utils/rtd3_utils.py", line 1104, in learn
    reset_num_timesteps=reset_num_timesteps,
  File "/home/shandilya/py36/lib/python3.6/site-packages/stable_baselines3/common/off_policy_algorithm.py", line 369, in learn
    self.train(batch_size=self.batch_size, gradient_steps=gradient_steps)
  File "/home/shandilya/Desktop/Projects/NavigationController/utils/rtd3_utils.py", line 1080, in train
    self.update_policy(steps, batch_size, replay_data)
  File "/home/shandilya/Desktop/Projects/NavigationController/utils/rtd3_utils.py", line 1044, in update_policy
    actions, hidden_state= self.actor(replay_data.observations[i], hidden_state)
IndexError: list index out of range
2021-12-23 16:17:54.633934: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/shandilya/.mujoco/mjpro150/bin
2021-12-23 16:17:54.633979: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
/home/shandilya/Desktop/Projects/NavigationController
Env Type: maze
Task: GoalRewardNoObstacle
Model: <class 'utils.rtd3_utils.RTD3'>
Policy: <class 'utils.rtd3_utils.RecurrentTD3Policy'>
Replay Buffer: <class 'utils.rtd3_utils.EpisodicDictReplayBuffer'>
Using cpu device
2880
2880
Logging to assets/out/models/exp22/TD3_16
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 132      |
|    ep_rew_mean     | -10      |
| time/              |          |
|    episodes        | 4        |
|    fps             | 38       |
|    time_elapsed    | 13       |
|    total timesteps | 530      |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 131      |
|    ep_rew_mean     | -10      |
| time/              |          |
|    episodes        | 8        |
|    fps             | 39       |
|    time_elapsed    | 26       |
|    total timesteps | 1050     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 95.9     |
|    ep_rew_mean     | -10      |
| time/              |          |
|    episodes        | 12       |
|    fps             | 13       |
|    time_elapsed    | 83       |
|    total timesteps | 1151     |
| train/             |          |
|    actor_loss      | 0.206    |
|    critic_loss     | 0.226    |
|    learning_rate   | 0.000999 |
|    n_updates       | 211      |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 78.4     |
|    ep_rew_mean     | -10      |
| time/              |          |
|    episodes        | 16       |
|    fps             | 11       |
|    time_elapsed    | 113      |
|    total timesteps | 1254     |
| train/             |          |
|    actor_loss      | 0.215    |
|    critic_loss     | 0.454    |
|    learning_rate   | 0.000999 |
|    n_updates       | 314      |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 68       |
|    ep_rew_mean     | -10      |
| time/              |          |
|    episodes        | 20       |
|    fps             | 9        |
|    time_elapsed    | 143      |
|    total timesteps | 1359     |
| train/             |          |
|    actor_loss      | 1.01     |
|    critic_loss     | 2.66     |
|    learning_rate   | 0.000999 |
|    n_updates       | 415      |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 61       |
|    ep_rew_mean     | -10      |
| time/              |          |
|    episodes        | 24       |
|    fps             | 8        |
|    time_elapsed    | 173      |
|    total timesteps | 1465     |
| train/             |          |
|    actor_loss      | 2.38     |
|    critic_loss     | 1.24     |
|    learning_rate   | 0.000999 |
|    n_updates       | 521      |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 56.2     |
|    ep_rew_mean     | -10      |
| time/              |          |
|    episodes        | 28       |
|    fps             | 7        |
|    time_elapsed    | 207      |
|    total timesteps | 1574     |
| train/             |          |
|    actor_loss      | 3.9      |
|    critic_loss     | 1.27     |
|    learning_rate   | 0.000998 |
|    n_updates       | 637      |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 66.6     |
|    ep_rew_mean     | -10      |
| time/              |          |
|    episodes        | 32       |
|    fps             | 8        |
|    time_elapsed    | 249      |
|    total timesteps | 2132     |
| train/             |          |
|    actor_loss      | 2        |
|    critic_loss     | 0.0863   |
|    learning_rate   | 0.000998 |
|    n_updates       | 738      |
---------------------------------
Traceback (most recent call last):
  File "train.py", line 82, in <module>
    model.learn(args.timesteps)
  File "/home/shandilya/Desktop/Projects/NavigationController/learning/explore.py", line 207, in learn
    callback = self.rl_callback
  File "/home/shandilya/Desktop/Projects/NavigationController/utils/rtd3_utils.py", line 1111, in learn
    reset_num_timesteps=reset_num_timesteps,
  File "/home/shandilya/py36/lib/python3.6/site-packages/stable_baselines3/common/off_policy_algorithm.py", line 369, in learn
    self.train(batch_size=self.batch_size, gradient_steps=gradient_steps)
  File "/home/shandilya/Desktop/Projects/NavigationController/utils/rtd3_utils.py", line 1087, in train
    self.update_policy(steps, batch_size, replay_data)
  File "/home/shandilya/Desktop/Projects/NavigationController/utils/rtd3_utils.py", line 1051, in update_policy
    actions, hidden_state= self.actor(replay_data.observations[i], hidden_state)
IndexError: list index out of range
2021-12-23 16:39:10.574576: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/shandilya/.mujoco/mjpro150/bin
2021-12-23 16:39:10.574626: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
/home/shandilya/Desktop/Projects/NavigationController
Env Type: maze
Task: GoalRewardNoObstacle
Model: <class 'utils.rtd3_utils.RTD3'>
Policy: <class 'utils.rtd3_utils.RecurrentTD3Policy'>
Replay Buffer: <class 'utils.rtd3_utils.EpisodicDictReplayBuffer'>
Using cpu device
2880
2880
Logging to assets/out/models/exp22/TD3_19
Terminated
2021-12-23 16:52:36.762070: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/shandilya/.mujoco/mjpro150/bin
2021-12-23 16:52:36.762114: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
/home/shandilya/Desktop/Projects/NavigationController
Env Type: maze
Task: GoalRewardNoObstacle
Model: <class 'utils.rtd3_utils.RTD3'>
Policy: <class 'utils.rtd3_utils.RecurrentTD3Policy'>
Replay Buffer: <class 'utils.rtd3_utils.EpisodicDictReplayBuffer'>
Using cpu device
2880
2880
Logging to assets/out/models/exp22/TD3_22
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 132      |
|    ep_rew_mean     | -10      |
| time/              |          |
|    episodes        | 4        |
|    fps             | 40       |
|    time_elapsed    | 12       |
|    total timesteps | 526      |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 133      |
|    ep_rew_mean     | -10      |
| time/              |          |
|    episodes        | 8        |
|    fps             | 43       |
|    time_elapsed    | 24       |
|    total timesteps | 1065     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 128      |
|    ep_rew_mean     | -10      |
| time/              |          |
|    episodes        | 12       |
|    fps             | 15       |
|    time_elapsed    | 99       |
|    total timesteps | 1537     |
| train/             |          |
|    actor_loss      | 0.0403   |
|    critic_loss     | 0.00259  |
|    learning_rate   | 0.000999 |
|    n_updates       | 224      |
---------------------------------
Traceback (most recent call last):
  File "train.py", line 82, in <module>
    model.learn(args.timesteps)
  File "/home/shandilya/Desktop/Projects/NavigationController/learning/explore.py", line 207, in learn
    callback = self.rl_callback
  File "/home/shandilya/Desktop/Projects/NavigationController/utils/rtd3_utils.py", line 1111, in learn
    reset_num_timesteps=reset_num_timesteps,
  File "/home/shandilya/py36/lib/python3.6/site-packages/stable_baselines3/common/off_policy_algorithm.py", line 369, in learn
    self.train(batch_size=self.batch_size, gradient_steps=gradient_steps)
  File "/home/shandilya/Desktop/Projects/NavigationController/utils/rtd3_utils.py", line 1087, in train
    self.update_policy(steps, batch_size, replay_data)
  File "/home/shandilya/Desktop/Projects/NavigationController/utils/rtd3_utils.py", line 1049, in update_policy
    actions, hidden_state= self.actor(replay_data.observations[i], hidden_state)
IndexError: list index out of range
2021-12-23 17:01:22.397344: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/shandilya/.mujoco/mjpro150/bin
2021-12-23 17:01:22.397396: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
/home/shandilya/Desktop/Projects/NavigationController
Env Type: maze
Task: GoalRewardNoObstacle
Model: <class 'utils.rtd3_utils.RTD3'>
Policy: <class 'utils.rtd3_utils.RecurrentTD3Policy'>
Replay Buffer: <class 'utils.rtd3_utils.EpisodicDictReplayBuffer'>
Using cpu device
2880
2880
Logging to assets/out/models/exp22/TD3_25
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 139      |
|    ep_rew_mean     | -10      |
| time/              |          |
|    episodes        | 4        |
|    fps             | 38       |
|    time_elapsed    | 14       |
|    total timesteps | 557      |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 137      |
|    ep_rew_mean     | -10      |
| time/              |          |
|    episodes        | 8        |
|    fps             | 39       |
|    time_elapsed    | 27       |
|    total timesteps | 1093     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 258      |
|    ep_rew_mean     | -6.2     |
| time/              |          |
|    episodes        | 12       |
|    fps             | 5        |
|    time_elapsed    | 592      |
|    total timesteps | 3097     |
| train/             |          |
|    actor_loss      | 0.0358   |
|    critic_loss     | 6.28e-05 |
|    learning_rate   | 0.000997 |
|    n_updates       | 1621     |
---------------------------------
Eval num_timesteps=5000, episode_reward=0.84 +/- 0.58
Episode length: 501.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 501      |
|    mean_reward     | 0.841    |
| time/              |          |
|    total_timesteps | 5000     |
| train/             |          |
|    actor_loss      | 0.0111   |
|    critic_loss     | 0.000159 |
|    learning_rate   | 0.000995 |
|    n_updates       | 3625     |
---------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 319      |
|    ep_rew_mean     | -3.98    |
| time/              |          |
|    episodes        | 16       |
|    fps             | 3        |
|    time_elapsed    | 1423     |
|    total timesteps | 5101     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 355      |
|    ep_rew_mean     | -2.82    |
| time/              |          |
|    episodes        | 20       |
|    fps             | 3        |
|    time_elapsed    | 2215     |
|    total timesteps | 7105     |
| train/             |          |
|    actor_loss      | 0.00151  |
|    critic_loss     | 4.21e-06 |
|    learning_rate   | 0.000993 |
|    n_updates       | 5629     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 380      |
|    ep_rew_mean     | -1.79    |
| time/              |          |
|    episodes        | 24       |
|    fps             | 3        |
|    time_elapsed    | 2999     |
|    total timesteps | 9109     |
| train/             |          |
|    actor_loss      | 0.000168 |
|    critic_loss     | 1.7e-07  |
|    learning_rate   | 0.000991 |
|    n_updates       | 7633     |
---------------------------------
Eval num_timesteps=10000, episode_reward=0.75 +/- 0.82
Episode length: 501.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 501      |
|    mean_reward     | 0.748    |
| time/              |          |
|    total_timesteps | 10000    |
| train/             |          |
|    actor_loss      | 8.35e-05 |
|    critic_loss     | 2.24e-08 |
|    learning_rate   | 0.00099  |
|    n_updates       | 8635     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 397      |
|    ep_rew_mean     | -1.19    |
| time/              |          |
|    episodes        | 28       |
|    fps             | 2        |
|    time_elapsed    | 3848     |
|    total timesteps | 11113    |
| train/             |          |
|    actor_loss      | 5.06e-05 |
|    critic_loss     | 5.2e-09  |
|    learning_rate   | 0.000989 |
|    n_updates       | 9637     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 410      |
|    ep_rew_mean     | -0.586   |
| time/              |          |
|    episodes        | 32       |
|    fps             | 2        |
|    time_elapsed    | 4633     |
|    total timesteps | 13117    |
| train/             |          |
|    actor_loss      | 3.03e-06 |
|    critic_loss     | 7.13e-10 |
|    learning_rate   | 0.000988 |
|    n_updates       | 11641    |
---------------------------------
Terminated
2021-12-23 18:28:37.258502: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/shandilya/.mujoco/mjpro150/bin
2021-12-23 18:28:37.258536: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
/home/shandilya/Desktop/Projects/NavigationController
Env Type: maze
Task: GoalRewardNoObstacle
Model: <class 'utils.rtd3_utils.RTD3'>
Policy: <class 'utils.rtd3_utils.RecurrentTD3Policy'>
Replay Buffer: <class 'utils.rtd3_utils.EpisodicDictReplayBuffer'>
Using cpu device
2880
2880
Logging to assets/out/models/exp22/TD3_26
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 138      |
|    ep_rew_mean     | -0.972   |
| time/              |          |
|    episodes        | 4        |
|    fps             | 38       |
|    time_elapsed    | 14       |
|    total timesteps | 551      |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 137      |
|    ep_rew_mean     | -0.307   |
| time/              |          |
|    episodes        | 8        |
|    fps             | 39       |
|    time_elapsed    | 27       |
|    total timesteps | 1093     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 247      |
|    ep_rew_mean     | 1.27     |
| time/              |          |
|    episodes        | 12       |
|    fps             | 5        |
|    time_elapsed    | 528      |
|    total timesteps | 2968     |
| train/             |          |
|    actor_loss      | 0.162    |
|    critic_loss     | 0.00228  |
|    learning_rate   | 0.000998 |
|    n_updates       | 1468     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 311      |
|    ep_rew_mean     | 1.83     |
| time/              |          |
|    episodes        | 16       |
|    fps             | 3        |
|    time_elapsed    | 1286     |
|    total timesteps | 4972     |
| train/             |          |
|    actor_loss      | 0.0281   |
|    critic_loss     | 0.00133  |
|    learning_rate   | 0.000996 |
|    n_updates       | 3472     |
---------------------------------
Eval num_timesteps=5000, episode_reward=-0.62 +/- 0.67
Episode length: 501.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 501      |
|    mean_reward     | -0.623   |
| time/              |          |
|    total_timesteps | 5000     |
| train/             |          |
|    actor_loss      | 0.0184   |
|    critic_loss     | 0.000473 |
|    learning_rate   | 0.000995 |
|    n_updates       | 3973     |
---------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 349      |
|    ep_rew_mean     | 2.3      |
| time/              |          |
|    episodes        | 20       |
|    fps             | 3        |
|    time_elapsed    | 2114     |
|    total timesteps | 6976     |
| train/             |          |
|    actor_loss      | 0.00479  |
|    critic_loss     | 4.98e-05 |
|    learning_rate   | 0.000994 |
|    n_updates       | 5476     |
---------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 374       |
|    ep_rew_mean     | 2.96      |
| time/              |           |
|    episodes        | 24        |
|    fps             | 3         |
|    time_elapsed    | 2879      |
|    total timesteps | 8980      |
| train/             |           |
|    actor_loss      | -0.000787 |
|    critic_loss     | 7.63e-06  |
|    learning_rate   | 0.000992  |
|    n_updates       | 7480      |
----------------------------------
Eval num_timesteps=10000, episode_reward=-1.31 +/- 0.93
Episode length: 501.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 501      |
|    mean_reward     | -1.31    |
| time/              |          |
|    total_timesteps | 10000    |
| train/             |          |
|    actor_loss      | -0.00527 |
|    critic_loss     | 0.00057  |
|    learning_rate   | 0.00099  |
|    n_updates       | 8983     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 392      |
|    ep_rew_mean     | 3.92     |
| time/              |          |
|    episodes        | 28       |
|    fps             | 2        |
|    time_elapsed    | 3713     |
|    total timesteps | 10984    |
| train/             |          |
|    actor_loss      | -0.00269 |
|    critic_loss     | 1.29e-05 |
|    learning_rate   | 0.00099  |
|    n_updates       | 9484     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 406      |
|    ep_rew_mean     | 3.44     |
| time/              |          |
|    episodes        | 32       |
|    fps             | 2        |
|    time_elapsed    | 4478     |
|    total timesteps | 12988    |
| train/             |          |
|    actor_loss      | -0.00465 |
|    critic_loss     | 0.000561 |
|    learning_rate   | 0.000988 |
|    n_updates       | 11488    |
---------------------------------
Terminated
2021-12-23 19:58:35.766616: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/shandilya/.mujoco/mjpro150/bin
2021-12-23 19:58:35.766661: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
/home/shandilya/Desktop/Projects/NavigationController
Env Type: maze
Task: GoalRewardNoObstacle
Model: <class 'utils.rtd3_utils.RTD3'>
Policy: <class 'utils.rtd3_utils.RecurrentTD3Policy'>
Replay Buffer: <class 'utils.rtd3_utils.EpisodicDictReplayBuffer'>
Using cpu device
2880
2880
Logging to assets/out/models/exp22/TD3_27
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 114      |
|    ep_rew_mean     | 27.3     |
| time/              |          |
|    episodes        | 4        |
|    fps             | 36       |
|    time_elapsed    | 12       |
|    total timesteps | 455      |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 102      |
|    ep_rew_mean     | 24       |
| time/              |          |
|    episodes        | 8        |
|    fps             | 40       |
|    time_elapsed    | 20       |
|    total timesteps | 813      |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 129      |
|    ep_rew_mean     | 50       |
| time/              |          |
|    episodes        | 12       |
|    fps             | 22       |
|    time_elapsed    | 68       |
|    total timesteps | 1545     |
| train/             |          |
|    actor_loss      | -0.348   |
|    critic_loss     | 7.09     |
|    learning_rate   | 0.000999 |
|    n_updates       | 97       |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 98.8     |
|    ep_rew_mean     | 36.2     |
| time/              |          |
|    episodes        | 16       |
|    fps             | 4        |
|    time_elapsed    | 356      |
|    total timesteps | 1581     |
| train/             |          |
|    actor_loss      | -0.226   |
|    critic_loss     | 0.769    |
|    learning_rate   | 0.000998 |
|    n_updates       | 628      |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 81.1     |
|    ep_rew_mean     | 28       |
| time/              |          |
|    episodes        | 20       |
|    fps             | 4        |
|    time_elapsed    | 379      |
|    total timesteps | 1622     |
| train/             |          |
|    actor_loss      | -0.372   |
|    critic_loss     | 0.731    |
|    learning_rate   | 0.000998 |
|    n_updates       | 664      |
---------------------------------
Terminated
2021-12-23 20:21:48.091297: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/shandilya/.mujoco/mjpro150/bin
2021-12-23 20:21:48.091341: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
/home/shandilya/Desktop/Projects/NavigationController
Env Type: maze
Task: GoalRewardNoObstacle
Model: <class 'utils.rtd3_utils.RTD3'>
Policy: <class 'utils.rtd3_utils.RecurrentTD3Policy'>
Replay Buffer: <class 'utils.rtd3_utils.EpisodicDictReplayBuffer'>
Using cpu device
2880
2880
Logging to assets/out/models/exp22/TD3_28
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 135      |
|    ep_rew_mean     | -0.353   |
| time/              |          |
|    episodes        | 4        |
|    fps             | 56       |
|    time_elapsed    | 9        |
|    total timesteps | 540      |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 132      |
|    ep_rew_mean     | -0.102   |
| time/              |          |
|    episodes        | 8        |
|    fps             | 59       |
|    time_elapsed    | 17       |
|    total timesteps | 1055     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 255      |
|    ep_rew_mean     | 0.0193   |
| time/              |          |
|    episodes        | 12       |
|    fps             | 5        |
|    time_elapsed    | 571      |
|    total timesteps | 3059     |
| train/             |          |
|    actor_loss      | 0.858    |
|    critic_loss     | 0.908    |
|    learning_rate   | 0.000997 |
|    n_updates       | 1626     |
---------------------------------
Eval num_timesteps=5000, episode_reward=-2.16 +/- 0.65
Episode length: 501.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 501      |
|    mean_reward     | -2.16    |
| time/              |          |
|    total_timesteps | 5000     |
| train/             |          |
|    actor_loss      | 0.122    |
|    critic_loss     | 0.0227   |
|    learning_rate   | 0.000995 |
|    n_updates       | 3630     |
---------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 316      |
|    ep_rew_mean     | 0.213    |
| time/              |          |
|    episodes        | 16       |
|    fps             | 3        |
|    time_elapsed    | 1379     |
|    total timesteps | 5063     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 353      |
|    ep_rew_mean     | 0.0757   |
| time/              |          |
|    episodes        | 20       |
|    fps             | 3        |
|    time_elapsed    | 2135     |
|    total timesteps | 7067     |
| train/             |          |
|    actor_loss      | 0.00358  |
|    critic_loss     | 0.00126  |
|    learning_rate   | 0.000993 |
|    n_updates       | 5634     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 378      |
|    ep_rew_mean     | 0.565    |
| time/              |          |
|    episodes        | 24       |
|    fps             | 3        |
|    time_elapsed    | 2892     |
|    total timesteps | 9071     |
| train/             |          |
|    actor_loss      | -0.00864 |
|    critic_loss     | 0.000911 |
|    learning_rate   | 0.000992 |
|    n_updates       | 7638     |
---------------------------------
Eval num_timesteps=10000, episode_reward=-1.75 +/- 0.40
Episode length: 501.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 501      |
|    mean_reward     | -1.75    |
| time/              |          |
|    total_timesteps | 10000    |
| train/             |          |
|    actor_loss      | -0.0102  |
|    critic_loss     | 0.000119 |
|    learning_rate   | 0.000991 |
|    n_updates       | 8640     |
---------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 396      |
|    ep_rew_mean     | 0.555    |
| time/              |          |
|    episodes        | 28       |
|    fps             | 2        |
|    time_elapsed    | 3736     |
|    total timesteps | 11075    |
| train/             |          |
|    actor_loss      | -0.016   |
|    critic_loss     | 0.00112  |
|    learning_rate   | 0.00099  |
|    n_updates       | 9642     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 409      |
|    ep_rew_mean     | 0.378    |
| time/              |          |
|    episodes        | 32       |
|    fps             | 2        |
|    time_elapsed    | 4542     |
|    total timesteps | 13079    |
| train/             |          |
|    actor_loss      | -0.0101  |
|    critic_loss     | 0.000108 |
|    learning_rate   | 0.000988 |
|    n_updates       | 11646    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 413      |
|    ep_rew_mean     | 0.0224   |
| time/              |          |
|    episodes        | 36       |
|    fps             | 2        |
|    time_elapsed    | 5249     |
|    total timesteps | 14861    |
| train/             |          |
|    actor_loss      | -0.00934 |
|    critic_loss     | 0.00308  |
|    learning_rate   | 0.000986 |
|    n_updates       | 13567    |
---------------------------------
Eval num_timesteps=15000, episode_reward=-1.93 +/- 0.36
Episode length: 501.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 501      |
|    mean_reward     | -1.93    |
| time/              |          |
|    total_timesteps | 15000    |
| train/             |          |
|    actor_loss      | -0.00896 |
|    critic_loss     | 0.0014   |
|    learning_rate   | 0.000985 |
|    n_updates       | 13929    |
---------------------------------
Terminated
2021-12-23 23:41:08.606208: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/shandilya/.mujoco/mjpro150/bin
2021-12-23 23:41:08.606242: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
/home/shandilya/Desktop/Projects/NavigationController
Env Type: maze
Task: GoalRewardNoObstacle
/tmp/tmpg2hzdwde.xml
/tmp/tmphnq5kdbw.xml
Model: <class 'utils.rtd3_utils.RTD3'>
Policy: <class 'utils.rtd3_utils.RecurrentTD3Policy'>
Replay Buffer: <class 'utils.rtd3_utils.EpisodicDictReplayBuffer'>
Using cpu device
2880
2880
/tmp/tmpa69hgeye.xml
Logging to assets/out/models/exp22/TD3_29
/tmp/tmpzqqd_7xz.xml
/tmp/tmpu8e4a8d_.xml
/tmp/tmprn03cchp.xml
/tmp/tmpyzysstqn.xml
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 147      |
|    ep_rew_mean     | -1.34    |
| time/              |          |
|    episodes        | 4        |
|    fps             | 60       |
|    time_elapsed    | 9        |
|    total timesteps | 588      |
---------------------------------
/tmp/tmpih74i7gw.xml
/tmp/tmpwyze3i5m.xml
/tmp/tmp2zq8jgvp.xml
/tmp/tmpz5yrsbps.xml
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 137      |
|    ep_rew_mean     | 0.227    |
| time/              |          |
|    episodes        | 8        |
|    fps             | 21       |
|    time_elapsed    | 52       |
|    total timesteps | 1095     |
| train/             |          |
|    actor_loss      | -0.00446 |
|    critic_loss     | 0.916    |
|    learning_rate   | 0.000999 |
|    n_updates       | 127      |
---------------------------------
Terminated
2021-12-23 23:42:41.284133: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/shandilya/.mujoco/mjpro150/bin
2021-12-23 23:42:41.284171: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
/home/shandilya/Desktop/Projects/NavigationController
Env Type: maze
Task: GoalRewardNoObstacle
Model: <class 'utils.rtd3_utils.RTD3'>
Policy: <class 'utils.rtd3_utils.RecurrentTD3Policy'>
Replay Buffer: <class 'utils.rtd3_utils.EpisodicDictReplayBuffer'>
Using cpu device
2880
2880
Logging to assets/out/models/exp22/TD3_30
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 147      |
|    ep_rew_mean     | -1.34    |
| time/              |          |
|    episodes        | 4        |
|    fps             | 60       |
|    time_elapsed    | 9        |
|    total timesteps | 588      |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 132      |
|    ep_rew_mean     | -1.14    |
| time/              |          |
|    episodes        | 8        |
|    fps             | 61       |
|    time_elapsed    | 17       |
|    total timesteps | 1059     |
---------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 96.2      |
|    ep_rew_mean     | -3.61     |
| time/              |           |
|    episodes        | 12        |
|    fps             | 16        |
|    time_elapsed    | 68        |
|    total timesteps | 1155      |
| train/             |           |
|    actor_loss      | -0.000176 |
|    critic_loss     | 0.00309   |
|    learning_rate   | 0.000999  |
|    n_updates       | 185       |
----------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 78.2     |
|    ep_rew_mean     | -4.85    |
| time/              |          |
|    episodes        | 16       |
|    fps             | 12       |
|    time_elapsed    | 96       |
|    total timesteps | 1251     |
| train/             |          |
|    actor_loss      | -0.00473 |
|    critic_loss     | 0.000285 |
|    learning_rate   | 0.000999 |
|    n_updates       | 283      |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 68       |
|    ep_rew_mean     | -5.6     |
| time/              |          |
|    episodes        | 20       |
|    fps             | 10       |
|    time_elapsed    | 126      |
|    total timesteps | 1359     |
| train/             |          |
|    actor_loss      | -0.00993 |
|    critic_loss     | 3.26     |
|    learning_rate   | 0.000999 |
|    n_updates       | 385      |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 60.6     |
|    ep_rew_mean     | -6.11    |
| time/              |          |
|    episodes        | 24       |
|    fps             | 9        |
|    time_elapsed    | 155      |
|    total timesteps | 1455     |
| train/             |          |
|    actor_loss      | 0.00172  |
|    critic_loss     | 3.8e-05  |
|    learning_rate   | 0.000999 |
|    n_updates       | 484      |
---------------------------------
Terminated
2021-12-23 23:46:05.063525: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/shandilya/.mujoco/mjpro150/bin
2021-12-23 23:46:05.063570: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
/home/shandilya/Desktop/Projects/NavigationController
Env Type: maze
Task: GoalRewardNoObstacle
Model: <class 'utils.rtd3_utils.RTD3'>
Policy: <class 'utils.rtd3_utils.RecurrentTD3Policy'>
Replay Buffer: <class 'utils.rtd3_utils.EpisodicDictReplayBuffer'>
Using cpu device
2880
2880
Logging to assets/out/models/exp22/TD3_31
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 135      |
|    ep_rew_mean     | -0.304   |
| time/              |          |
|    episodes        | 4        |
|    fps             | 60       |
|    time_elapsed    | 8        |
|    total timesteps | 541      |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 129      |
|    ep_rew_mean     | 0.558    |
| time/              |          |
|    episodes        | 8        |
|    fps             | 62       |
|    time_elapsed    | 16       |
|    total timesteps | 1029     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 111      |
|    ep_rew_mean     | 3.34     |
| time/              |          |
|    episodes        | 12       |
|    fps             | 13       |
|    time_elapsed    | 98       |
|    total timesteps | 1327     |
| train/             |          |
|    actor_loss      | -0.00706 |
|    critic_loss     | 0.00792  |
|    learning_rate   | 0.000999 |
|    n_updates       | 283      |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 102      |
|    ep_rew_mean     | 4.66     |
| time/              |          |
|    episodes        | 16       |
|    fps             | 8        |
|    time_elapsed    | 182      |
|    total timesteps | 1624     |
| train/             |          |
|    actor_loss      | -0.305   |
|    critic_loss     | 0.346    |
|    learning_rate   | 0.000998 |
|    n_updates       | 582      |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 96.7     |
|    ep_rew_mean     | 5.49     |
| time/              |          |
|    episodes        | 20       |
|    fps             | 7        |
|    time_elapsed    | 273      |
|    total timesteps | 1933     |
| train/             |          |
|    actor_loss      | -0.157   |
|    critic_loss     | 0.0797   |
|    learning_rate   | 0.000998 |
|    n_updates       | 885      |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 93.3     |
|    ep_rew_mean     | 6.11     |
| time/              |          |
|    episodes        | 24       |
|    fps             | 6        |
|    time_elapsed    | 370      |
|    total timesteps | 2239     |
| train/             |          |
|    actor_loss      | -0.177   |
|    critic_loss     | 0.205    |
|    learning_rate   | 0.000998 |
|    n_updates       | 1197     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 90.6     |
|    ep_rew_mean     | 6.47     |
| time/              |          |
|    episodes        | 28       |
|    fps             | 5        |
|    time_elapsed    | 475      |
|    total timesteps | 2537     |
| train/             |          |
|    actor_loss      | -0.311   |
|    critic_loss     | 0.0652   |
|    learning_rate   | 0.000998 |
|    n_updates       | 1495     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 88.4     |
|    ep_rew_mean     | 6.8      |
| time/              |          |
|    episodes        | 32       |
|    fps             | 4        |
|    time_elapsed    | 573      |
|    total timesteps | 2830     |
| train/             |          |
|    actor_loss      | -0.406   |
|    critic_loss     | 0.0785   |
|    learning_rate   | 0.000997 |
|    n_updates       | 1788     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 86.9     |
|    ep_rew_mean     | 7.1      |
| time/              |          |
|    episodes        | 36       |
|    fps             | 4        |
|    time_elapsed    | 670      |
|    total timesteps | 3128     |
| train/             |          |
|    actor_loss      | -0.513   |
|    critic_loss     | 0.0905   |
|    learning_rate   | 0.000997 |
|    n_updates       | 2081     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 85.8     |
|    ep_rew_mean     | 7.26     |
| time/              |          |
|    episodes        | 40       |
|    fps             | 4        |
|    time_elapsed    | 773      |
|    total timesteps | 3433     |
| train/             |          |
|    actor_loss      | -0.696   |
|    critic_loss     | 0.207    |
|    learning_rate   | 0.000997 |
|    n_updates       | 2389     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 84.7     |
|    ep_rew_mean     | 7.41     |
| time/              |          |
|    episodes        | 44       |
|    fps             | 4        |
|    time_elapsed    | 872      |
|    total timesteps | 3727     |
| train/             |          |
|    actor_loss      | -0.679   |
|    critic_loss     | 0.25     |
|    learning_rate   | 0.000996 |
|    n_updates       | 2683     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 83.9     |
|    ep_rew_mean     | 7.52     |
| time/              |          |
|    episodes        | 48       |
|    fps             | 4        |
|    time_elapsed    | 970      |
|    total timesteps | 4026     |
| train/             |          |
|    actor_loss      | -0.839   |
|    critic_loss     | 0.0908   |
|    learning_rate   | 0.000996 |
|    n_updates       | 2984     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 83.2     |
|    ep_rew_mean     | 7.61     |
| time/              |          |
|    episodes        | 52       |
|    fps             | 4        |
|    time_elapsed    | 1068     |
|    total timesteps | 4329     |
| train/             |          |
|    actor_loss      | -0.926   |
|    critic_loss     | 0.104    |
|    learning_rate   | 0.000996 |
|    n_updates       | 3283     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 82.6     |
|    ep_rew_mean     | 7.71     |
| time/              |          |
|    episodes        | 56       |
|    fps             | 3        |
|    time_elapsed    | 1167     |
|    total timesteps | 4625     |
| train/             |          |
|    actor_loss      | -0.997   |
|    critic_loss     | 0.0842   |
|    learning_rate   | 0.000995 |
|    n_updates       | 3583     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 82.1     |
|    ep_rew_mean     | 7.78     |
| time/              |          |
|    episodes        | 60       |
|    fps             | 3        |
|    time_elapsed    | 1266     |
|    total timesteps | 4925     |
| train/             |          |
|    actor_loss      | -1.18    |
|    critic_loss     | 0.249    |
|    learning_rate   | 0.000995 |
|    n_updates       | 3880     |
---------------------------------
Eval num_timesteps=5000, episode_reward=8.67 +/- 0.19
Episode length: 77.60 +/- 6.28
---------------------------------
| eval/              |          |
|    mean_ep_length  | 77.6     |
|    mean_reward     | 8.67     |
| time/              |          |
|    total_timesteps | 5000     |
| train/             |          |
|    actor_loss      | -1.09    |
|    critic_loss     | 0.271    |
|    learning_rate   | 0.000995 |
|    n_updates       | 4028     |
---------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 81.8     |
|    ep_rew_mean     | 7.87     |
| time/              |          |
|    episodes        | 64       |
|    fps             | 3        |
|    time_elapsed    | 1380     |
|    total timesteps | 5232     |
| train/             |          |
|    actor_loss      | -1.24    |
|    critic_loss     | 0.145    |
|    learning_rate   | 0.000995 |
|    n_updates       | 4191     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 81.4     |
|    ep_rew_mean     | 7.92     |
| time/              |          |
|    episodes        | 68       |
|    fps             | 3        |
|    time_elapsed    | 1480     |
|    total timesteps | 5535     |
| train/             |          |
|    actor_loss      | -1.42    |
|    critic_loss     | 0.352    |
|    learning_rate   | 0.000995 |
|    n_updates       | 4492     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 81       |
|    ep_rew_mean     | 7.97     |
| time/              |          |
|    episodes        | 72       |
|    fps             | 3        |
|    time_elapsed    | 1579     |
|    total timesteps | 5832     |
| train/             |          |
|    actor_loss      | -1.41    |
|    critic_loss     | 0.141    |
|    learning_rate   | 0.000994 |
|    n_updates       | 4790     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 80.6     |
|    ep_rew_mean     | 8.01     |
| time/              |          |
|    episodes        | 76       |
|    fps             | 3        |
|    time_elapsed    | 1677     |
|    total timesteps | 6129     |
| train/             |          |
|    actor_loss      | -1.6     |
|    critic_loss     | 0.311    |
|    learning_rate   | 0.000994 |
|    n_updates       | 5086     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 80.3     |
|    ep_rew_mean     | 8.04     |
| time/              |          |
|    episodes        | 80       |
|    fps             | 3        |
|    time_elapsed    | 1775     |
|    total timesteps | 6427     |
| train/             |          |
|    actor_loss      | -1.51    |
|    critic_loss     | 0.736    |
|    learning_rate   | 0.000994 |
|    n_updates       | 5382     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 80.2     |
|    ep_rew_mean     | 8.08     |
| time/              |          |
|    episodes        | 84       |
|    fps             | 3        |
|    time_elapsed    | 1878     |
|    total timesteps | 6741     |
| train/             |          |
|    actor_loss      | -1.59    |
|    critic_loss     | 0.52     |
|    learning_rate   | 0.000993 |
|    n_updates       | 5690     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 80       |
|    ep_rew_mean     | 8.11     |
| time/              |          |
|    episodes        | 88       |
|    fps             | 3        |
|    time_elapsed    | 1979     |
|    total timesteps | 7037     |
| train/             |          |
|    actor_loss      | -1.83    |
|    critic_loss     | 0.291    |
|    learning_rate   | 0.000993 |
|    n_updates       | 5996     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 79.9     |
|    ep_rew_mean     | 8.14     |
| time/              |          |
|    episodes        | 92       |
|    fps             | 3        |
|    time_elapsed    | 2081     |
|    total timesteps | 7347     |
| train/             |          |
|    actor_loss      | -1.9     |
|    critic_loss     | 0.253    |
|    learning_rate   | 0.000993 |
|    n_updates       | 6304     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 79.6     |
|    ep_rew_mean     | 8.18     |
| time/              |          |
|    episodes        | 96       |
|    fps             | 3        |
|    time_elapsed    | 2180     |
|    total timesteps | 7645     |
| train/             |          |
|    actor_loss      | -2.02    |
|    critic_loss     | 0.315    |
|    learning_rate   | 0.000993 |
|    n_updates       | 6604     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 79.5     |
|    ep_rew_mean     | 8.2      |
| time/              |          |
|    episodes        | 100      |
|    fps             | 3        |
|    time_elapsed    | 2278     |
|    total timesteps | 7945     |
| train/             |          |
|    actor_loss      | -2.09    |
|    critic_loss     | 0.3      |
|    learning_rate   | 0.000992 |
|    n_updates       | 6902     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 77       |
|    ep_rew_mean     | 8.58     |
| time/              |          |
|    episodes        | 104      |
|    fps             | 3        |
|    time_elapsed    | 2376     |
|    total timesteps | 8246     |
| train/             |          |
|    actor_loss      | -2.06    |
|    critic_loss     | 0.562    |
|    learning_rate   | 0.000992 |
|    n_updates       | 7201     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 75.3     |
|    ep_rew_mean     | 8.88     |
| time/              |          |
|    episodes        | 108      |
|    fps             | 3        |
|    time_elapsed    | 2479     |
|    total timesteps | 8558     |
| train/             |          |
|    actor_loss      | -2.21    |
|    critic_loss     | 0.238    |
|    learning_rate   | 0.000992 |
|    n_updates       | 7510     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 75.3     |
|    ep_rew_mean     | 8.89     |
| time/              |          |
|    episodes        | 112      |
|    fps             | 3        |
|    time_elapsed    | 2579     |
|    total timesteps | 8857     |
| train/             |          |
|    actor_loss      | -2.31    |
|    critic_loss     | 0.292    |
|    learning_rate   | 0.000991 |
|    n_updates       | 7813     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 75.4     |
|    ep_rew_mean     | 8.89     |
| time/              |          |
|    episodes        | 116      |
|    fps             | 3        |
|    time_elapsed    | 2678     |
|    total timesteps | 9160     |
| train/             |          |
|    actor_loss      | -2.32    |
|    critic_loss     | 0.174    |
|    learning_rate   | 0.000991 |
|    n_updates       | 8108     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 75.3     |
|    ep_rew_mean     | 8.9      |
| time/              |          |
|    episodes        | 120      |
|    fps             | 3        |
|    time_elapsed    | 2781     |
|    total timesteps | 9463     |
| train/             |          |
|    actor_loss      | -2.43    |
|    critic_loss     | 0.268    |
|    learning_rate   | 0.000991 |
|    n_updates       | 8421     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 75.3     |
|    ep_rew_mean     | 8.88     |
| time/              |          |
|    episodes        | 124      |
|    fps             | 3        |
|    time_elapsed    | 2881     |
|    total timesteps | 9766     |
| train/             |          |
|    actor_loss      | -2.34    |
|    critic_loss     | 0.291    |
|    learning_rate   | 0.00099  |
|    n_updates       | 8723     |
---------------------------------
Eval num_timesteps=10000, episode_reward=8.53 +/- 0.15
Episode length: 75.40 +/- 1.96
---------------------------------
| eval/              |          |
|    mean_ep_length  | 75.4     |
|    mean_reward     | 8.53     |
| time/              |          |
|    total_timesteps | 10000    |
| train/             |          |
|    actor_loss      | -2.57    |
|    critic_loss     | 0.346    |
|    learning_rate   | 0.00099  |
|    n_updates       | 9018     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 75.2     |
|    ep_rew_mean     | 8.89     |
| time/              |          |
|    episodes        | 128      |
|    fps             | 3        |
|    time_elapsed    | 2990     |
|    total timesteps | 10060    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 75.2     |
|    ep_rew_mean     | 8.91     |
| time/              |          |
|    episodes        | 132      |
|    fps             | 3        |
|    time_elapsed    | 3088     |
|    total timesteps | 10355    |
| train/             |          |
|    actor_loss      | -2.62    |
|    critic_loss     | 0.283    |
|    learning_rate   | 0.00099  |
|    n_updates       | 9312     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 75.3     |
|    ep_rew_mean     | 8.88     |
| time/              |          |
|    episodes        | 136      |
|    fps             | 3        |
|    time_elapsed    | 3188     |
|    total timesteps | 10656    |
| train/             |          |
|    actor_loss      | -2.58    |
|    critic_loss     | 0.333    |
|    learning_rate   | 0.00099  |
|    n_updates       | 9614     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 75.5     |
|    ep_rew_mean     | 8.89     |
| time/              |          |
|    episodes        | 140      |
|    fps             | 3        |
|    time_elapsed    | 3294     |
|    total timesteps | 10979    |
| train/             |          |
|    actor_loss      | -2.73    |
|    critic_loss     | 0.24     |
|    learning_rate   | 0.000989 |
|    n_updates       | 9934     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 75.6     |
|    ep_rew_mean     | 8.88     |
| time/              |          |
|    episodes        | 144      |
|    fps             | 3        |
|    time_elapsed    | 3396     |
|    total timesteps | 11291    |
| train/             |          |
|    actor_loss      | -2.69    |
|    critic_loss     | 0.106    |
|    learning_rate   | 0.000989 |
|    n_updates       | 10246    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 75.7     |
|    ep_rew_mean     | 8.88     |
| time/              |          |
|    episodes        | 148      |
|    fps             | 3        |
|    time_elapsed    | 3499     |
|    total timesteps | 11600    |
| train/             |          |
|    actor_loss      | -2.84    |
|    critic_loss     | 0.299    |
|    learning_rate   | 0.000989 |
|    n_updates       | 10556    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 75.8     |
|    ep_rew_mean     | 8.89     |
| time/              |          |
|    episodes        | 152      |
|    fps             | 3        |
|    time_elapsed    | 3600     |
|    total timesteps | 11906    |
| train/             |          |
|    actor_loss      | -2.78    |
|    critic_loss     | 0.104    |
|    learning_rate   | 0.000988 |
|    n_updates       | 10861    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 75.8     |
|    ep_rew_mean     | 8.88     |
| time/              |          |
|    episodes        | 156      |
|    fps             | 3        |
|    time_elapsed    | 3700     |
|    total timesteps | 12205    |
| train/             |          |
|    actor_loss      | -2.97    |
|    critic_loss     | 0.374    |
|    learning_rate   | 0.000988 |
|    n_updates       | 11163    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 75.9     |
|    ep_rew_mean     | 8.89     |
| time/              |          |
|    episodes        | 160      |
|    fps             | 3        |
|    time_elapsed    | 3802     |
|    total timesteps | 12513    |
| train/             |          |
|    actor_loss      | -3.01    |
|    critic_loss     | 0.342    |
|    learning_rate   | 0.000988 |
|    n_updates       | 11471    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 75.8     |
|    ep_rew_mean     | 8.88     |
| time/              |          |
|    episodes        | 164      |
|    fps             | 3        |
|    time_elapsed    | 3901     |
|    total timesteps | 12812    |
| train/             |          |
|    actor_loss      | -3.06    |
|    critic_loss     | 0.384    |
|    learning_rate   | 0.000987 |
|    n_updates       | 11768    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 75.7     |
|    ep_rew_mean     | 8.88     |
| time/              |          |
|    episodes        | 168      |
|    fps             | 3        |
|    time_elapsed    | 3998     |
|    total timesteps | 13106    |
| train/             |          |
|    actor_loss      | -3.08    |
|    critic_loss     | 0.356    |
|    learning_rate   | 0.000987 |
|    n_updates       | 12064    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 75.8     |
|    ep_rew_mean     | 8.87     |
| time/              |          |
|    episodes        | 172      |
|    fps             | 3        |
|    time_elapsed    | 4097     |
|    total timesteps | 13414    |
| train/             |          |
|    actor_loss      | -3.14    |
|    critic_loss     | 0.372    |
|    learning_rate   | 0.000987 |
|    n_updates       | 12364    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 75.8     |
|    ep_rew_mean     | 8.89     |
| time/              |          |
|    episodes        | 176      |
|    fps             | 3        |
|    time_elapsed    | 4197     |
|    total timesteps | 13708    |
| train/             |          |
|    actor_loss      | -3.05    |
|    critic_loss     | 0.923    |
|    learning_rate   | 0.000987 |
|    n_updates       | 12666    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 75.9     |
|    ep_rew_mean     | 8.91     |
| time/              |          |
|    episodes        | 180      |
|    fps             | 3        |
|    time_elapsed    | 4297     |
|    total timesteps | 14015    |
| train/             |          |
|    actor_loss      | -3.21    |
|    critic_loss     | 0.329    |
|    learning_rate   | 0.000986 |
|    n_updates       | 12968    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 75.7     |
|    ep_rew_mean     | 8.9      |
| time/              |          |
|    episodes        | 184      |
|    fps             | 3        |
|    time_elapsed    | 4397     |
|    total timesteps | 14312    |
| train/             |          |
|    actor_loss      | -3.11    |
|    critic_loss     | 0.636    |
|    learning_rate   | 0.000986 |
|    n_updates       | 13268    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 75.7     |
|    ep_rew_mean     | 8.9      |
| time/              |          |
|    episodes        | 188      |
|    fps             | 3        |
|    time_elapsed    | 4497     |
|    total timesteps | 14611    |
| train/             |          |
|    actor_loss      | -3.3     |
|    critic_loss     | 0.352    |
|    learning_rate   | 0.000986 |
|    n_updates       | 13570    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 75.7     |
|    ep_rew_mean     | 8.91     |
| time/              |          |
|    episodes        | 192      |
|    fps             | 3        |
|    time_elapsed    | 4597     |
|    total timesteps | 14916    |
| train/             |          |
|    actor_loss      | -3.35    |
|    critic_loss     | 0.352    |
|    learning_rate   | 0.000985 |
|    n_updates       | 13875    |
---------------------------------
Eval num_timesteps=15000, episode_reward=8.58 +/- 0.22
Episode length: 76.40 +/- 2.33
---------------------------------
| eval/              |          |
|    mean_ep_length  | 76.4     |
|    mean_reward     | 8.58     |
| time/              |          |
|    total_timesteps | 15000    |
| train/             |          |
|    actor_loss      | -3.37    |
|    critic_loss     | 0.353    |
|    learning_rate   | 0.000985 |
|    n_updates       | 14022    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 75.7     |
|    ep_rew_mean     | 8.9      |
| time/              |          |
|    episodes        | 196      |
|    fps             | 3        |
|    time_elapsed    | 4704     |
|    total timesteps | 15215    |
| train/             |          |
|    actor_loss      | -3.4     |
|    critic_loss     | 0.368    |
|    learning_rate   | 0.000985 |
|    n_updates       | 14170    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 75.7     |
|    ep_rew_mean     | 8.9      |
| time/              |          |
|    episodes        | 200      |
|    fps             | 3        |
|    time_elapsed    | 4806     |
|    total timesteps | 15518    |
| train/             |          |
|    actor_loss      | -3.42    |
|    critic_loss     | 0.369    |
|    learning_rate   | 0.000985 |
|    n_updates       | 14476    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 75.7     |
|    ep_rew_mean     | 8.89     |
| time/              |          |
|    episodes        | 204      |
|    fps             | 3        |
|    time_elapsed    | 4904     |
|    total timesteps | 15812    |
| train/             |          |
|    actor_loss      | -3.44    |
|    critic_loss     | 0.305    |
|    learning_rate   | 0.000984 |
|    n_updates       | 14771    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 75.5     |
|    ep_rew_mean     | 8.88     |
| time/              |          |
|    episodes        | 208      |
|    fps             | 3        |
|    time_elapsed    | 5001     |
|    total timesteps | 16112    |
| train/             |          |
|    actor_loss      | -3.52    |
|    critic_loss     | 0.385    |
|    learning_rate   | 0.000984 |
|    n_updates       | 15064    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 75.5     |
|    ep_rew_mean     | 8.87     |
| time/              |          |
|    episodes        | 212      |
|    fps             | 3        |
|    time_elapsed    | 5100     |
|    total timesteps | 16407    |
| train/             |          |
|    actor_loss      | -3.56    |
|    critic_loss     | 0.389    |
|    learning_rate   | 0.000984 |
|    n_updates       | 15364    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 75.5     |
|    ep_rew_mean     | 8.89     |
| time/              |          |
|    episodes        | 216      |
|    fps             | 3        |
|    time_elapsed    | 5200     |
|    total timesteps | 16705    |
| train/             |          |
|    actor_loss      | -3.58    |
|    critic_loss     | 0.346    |
|    learning_rate   | 0.000984 |
|    n_updates       | 15663    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 75.4     |
|    ep_rew_mean     | 8.88     |
| time/              |          |
|    episodes        | 220      |
|    fps             | 3        |
|    time_elapsed    | 5298     |
|    total timesteps | 17001    |
| train/             |          |
|    actor_loss      | -3.53    |
|    critic_loss     | 0.374    |
|    learning_rate   | 0.000983 |
|    n_updates       | 15959    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 75.3     |
|    ep_rew_mean     | 8.88     |
| time/              |          |
|    episodes        | 224      |
|    fps             | 3        |
|    time_elapsed    | 5396     |
|    total timesteps | 17296    |
| train/             |          |
|    actor_loss      | -3.54    |
|    critic_loss     | 0.38     |
|    learning_rate   | 0.000983 |
|    n_updates       | 16253    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 75.5     |
|    ep_rew_mean     | 8.88     |
| time/              |          |
|    episodes        | 228      |
|    fps             | 3        |
|    time_elapsed    | 5496     |
|    total timesteps | 17608    |
| train/             |          |
|    actor_loss      | -3.68    |
|    critic_loss     | 0.322    |
|    learning_rate   | 0.000983 |
|    n_updates       | 16556    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 75.6     |
|    ep_rew_mean     | 8.86     |
| time/              |          |
|    episodes        | 232      |
|    fps             | 3        |
|    time_elapsed    | 5600     |
|    total timesteps | 17914    |
| train/             |          |
|    actor_loss      | -3.71    |
|    critic_loss     | 0.341    |
|    learning_rate   | 0.000982 |
|    n_updates       | 16871    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 75.6     |
|    ep_rew_mean     | 8.85     |
| time/              |          |
|    episodes        | 236      |
|    fps             | 3        |
|    time_elapsed    | 5700     |
|    total timesteps | 18214    |
| train/             |          |
|    actor_loss      | -3.76    |
|    critic_loss     | 0.332    |
|    learning_rate   | 0.000982 |
|    n_updates       | 17169    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 75.4     |
|    ep_rew_mean     | 8.84     |
| time/              |          |
|    episodes        | 240      |
|    fps             | 3        |
|    time_elapsed    | 5801     |
|    total timesteps | 18519    |
| train/             |          |
|    actor_loss      | -3.76    |
|    critic_loss     | 0.267    |
|    learning_rate   | 0.000982 |
|    n_updates       | 17473    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 75.4     |
|    ep_rew_mean     | 8.88     |
| time/              |          |
|    episodes        | 244      |
|    fps             | 3        |
|    time_elapsed    | 5906     |
|    total timesteps | 18831    |
| train/             |          |
|    actor_loss      | -3.8     |
|    critic_loss     | 0.325    |
|    learning_rate   | 0.000981 |
|    n_updates       | 17786    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 75.3     |
|    ep_rew_mean     | 8.88     |
| time/              |          |
|    episodes        | 248      |
|    fps             | 3        |
|    time_elapsed    | 6005     |
|    total timesteps | 19132    |
| train/             |          |
|    actor_loss      | -3.74    |
|    critic_loss     | 0.364    |
|    learning_rate   | 0.000981 |
|    n_updates       | 18085    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 75.2     |
|    ep_rew_mean     | 8.88     |
| time/              |          |
|    episodes        | 252      |
|    fps             | 3        |
|    time_elapsed    | 6107     |
|    total timesteps | 19430    |
| train/             |          |
|    actor_loss      | -3.76    |
|    critic_loss     | 1.03     |
|    learning_rate   | 0.000981 |
|    n_updates       | 18388    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 75.3     |
|    ep_rew_mean     | 8.88     |
| time/              |          |
|    episodes        | 256      |
|    fps             | 3        |
|    time_elapsed    | 6209     |
|    total timesteps | 19734    |
| train/             |          |
|    actor_loss      | -3.91    |
|    critic_loss     | 0.382    |
|    learning_rate   | 0.000981 |
|    n_updates       | 18693    |
---------------------------------
Eval num_timesteps=20000, episode_reward=8.64 +/- 0.19
Episode length: 75.60 +/- 1.36
---------------------------------
| eval/              |          |
|    mean_ep_length  | 75.6     |
|    mean_reward     | 8.64     |
| time/              |          |
|    total_timesteps | 20000    |
| train/             |          |
|    actor_loss      | -3.93    |
|    critic_loss     | 0.372    |
|    learning_rate   | 0.00098  |
|    n_updates       | 18990    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 75.2     |
|    ep_rew_mean     | 8.86     |
| time/              |          |
|    episodes        | 260      |
|    fps             | 3        |
|    time_elapsed    | 6318     |
|    total timesteps | 20032    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 75.4     |
|    ep_rew_mean     | 8.86     |
| time/              |          |
|    episodes        | 264      |
|    fps             | 3        |
|    time_elapsed    | 6420     |
|    total timesteps | 20348    |
| train/             |          |
|    actor_loss      | -3.92    |
|    critic_loss     | 0.269    |
|    learning_rate   | 0.00098  |
|    n_updates       | 19299    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 75.5     |
|    ep_rew_mean     | 8.87     |
| time/              |          |
|    episodes        | 268      |
|    fps             | 3        |
|    time_elapsed    | 6522     |
|    total timesteps | 20660    |
| train/             |          |
|    actor_loss      | -3.91    |
|    critic_loss     | 0.255    |
|    learning_rate   | 0.00098  |
|    n_updates       | 19608    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 75.5     |
|    ep_rew_mean     | 8.87     |
| time/              |          |
|    episodes        | 272      |
|    fps             | 3        |
|    time_elapsed    | 6626     |
|    total timesteps | 20961    |
| train/             |          |
|    actor_loss      | -3.97    |
|    critic_loss     | 0.337    |
|    learning_rate   | 0.000979 |
|    n_updates       | 19918    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 75.5     |
|    ep_rew_mean     | 8.87     |
| time/              |          |
|    episodes        | 276      |
|    fps             | 3        |
|    time_elapsed    | 6725     |
|    total timesteps | 21255    |
| train/             |          |
|    actor_loss      | -3.92    |
|    critic_loss     | 0.415    |
|    learning_rate   | 0.000979 |
|    n_updates       | 20214    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 75.5     |
|    ep_rew_mean     | 8.87     |
| time/              |          |
|    episodes        | 280      |
|    fps             | 3        |
|    time_elapsed    | 6824     |
|    total timesteps | 21564    |
| train/             |          |
|    actor_loss      | -3.97    |
|    critic_loss     | 0.209    |
|    learning_rate   | 0.000979 |
|    n_updates       | 20513    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 75.7     |
|    ep_rew_mean     | 8.86     |
| time/              |          |
|    episodes        | 284      |
|    fps             | 3        |
|    time_elapsed    | 6933     |
|    total timesteps | 21880    |
| train/             |          |
|    actor_loss      | -4.01    |
|    critic_loss     | 0.313    |
|    learning_rate   | 0.000978 |
|    n_updates       | 20838    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 75.7     |
|    ep_rew_mean     | 8.85     |
| time/              |          |
|    episodes        | 288      |
|    fps             | 3        |
|    time_elapsed    | 7032     |
|    total timesteps | 22177    |
| train/             |          |
|    actor_loss      | -4.02    |
|    critic_loss     | 0.314    |
|    learning_rate   | 0.000978 |
|    n_updates       | 21134    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 75.6     |
|    ep_rew_mean     | 8.85     |
| time/              |          |
|    episodes        | 292      |
|    fps             | 3        |
|    time_elapsed    | 7129     |
|    total timesteps | 22474    |
| train/             |          |
|    actor_loss      | -3.96    |
|    critic_loss     | 0.36     |
|    learning_rate   | 0.000978 |
|    n_updates       | 21431    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 75.5     |
|    ep_rew_mean     | 8.87     |
| time/              |          |
|    episodes        | 296      |
|    fps             | 3        |
|    time_elapsed    | 7227     |
|    total timesteps | 22767    |
| train/             |          |
|    actor_loss      | -3.98    |
|    critic_loss     | 0.343    |
|    learning_rate   | 0.000978 |
|    n_updates       | 21723    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 75.5     |
|    ep_rew_mean     | 8.89     |
| time/              |          |
|    episodes        | 300      |
|    fps             | 3        |
|    time_elapsed    | 7329     |
|    total timesteps | 23072    |
| train/             |          |
|    actor_loss      | -4.08    |
|    critic_loss     | 0.269    |
|    learning_rate   | 0.000977 |
|    n_updates       | 22029    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 75.7     |
|    ep_rew_mean     | 8.92     |
| time/              |          |
|    episodes        | 304      |
|    fps             | 3        |
|    time_elapsed    | 7431     |
|    total timesteps | 23382    |
| train/             |          |
|    actor_loss      | -4.11    |
|    critic_loss     | 0.313    |
|    learning_rate   | 0.000977 |
|    n_updates       | 22334    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 75.6     |
|    ep_rew_mean     | 8.91     |
| time/              |          |
|    episodes        | 308      |
|    fps             | 3        |
|    time_elapsed    | 7531     |
|    total timesteps | 23676    |
| train/             |          |
|    actor_loss      | -4.05    |
|    critic_loss     | 2.09     |
|    learning_rate   | 0.000977 |
|    n_updates       | 22633    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 75.7     |
|    ep_rew_mean     | 8.91     |
| time/              |          |
|    episodes        | 312      |
|    fps             | 3        |
|    time_elapsed    | 7630     |
|    total timesteps | 23981    |
| train/             |          |
|    actor_loss      | -4.04    |
|    critic_loss     | 1.44     |
|    learning_rate   | 0.000976 |
|    n_updates       | 22929    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 75.8     |
|    ep_rew_mean     | 8.9      |
| time/              |          |
|    episodes        | 316      |
|    fps             | 3        |
|    time_elapsed    | 7735     |
|    total timesteps | 24288    |
| train/             |          |
|    actor_loss      | -4.18    |
|    critic_loss     | 0.364    |
|    learning_rate   | 0.000976 |
|    n_updates       | 23244    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 75.8     |
|    ep_rew_mean     | 8.89     |
| time/              |          |
|    episodes        | 320      |
|    fps             | 3        |
|    time_elapsed    | 7834     |
|    total timesteps | 24584    |
| train/             |          |
|    actor_loss      | -4.18    |
|    critic_loss     | 0.337    |
|    learning_rate   | 0.000976 |
|    n_updates       | 23541    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 75.9     |
|    ep_rew_mean     | 8.9      |
| time/              |          |
|    episodes        | 324      |
|    fps             | 3        |
|    time_elapsed    | 7934     |
|    total timesteps | 24884    |
| train/             |          |
|    actor_loss      | -4.18    |
|    critic_loss     | 0.305    |
|    learning_rate   | 0.000975 |
|    n_updates       | 23841    |
---------------------------------
Eval num_timesteps=25000, episode_reward=8.68 +/- 0.05
Episode length: 76.20 +/- 3.12
---------------------------------
| eval/              |          |
|    mean_ep_length  | 76.2     |
|    mean_reward     | 8.68     |
| time/              |          |
|    total_timesteps | 25000    |
| train/             |          |
|    actor_loss      | -4.19    |
|    critic_loss     | 0.326    |
|    learning_rate   | 0.000975 |
|    n_updates       | 23989    |
---------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 75.7     |
|    ep_rew_mean     | 8.91     |
| time/              |          |
|    episodes        | 328      |
|    fps             | 3        |
|    time_elapsed    | 8043     |
|    total timesteps | 25181    |
| train/             |          |
|    actor_loss      | -4.19    |
|    critic_loss     | 0.32     |
|    learning_rate   | 0.000975 |
|    n_updates       | 24138    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 75.6     |
|    ep_rew_mean     | 8.93     |
| time/              |          |
|    episodes        | 332      |
|    fps             | 3        |
|    time_elapsed    | 8141     |
|    total timesteps | 25475    |
| train/             |          |
|    actor_loss      | -4.13    |
|    critic_loss     | 1.1      |
|    learning_rate   | 0.000975 |
|    n_updates       | 24433    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 75.5     |
|    ep_rew_mean     | 8.93     |
| time/              |          |
|    episodes        | 336      |
|    fps             | 3        |
|    time_elapsed    | 8239     |
|    total timesteps | 25769    |
| train/             |          |
|    actor_loss      | -4.13    |
|    critic_loss     | 0.337    |
|    learning_rate   | 0.000975 |
|    n_updates       | 24727    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 75.5     |
|    ep_rew_mean     | 8.94     |
| time/              |          |
|    episodes        | 340      |
|    fps             | 3        |
|    time_elapsed    | 8336     |
|    total timesteps | 26064    |
| train/             |          |
|    actor_loss      | -4.19    |
|    critic_loss     | 1.45     |
|    learning_rate   | 0.000974 |
|    n_updates       | 25016    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 75.3     |
|    ep_rew_mean     | 8.91     |
| time/              |          |
|    episodes        | 344      |
|    fps             | 3        |
|    time_elapsed    | 8436     |
|    total timesteps | 26362    |
| train/             |          |
|    actor_loss      | -4.16    |
|    critic_loss     | 0.761    |
|    learning_rate   | 0.000974 |
|    n_updates       | 25316    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 75.3     |
|    ep_rew_mean     | 8.92     |
| time/              |          |
|    episodes        | 348      |
|    fps             | 3        |
|    time_elapsed    | 8540     |
|    total timesteps | 26667    |
| train/             |          |
|    actor_loss      | -4.25    |
|    critic_loss     | 0.298    |
|    learning_rate   | 0.000974 |
|    n_updates       | 25624    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 75.4     |
|    ep_rew_mean     | 8.93     |
| time/              |          |
|    episodes        | 352      |
|    fps             | 3        |
|    time_elapsed    | 8642     |
|    total timesteps | 26970    |
| train/             |          |
|    actor_loss      | -4.25    |
|    critic_loss     | 0.256    |
|    learning_rate   | 0.000973 |
|    n_updates       | 25927    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 75.4     |
|    ep_rew_mean     | 8.93     |
| time/              |          |
|    episodes        | 356      |
|    fps             | 3        |
|    time_elapsed    | 8742     |
|    total timesteps | 27270    |
| train/             |          |
|    actor_loss      | -4.3     |
|    critic_loss     | 0.349    |
|    learning_rate   | 0.000973 |
|    n_updates       | 26226    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 75.3     |
|    ep_rew_mean     | 8.93     |
| time/              |          |
|    episodes        | 360      |
|    fps             | 3        |
|    time_elapsed    | 8868     |
|    total timesteps | 27562    |
| train/             |          |
|    actor_loss      | -4.19    |
|    critic_loss     | 2.14     |
|    learning_rate   | 0.000973 |
|    n_updates       | 26520    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 75.1     |
|    ep_rew_mean     | 8.94     |
| time/              |          |
|    episodes        | 364      |
|    fps             | 3        |
|    time_elapsed    | 8970     |
|    total timesteps | 27854    |
| train/             |          |
|    actor_loss      | -4.25    |
|    critic_loss     | 0.353    |
|    learning_rate   | 0.000972 |
|    n_updates       | 26811    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 75       |
|    ep_rew_mean     | 8.94     |
| time/              |          |
|    episodes        | 368      |
|    fps             | 3        |
|    time_elapsed    | 9073     |
|    total timesteps | 28161    |
| train/             |          |
|    actor_loss      | -4.33    |
|    critic_loss     | 0.322    |
|    learning_rate   | 0.000972 |
|    n_updates       | 27119    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 75       |
|    ep_rew_mean     | 8.95     |
| time/              |          |
|    episodes        | 372      |
|    fps             | 3        |
|    time_elapsed    | 9173     |
|    total timesteps | 28463    |
| train/             |          |
|    actor_loss      | -4.32    |
|    critic_loss     | 0.29     |
|    learning_rate   | 0.000972 |
|    n_updates       | 27415    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 75       |
|    ep_rew_mean     | 8.94     |
| time/              |          |
|    episodes        | 376      |
|    fps             | 3        |
|    time_elapsed    | 9277     |
|    total timesteps | 28756    |
| train/             |          |
|    actor_loss      | -4.36    |
|    critic_loss     | 0.355    |
|    learning_rate   | 0.000972 |
|    n_updates       | 27716    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 75       |
|    ep_rew_mean     | 8.93     |
| time/              |          |
|    episodes        | 380      |
|    fps             | 3        |
|    time_elapsed    | 9382     |
|    total timesteps | 29062    |
| train/             |          |
|    actor_loss      | -4.37    |
|    critic_loss     | 0.347    |
|    learning_rate   | 0.000971 |
|    n_updates       | 28016    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 75       |
|    ep_rew_mean     | 8.95     |
| time/              |          |
|    episodes        | 384      |
|    fps             | 3        |
|    time_elapsed    | 9490     |
|    total timesteps | 29380    |
| train/             |          |
|    actor_loss      | -4.38    |
|    critic_loss     | 0.355    |
|    learning_rate   | 0.000971 |
|    n_updates       | 28334    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 75.1     |
|    ep_rew_mean     | 8.95     |
| time/              |          |
|    episodes        | 388      |
|    fps             | 3        |
|    time_elapsed    | 9597     |
|    total timesteps | 29684    |
| train/             |          |
|    actor_loss      | -4.39    |
|    critic_loss     | 0.362    |
|    learning_rate   | 0.000971 |
|    n_updates       | 28641    |
---------------------------------
Eval num_timesteps=30000, episode_reward=8.56 +/- 0.21
Episode length: 75.80 +/- 6.14
---------------------------------
| eval/              |          |
|    mean_ep_length  | 75.8     |
|    mean_reward     | 8.56     |
| time/              |          |
|    total_timesteps | 30000    |
| train/             |          |
|    actor_loss      | -4.36    |
|    critic_loss     | 0.235    |
|    learning_rate   | 0.00097  |
|    n_updates       | 28952    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 75.3     |
|    ep_rew_mean     | 8.96     |
| time/              |          |
|    episodes        | 392      |
|    fps             | 3        |
|    time_elapsed    | 9711     |
|    total timesteps | 30006    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 75.5     |
|    ep_rew_mean     | 8.94     |
| time/              |          |
|    episodes        | 396      |
|    fps             | 3        |
|    time_elapsed    | 9820     |
|    total timesteps | 30314    |
| train/             |          |
|    actor_loss      | -4.4     |
|    critic_loss     | 0.358    |
|    learning_rate   | 0.00097  |
|    n_updates       | 29267    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 75.4     |
|    ep_rew_mean     | 8.92     |
| time/              |          |
|    episodes        | 400      |
|    fps             | 3        |
|    time_elapsed    | 9923     |
|    total timesteps | 30616    |
| train/             |          |
|    actor_loss      | -4.42    |
|    critic_loss     | 0.383    |
|    learning_rate   | 0.00097  |
|    n_updates       | 29572    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 75.3     |
|    ep_rew_mean     | 8.89     |
| time/              |          |
|    episodes        | 404      |
|    fps             | 3        |
|    time_elapsed    | 10025    |
|    total timesteps | 30915    |
| train/             |          |
|    actor_loss      | -4.43    |
|    critic_loss     | 0.332    |
|    learning_rate   | 0.000969 |
|    n_updates       | 29873    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 75.5     |
|    ep_rew_mean     | 8.92     |
| time/              |          |
|    episodes        | 408      |
|    fps             | 3        |
|    time_elapsed    | 10127    |
|    total timesteps | 31229    |
| train/             |          |
|    actor_loss      | -4.42    |
|    critic_loss     | 0.283    |
|    learning_rate   | 0.000969 |
|    n_updates       | 30178    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 75.6     |
|    ep_rew_mean     | 8.92     |
| time/              |          |
|    episodes        | 412      |
|    fps             | 3        |
|    time_elapsed    | 10236    |
|    total timesteps | 31543    |
| train/             |          |
|    actor_loss      | -4.35    |
|    critic_loss     | 0.162    |
|    learning_rate   | 0.000969 |
|    n_updates       | 30500    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 75.8     |
|    ep_rew_mean     | 8.92     |
| time/              |          |
|    episodes        | 416      |
|    fps             | 3        |
|    time_elapsed    | 10341    |
|    total timesteps | 31865    |
| train/             |          |
|    actor_loss      | -4.39    |
|    critic_loss     | 0.281    |
|    learning_rate   | 0.000969 |
|    n_updates       | 30809    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 75.7     |
|    ep_rew_mean     | 8.94     |
| time/              |          |
|    episodes        | 420      |
|    fps             | 3        |
|    time_elapsed    | 10445    |
|    total timesteps | 32158    |
| train/             |          |
|    actor_loss      | -4.29    |
|    critic_loss     | 1.14     |
|    learning_rate   | 0.000968 |
|    n_updates       | 31116    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 75.7     |
|    ep_rew_mean     | 8.93     |
| time/              |          |
|    episodes        | 424      |
|    fps             | 3        |
|    time_elapsed    | 10545    |
|    total timesteps | 32451    |
| train/             |          |
|    actor_loss      | -4.44    |
|    critic_loss     | 0.345    |
|    learning_rate   | 0.000968 |
|    n_updates       | 31410    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 75.6     |
|    ep_rew_mean     | 8.94     |
| time/              |          |
|    episodes        | 428      |
|    fps             | 3        |
|    time_elapsed    | 10644    |
|    total timesteps | 32743    |
| train/             |          |
|    actor_loss      | -4.45    |
|    critic_loss     | 0.354    |
|    learning_rate   | 0.000968 |
|    n_updates       | 31702    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 75.7     |
|    ep_rew_mean     | 8.91     |
| time/              |          |
|    episodes        | 432      |
|    fps             | 3        |
|    time_elapsed    | 10746    |
|    total timesteps | 33044    |
| train/             |          |
|    actor_loss      | -4.44    |
|    critic_loss     | 0.308    |
|    learning_rate   | 0.000967 |
|    n_updates       | 32000    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 75.8     |
|    ep_rew_mean     | 8.93     |
| time/              |          |
|    episodes        | 436      |
|    fps             | 3        |
|    time_elapsed    | 10849    |
|    total timesteps | 33346    |
| train/             |          |
|    actor_loss      | -4.49    |
|    critic_loss     | 0.378    |
|    learning_rate   | 0.000967 |
|    n_updates       | 32303    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 75.8     |
|    ep_rew_mean     | 8.94     |
| time/              |          |
|    episodes        | 440      |
|    fps             | 3        |
|    time_elapsed    | 10949    |
|    total timesteps | 33646    |
| train/             |          |
|    actor_loss      | -4.49    |
|    critic_loss     | 0.378    |
|    learning_rate   | 0.000967 |
|    n_updates       | 32598    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 75.9     |
|    ep_rew_mean     | 8.94     |
| time/              |          |
|    episodes        | 444      |
|    fps             | 3        |
|    time_elapsed    | 11057    |
|    total timesteps | 33955    |
| train/             |          |
|    actor_loss      | -4.49    |
|    critic_loss     | 0.382    |
|    learning_rate   | 0.000966 |
|    n_updates       | 32912    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 75.9     |
|    ep_rew_mean     | 8.94     |
| time/              |          |
|    episodes        | 448      |
|    fps             | 3        |
|    time_elapsed    | 11158    |
|    total timesteps | 34257    |
| train/             |          |
|    actor_loss      | -4.47    |
|    critic_loss     | 0.31     |
|    learning_rate   | 0.000966 |
|    n_updates       | 33208    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 75.9     |
|    ep_rew_mean     | 8.94     |
| time/              |          |
|    episodes        | 452      |
|    fps             | 3        |
|    time_elapsed    | 11262    |
|    total timesteps | 34559    |
| train/             |          |
|    actor_loss      | -4.48    |
|    critic_loss     | 0.329    |
|    learning_rate   | 0.000966 |
|    n_updates       | 33511    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 75.9     |
|    ep_rew_mean     | 8.95     |
| time/              |          |
|    episodes        | 456      |
|    fps             | 3        |
|    time_elapsed    | 11367    |
|    total timesteps | 34861    |
| train/             |          |
|    actor_loss      | -4.47    |
|    critic_loss     | 0.31     |
|    learning_rate   | 0.000966 |
|    n_updates       | 33820    |
---------------------------------
Eval num_timesteps=35000, episode_reward=8.56 +/- 0.20
Episode length: 77.40 +/- 2.58
---------------------------------
| eval/              |          |
|    mean_ep_length  | 77.4     |
|    mean_reward     | 8.56     |
| time/              |          |
|    total_timesteps | 35000    |
| train/             |          |
|    actor_loss      | -4.36    |
|    critic_loss     | 0.342    |
|    learning_rate   | 0.000965 |
|    n_updates       | 33965    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 76       |
|    ep_rew_mean     | 8.95     |
| time/              |          |
|    episodes        | 460      |
|    fps             | 3        |
|    time_elapsed    | 11475    |
|    total timesteps | 35158    |
| train/             |          |
|    actor_loss      | -4.49    |
|    critic_loss     | 0.353    |
|    learning_rate   | 0.000965 |
|    n_updates       | 34112    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 76.1     |
|    ep_rew_mean     | 8.93     |
| time/              |          |
|    episodes        | 464      |
|    fps             | 3        |
|    time_elapsed    | 11581    |
|    total timesteps | 35466    |
| train/             |          |
|    actor_loss      | -4.5     |
|    critic_loss     | 0.373    |
|    learning_rate   | 0.000965 |
|    n_updates       | 34420    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 76       |
|    ep_rew_mean     | 8.92     |
| time/              |          |
|    episodes        | 468      |
|    fps             | 3        |
|    time_elapsed    | 11684    |
|    total timesteps | 35758    |
| train/             |          |
|    actor_loss      | -4.49    |
|    critic_loss     | 0.334    |
|    learning_rate   | 0.000965 |
|    n_updates       | 34716    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 75.9     |
|    ep_rew_mean     | 8.92     |
| time/              |          |
|    episodes        | 472      |
|    fps             | 3        |
|    time_elapsed    | 11785    |
|    total timesteps | 36057    |
| train/             |          |
|    actor_loss      | -4.52    |
|    critic_loss     | 0.356    |
|    learning_rate   | 0.000964 |
|    n_updates       | 35013    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 76.1     |
|    ep_rew_mean     | 8.93     |
| time/              |          |
|    episodes        | 476      |
|    fps             | 3        |
|    time_elapsed    | 11890    |
|    total timesteps | 36366    |
| train/             |          |
|    actor_loss      | -4.48    |
|    critic_loss     | 0.279    |
|    learning_rate   | 0.000964 |
|    n_updates       | 35318    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 76       |
|    ep_rew_mean     | 8.93     |
| time/              |          |
|    episodes        | 480      |
|    fps             | 3        |
|    time_elapsed    | 11993    |
|    total timesteps | 36662    |
| train/             |          |
|    actor_loss      | -4.38    |
|    critic_loss     | 0.431    |
|    learning_rate   | 0.000964 |
|    n_updates       | 35618    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 75.8     |
|    ep_rew_mean     | 8.92     |
| time/              |          |
|    episodes        | 484      |
|    fps             | 3        |
|    time_elapsed    | 12095    |
|    total timesteps | 36963    |
| train/             |          |
|    actor_loss      | -4.5     |
|    critic_loss     | 0.294    |
|    learning_rate   | 0.000963 |
|    n_updates       | 35915    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 75.8     |
|    ep_rew_mean     | 8.91     |
| time/              |          |
|    episodes        | 488      |
|    fps             | 3        |
|    time_elapsed    | 12201    |
|    total timesteps | 37262    |
| train/             |          |
|    actor_loss      | -4.42    |
|    critic_loss     | 0.363    |
|    learning_rate   | 0.000963 |
|    n_updates       | 36219    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 75.6     |
|    ep_rew_mean     | 8.92     |
| time/              |          |
|    episodes        | 492      |
|    fps             | 3        |
|    time_elapsed    | 12306    |
|    total timesteps | 37563    |
| train/             |          |
|    actor_loss      | -4.51    |
|    critic_loss     | 0.308    |
|    learning_rate   | 0.000963 |
|    n_updates       | 36520    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 75.5     |
|    ep_rew_mean     | 8.91     |
| time/              |          |
|    episodes        | 496      |
|    fps             | 3        |
|    time_elapsed    | 12408    |
|    total timesteps | 37862    |
| train/             |          |
|    actor_loss      | -4.41    |
|    critic_loss     | 0.366    |
|    learning_rate   | 0.000963 |
|    n_updates       | 36815    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 75.6     |
|    ep_rew_mean     | 8.93     |
| time/              |          |
|    episodes        | 500      |
|    fps             | 3        |
|    time_elapsed    | 12516    |
|    total timesteps | 38172    |
| train/             |          |
|    actor_loss      | -4.53    |
|    critic_loss     | 0.32     |
|    learning_rate   | 0.000962 |
|    n_updates       | 37125    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 75.6     |
|    ep_rew_mean     | 8.92     |
| time/              |          |
|    episodes        | 504      |
|    fps             | 3        |
|    time_elapsed    | 12622    |
|    total timesteps | 38479    |
| train/             |          |
|    actor_loss      | -4.56    |
|    critic_loss     | 0.387    |
|    learning_rate   | 0.000962 |
|    n_updates       | 37430    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 75.5     |
|    ep_rew_mean     | 8.91     |
| time/              |          |
|    episodes        | 508      |
|    fps             | 3        |
|    time_elapsed    | 12729    |
|    total timesteps | 38781    |
| train/             |          |
|    actor_loss      | -4.54    |
|    critic_loss     | 0.3      |
|    learning_rate   | 0.000962 |
|    n_updates       | 37736    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 75.4     |
|    ep_rew_mean     | 8.91     |
| time/              |          |
|    episodes        | 512      |
|    fps             | 3        |
|    time_elapsed    | 12834    |
|    total timesteps | 39080    |
| train/             |          |
|    actor_loss      | -4.55    |
|    critic_loss     | 0.341    |
|    learning_rate   | 0.000961 |
|    n_updates       | 38039    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 75.1     |
|    ep_rew_mean     | 8.92     |
| time/              |          |
|    episodes        | 516      |
|    fps             | 3        |
|    time_elapsed    | 12937    |
|    total timesteps | 39374    |
| train/             |          |
|    actor_loss      | -4.46    |
|    critic_loss     | 1.14     |
|    learning_rate   | 0.000961 |
|    n_updates       | 38331    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 75.2     |
|    ep_rew_mean     | 8.9      |
| time/              |          |
|    episodes        | 520      |
|    fps             | 3        |
|    time_elapsed    | 13043    |
|    total timesteps | 39674    |
| train/             |          |
|    actor_loss      | -4.55    |
|    critic_loss     | 0.304    |
|    learning_rate   | 0.000961 |
|    n_updates       | 38633    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 75.3     |
|    ep_rew_mean     | 8.91     |
| time/              |          |
|    episodes        | 524      |
|    fps             | 3        |
|    time_elapsed    | 13148    |
|    total timesteps | 39977    |
| train/             |          |
|    actor_loss      | -4.54    |
|    critic_loss     | 0.306    |
|    learning_rate   | 0.00096  |
|    n_updates       | 38932    |
---------------------------------
Eval num_timesteps=40000, episode_reward=8.77 +/- 0.18
Episode length: 74.20 +/- 1.47
---------------------------------
| eval/              |          |
|    mean_ep_length  | 74.2     |
|    mean_reward     | 8.77     |
| time/              |          |
|    total_timesteps | 40000    |
| train/             |          |
|    actor_loss      | -4.53    |
|    critic_loss     | 0.31     |
|    learning_rate   | 0.00096  |
|    n_updates       | 39008    |
---------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 75.3     |
|    ep_rew_mean     | 8.91     |
| time/              |          |
|    episodes        | 528      |
|    fps             | 3        |
|    time_elapsed    | 13265    |
|    total timesteps | 40274    |
| train/             |          |
|    actor_loss      | -4.47    |
|    critic_loss     | 0.35     |
|    learning_rate   | 0.00096  |
|    n_updates       | 39231    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 75.3     |
|    ep_rew_mean     | 8.89     |
| time/              |          |
|    episodes        | 532      |
|    fps             | 3        |
|    time_elapsed    | 13371    |
|    total timesteps | 40573    |
| train/             |          |
|    actor_loss      | -4.46    |
|    critic_loss     | 1.85     |
|    learning_rate   | 0.00096  |
|    n_updates       | 39531    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 75.4     |
|    ep_rew_mean     | 8.9      |
| time/              |          |
|    episodes        | 536      |
|    fps             | 3        |
|    time_elapsed    | 13478    |
|    total timesteps | 40883    |
| train/             |          |
|    actor_loss      | -4.57    |
|    critic_loss     | 0.334    |
|    learning_rate   | 0.00096  |
|    n_updates       | 39831    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 75.4     |
|    ep_rew_mean     | 8.87     |
| time/              |          |
|    episodes        | 540      |
|    fps             | 3        |
|    time_elapsed    | 13588    |
|    total timesteps | 41184    |
| train/             |          |
|    actor_loss      | -4.59    |
|    critic_loss     | 0.379    |
|    learning_rate   | 0.000959 |
|    n_updates       | 40138    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 75.3     |
|    ep_rew_mean     | 8.87     |
| time/              |          |
|    episodes        | 544      |
|    fps             | 3        |
|    time_elapsed    | 13694    |
|    total timesteps | 41481    |
| train/             |          |
|    actor_loss      | -4.59    |
|    critic_loss     | 0.375    |
|    learning_rate   | 0.000959 |
|    n_updates       | 40439    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 75.1     |
|    ep_rew_mean     | 8.86     |
| time/              |          |
|    episodes        | 548      |
|    fps             | 3        |
|    time_elapsed    | 13798    |
|    total timesteps | 41771    |
| train/             |          |
|    actor_loss      | -4.59    |
|    critic_loss     | 0.37     |
|    learning_rate   | 0.000959 |
|    n_updates       | 40730    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 75.2     |
|    ep_rew_mean     | 8.84     |
| time/              |          |
|    episodes        | 552      |
|    fps             | 3        |
|    time_elapsed    | 13904    |
|    total timesteps | 42074    |
| train/             |          |
|    actor_loss      | -4.56    |
|    critic_loss     | 0.265    |
|    learning_rate   | 0.000958 |
|    n_updates       | 41029    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 75.3     |
|    ep_rew_mean     | 8.84     |
| time/              |          |
|    episodes        | 556      |
|    fps             | 3        |
|    time_elapsed    | 14017    |
|    total timesteps | 42388    |
| train/             |          |
|    actor_loss      | -4.56    |
|    critic_loss     | 0.293    |
|    learning_rate   | 0.000958 |
|    n_updates       | 41347    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 75.4     |
|    ep_rew_mean     | 8.84     |
| time/              |          |
|    episodes        | 560      |
|    fps             | 3        |
|    time_elapsed    | 14125    |
|    total timesteps | 42694    |
| train/             |          |
|    actor_loss      | -4.57    |
|    critic_loss     | 0.295    |
|    learning_rate   | 0.000958 |
|    n_updates       | 41651    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 75.3     |
|    ep_rew_mean     | 8.84     |
| time/              |          |
|    episodes        | 564      |
|    fps             | 3        |
|    time_elapsed    | 14232    |
|    total timesteps | 42993    |
| train/             |          |
|    actor_loss      | -4.59    |
|    critic_loss     | 0.328    |
|    learning_rate   | 0.000958 |
|    n_updates       | 41949    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 75.3     |
|    ep_rew_mean     | 8.84     |
| time/              |          |
|    episodes        | 568      |
|    fps             | 3        |
|    time_elapsed    | 14340    |
|    total timesteps | 43290    |
| train/             |          |
|    actor_loss      | -4.6     |
|    critic_loss     | 0.346    |
|    learning_rate   | 0.000957 |
|    n_updates       | 42248    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 75.3     |
|    ep_rew_mean     | 8.84     |
| time/              |          |
|    episodes        | 572      |
|    fps             | 3        |
|    time_elapsed    | 14447    |
|    total timesteps | 43590    |
| train/             |          |
|    actor_loss      | -4.6     |
|    critic_loss     | 0.372    |
|    learning_rate   | 0.000957 |
|    n_updates       | 42548    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 75.2     |
|    ep_rew_mean     | 8.84     |
| time/              |          |
|    episodes        | 576      |
|    fps             | 3        |
|    time_elapsed    | 14554    |
|    total timesteps | 43887    |
| train/             |          |
|    actor_loss      | -4.51    |
|    critic_loss     | 0.373    |
|    learning_rate   | 0.000957 |
|    n_updates       | 42845    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 75.4     |
|    ep_rew_mean     | 8.83     |
| time/              |          |
|    episodes        | 580      |
|    fps             | 3        |
|    time_elapsed    | 14667    |
|    total timesteps | 44205    |
| train/             |          |
|    actor_loss      | -4.57    |
|    critic_loss     | 0.302    |
|    learning_rate   | 0.000956 |
|    n_updates       | 43160    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 75.5     |
|    ep_rew_mean     | 8.83     |
| time/              |          |
|    episodes        | 584      |
|    fps             | 3        |
|    time_elapsed    | 14777    |
|    total timesteps | 44509    |
| train/             |          |
|    actor_loss      | -4.57    |
|    critic_loss     | 0.302    |
|    learning_rate   | 0.000956 |
|    n_updates       | 43463    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 75.5     |
|    ep_rew_mean     | 8.83     |
| time/              |          |
|    episodes        | 588      |
|    fps             | 3        |
|    time_elapsed    | 14886    |
|    total timesteps | 44807    |
| train/             |          |
|    actor_loss      | -4.59    |
|    critic_loss     | 0.328    |
|    learning_rate   | 0.000956 |
|    n_updates       | 43763    |
---------------------------------
Eval num_timesteps=45000, episode_reward=8.73 +/- 0.20
Episode length: 76.40 +/- 2.33
---------------------------------
| eval/              |          |
|    mean_ep_length  | 76.4     |
|    mean_reward     | 8.73     |
| time/              |          |
|    total_timesteps | 45000    |
| train/             |          |
|    actor_loss      | -4.58    |
|    critic_loss     | 0.323    |
|    learning_rate   | 0.000955 |
|    n_updates       | 43990    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 75.5     |
|    ep_rew_mean     | 8.82     |
| time/              |          |
|    episodes        | 592      |
|    fps             | 3        |
|    time_elapsed    | 15008    |
|    total timesteps | 45118    |
| train/             |          |
|    actor_loss      | -4.51    |
|    critic_loss     | 0.193    |
|    learning_rate   | 0.000955 |
|    n_updates       | 44074    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 75.5     |
|    ep_rew_mean     | 8.82     |
| time/              |          |
|    episodes        | 596      |
|    fps             | 3        |
|    time_elapsed    | 15115    |
|    total timesteps | 45413    |
| train/             |          |
|    actor_loss      | -4.58    |
|    critic_loss     | 0.346    |
|    learning_rate   | 0.000955 |
|    n_updates       | 44370    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 75.5     |
|    ep_rew_mean     | 8.83     |
| time/              |          |
|    episodes        | 600      |
|    fps             | 3        |
|    time_elapsed    | 15224    |
|    total timesteps | 45721    |
| train/             |          |
|    actor_loss      | -4.58    |
|    critic_loss     | 0.332    |
|    learning_rate   | 0.000955 |
|    n_updates       | 44671    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 75.4     |
|    ep_rew_mean     | 8.83     |
| time/              |          |
|    episodes        | 604      |
|    fps             | 3        |
|    time_elapsed    | 15334    |
|    total timesteps | 46018    |
| train/             |          |
|    actor_loss      | -4.55    |
|    critic_loss     | 0.276    |
|    learning_rate   | 0.000955 |
|    n_updates       | 44975    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 75.4     |
|    ep_rew_mean     | 8.83     |
| time/              |          |
|    episodes        | 608      |
|    fps             | 2        |
|    time_elapsed    | 15446    |
|    total timesteps | 46324    |
| train/             |          |
|    actor_loss      | -4.46    |
|    critic_loss     | 1.14     |
|    learning_rate   | 0.000954 |
|    n_updates       | 45282    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 75.4     |
|    ep_rew_mean     | 8.83     |
| time/              |          |
|    episodes        | 612      |
|    fps             | 2        |
|    time_elapsed    | 15554    |
|    total timesteps | 46620    |
| train/             |          |
|    actor_loss      | -4.58    |
|    critic_loss     | 0.333    |
|    learning_rate   | 0.000954 |
|    n_updates       | 45577    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 75.4     |
|    ep_rew_mean     | 8.84     |
| time/              |          |
|    episodes        | 616      |
|    fps             | 2        |
|    time_elapsed    | 15661    |
|    total timesteps | 46913    |
| train/             |          |
|    actor_loss      | -4.57    |
|    critic_loss     | 0.336    |
|    learning_rate   | 0.000954 |
|    n_updates       | 45870    |
---------------------------------
Terminated
