/home/shandilya/Desktop/Projects/NavigationController
Env Type: maze
Task: GoalRewardSimple
Traceback (most recent call last):
  File "train.py", line 80, in <module>
    lmbda = args.lmbda
  File "/home/shandilya/Desktop/Projects/NavigationController/learning/explore.py", line 73, in __init__
    lambda : sb3.common.monitor.Monitor(env_class(
  File "/home/shandilya/py36/lib/python3.6/site-packages/stable_baselines3/common/vec_env/dummy_vec_env.py", line 25, in __init__
    self.envs = [fn() for fn in env_fns]
  File "/home/shandilya/py36/lib/python3.6/site-packages/stable_baselines3/common/vec_env/dummy_vec_env.py", line 25, in <listcomp>
    self.envs = [fn() for fn in env_fns]
  File "/home/shandilya/Desktop/Projects/NavigationController/learning/explore.py", line 78, in <lambda>
    history_steps
  File "/home/shandilya/Desktop/Projects/NavigationController/simulations/maze_env.py", line 117, in __init__
    self.set_env()
  File "/home/shandilya/Desktop/Projects/NavigationController/simulations/maze_env.py", line 244, in set_env
    self.sampled_path = self.__sample_path()
  File "/home/shandilya/Desktop/Projects/NavigationController/simulations/maze_env.py", line 310, in __sample_path
    target
  File "/home/shandilya/py36/lib/python3.6/site-packages/networkx/algorithms/shortest_paths/generic.py", line 526, in _build_paths_from_predecessors
    f"Target {target} cannot be reached" f"from given sources"
networkx.exception.NetworkXNoPath: Target 9 cannot be reachedfrom given sources
2021-12-17 12:50:39.042658: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/shandilya/.mujoco/mjpro150/bin
2021-12-17 12:50:39.042694: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
/home/shandilya/Desktop/Projects/NavigationController
Env Type: maze
Task: GoalRewardSimple
Model: <class 'stable_baselines3.td3.td3.TD3'>
Using cpu device
Logging to assets/out/models/exp17/TD3_7
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 225      |
|    ep_rew_mean     | 0.742    |
| time/              |          |
|    episodes        | 4        |
|    fps             | 65       |
|    time_elapsed    | 13       |
|    total timesteps | 900      |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 234      |
|    ep_rew_mean     | 11.7     |
| time/              |          |
|    episodes        | 8        |
|    fps             | 74       |
|    time_elapsed    | 25       |
|    total timesteps | 1874     |
---------------------------------
Traceback (most recent call last):
  File "train.py", line 82, in <module>
    model.learn(args.timesteps)
  File "/home/shandilya/Desktop/Projects/NavigationController/learning/explore.py", line 229, in learn
    callback = self.rl_callback
  File "/home/shandilya/py36/lib/python3.6/site-packages/stable_baselines3/td3/td3.py", line 211, in learn
    reset_num_timesteps=reset_num_timesteps,
  File "/home/shandilya/py36/lib/python3.6/site-packages/stable_baselines3/common/off_policy_algorithm.py", line 359, in learn
    log_interval=log_interval,
  File "/home/shandilya/py36/lib/python3.6/site-packages/stable_baselines3/common/off_policy_algorithm.py", line 563, in collect_rollouts
    action, buffer_action = self._sample_action(learning_starts, action_noise)
  File "/home/shandilya/py36/lib/python3.6/site-packages/stable_baselines3/common/off_policy_algorithm.py", line 407, in _sample_action
    unscaled_action, _ = self.predict(self._last_obs, deterministic=False)
  File "/home/shandilya/py36/lib/python3.6/site-packages/stable_baselines3/common/base_class.py", line 539, in predict
    return self.policy.predict(observation, state, mask, deterministic)
  File "/home/shandilya/py36/lib/python3.6/site-packages/stable_baselines3/common/policies.py", line 302, in predict
    actions = self._predict(observation, deterministic=deterministic)
  File "/home/shandilya/py36/lib/python3.6/site-packages/stable_baselines3/td3/policies.py", line 226, in _predict
    return self.actor(observation)
  File "/home/shandilya/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/shandilya/py36/lib/python3.6/site-packages/stable_baselines3/td3/policies.py", line 77, in forward
    features = self.extract_features(obs)
  File "/home/shandilya/py36/lib/python3.6/site-packages/stable_baselines3/common/policies.py", line 128, in extract_features
    return self.features_extractor(preprocessed_obs)
  File "/home/shandilya/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/shandilya/Desktop/Projects/NavigationController/utils/td3_utils.py", line 98, in forward
    out = self.fc(x)
  File "/home/shandilya/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/shandilya/py36/lib/python3.6/site-packages/torch/nn/modules/container.py", line 139, in forward
    input = module(input)
  File "/home/shandilya/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/shandilya/py36/lib/python3.6/site-packages/torch/nn/modules/linear.py", line 96, in forward
    return F.linear(input, self.weight, self.bias)
  File "/home/shandilya/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1847, in linear
    return torch._C._nn.linear(input, weight, bias)
RuntimeError: mat1 and mat2 shapes cannot be multiplied (1x900 and 1200x300)
2021-12-17 12:52:33.380954: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/shandilya/.mujoco/mjpro150/bin
2021-12-17 12:52:33.380998: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
/home/shandilya/Desktop/Projects/NavigationController
Env Type: maze
Task: GoalRewardSimple
Model: <class 'stable_baselines3.td3.td3.TD3'>
Using cpu device
Logging to assets/out/models/exp17/TD3_9
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | 1.84     |
| time/              |          |
|    episodes        | 4        |
|    fps             | 76       |
|    time_elapsed    | 13       |
|    total timesteps | 995      |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 242      |
|    ep_rew_mean     | 8.84     |
| time/              |          |
|    episodes        | 8        |
|    fps             | 79       |
|    time_elapsed    | 24       |
|    total timesteps | 1932     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 245      |
|    ep_rew_mean     | -5.35    |
| time/              |          |
|    episodes        | 12       |
|    fps             | 56       |
|    time_elapsed    | 51       |
|    total timesteps | 2936     |
| train/             |          |
|    actor_loss      | -0.106   |
|    critic_loss     | 2.79     |
|    learning_rate   | 0.000997 |
|    n_updates       | 251      |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 245      |
|    ep_rew_mean     | -1.52    |
| time/              |          |
|    episodes        | 16       |
|    fps             | 31       |
|    time_elapsed    | 125      |
|    total timesteps | 3914     |
| train/             |          |
|    actor_loss      | -0.189   |
|    critic_loss     | 2.03     |
|    learning_rate   | 0.000996 |
|    n_updates       | 1229     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 246      |
|    ep_rew_mean     | 1.71     |
| time/              |          |
|    episodes        | 20       |
|    fps             | 23       |
|    time_elapsed    | 205      |
|    total timesteps | 4918     |
| train/             |          |
|    actor_loss      | -0.156   |
|    critic_loss     | 2.36     |
|    learning_rate   | 0.000995 |
|    n_updates       | 2233     |
---------------------------------
Eval num_timesteps=5000, episode_reward=54.92 +/- 12.81
Episode length: 180.40 +/- 7.50
---------------------------------
| eval/              |          |
|    mean_ep_length  | 180      |
|    mean_reward     | 54.9     |
| time/              |          |
|    total_timesteps | 5000     |
| train/             |          |
|    actor_loss      | -0.15    |
|    critic_loss     | 2.04     |
|    learning_rate   | 0.000995 |
|    n_updates       | 2484     |
---------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 246      |
|    ep_rew_mean     | 0.601    |
| time/              |          |
|    episodes        | 24       |
|    fps             | 19       |
|    time_elapsed    | 298      |
|    total timesteps | 5914     |
| train/             |          |
|    actor_loss      | -0.176   |
|    critic_loss     | 2.07     |
|    learning_rate   | 0.000994 |
|    n_updates       | 3229     |
---------------------------------
Terminated
2021-12-17 12:58:28.688505: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/shandilya/.mujoco/mjpro150/bin
2021-12-17 12:58:28.688548: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
/home/shandilya/Desktop/Projects/NavigationController
Env Type: maze
Task: GoalRewardSimple
Model: <class 'stable_baselines3.td3.td3.TD3'>
Using cpu device
Logging to assets/out/models/exp17/TD3_10
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -42.4    |
| time/              |          |
|    episodes        | 4        |
|    fps             | 73       |
|    time_elapsed    | 13       |
|    total timesteps | 1004     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 242      |
|    ep_rew_mean     | -31.8    |
| time/              |          |
|    episodes        | 8        |
|    fps             | 78       |
|    time_elapsed    | 24       |
|    total timesteps | 1937     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 245      |
|    ep_rew_mean     | -25.8    |
| time/              |          |
|    episodes        | 12       |
|    fps             | 55       |
|    time_elapsed    | 52       |
|    total timesteps | 2941     |
| train/             |          |
|    actor_loss      | 0.207    |
|    critic_loss     | 3.74     |
|    learning_rate   | 0.000997 |
|    n_updates       | 251      |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 246      |
|    ep_rew_mean     | -19.4    |
| time/              |          |
|    episodes        | 16       |
|    fps             | 30       |
|    time_elapsed    | 126      |
|    total timesteps | 3934     |
| train/             |          |
|    actor_loss      | 0.394    |
|    critic_loss     | 2.3      |
|    learning_rate   | 0.000996 |
|    n_updates       | 1244     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 247      |
|    ep_rew_mean     | -16.5    |
| time/              |          |
|    episodes        | 20       |
|    fps             | 23       |
|    time_elapsed    | 207      |
|    total timesteps | 4938     |
| train/             |          |
|    actor_loss      | 0.556    |
|    critic_loss     | 1.79     |
|    learning_rate   | 0.000995 |
|    n_updates       | 2248     |
---------------------------------
Eval num_timesteps=5000, episode_reward=-32.29 +/- 18.11
Episode length: 251.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 251      |
|    mean_reward     | -32.3    |
| time/              |          |
|    total_timesteps | 5000     |
| train/             |          |
|    actor_loss      | 0.584    |
|    critic_loss     | 1.87     |
|    learning_rate   | 0.000995 |
|    n_updates       | 2499     |
---------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 248      |
|    ep_rew_mean     | -17.2    |
| time/              |          |
|    episodes        | 24       |
|    fps             | 19       |
|    time_elapsed    | 305      |
|    total timesteps | 5942     |
| train/             |          |
|    actor_loss      | 0.699    |
|    critic_loss     | 2.17     |
|    learning_rate   | 0.000994 |
|    n_updates       | 3252     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 248      |
|    ep_rew_mean     | -18.2    |
| time/              |          |
|    episodes        | 28       |
|    fps             | 18       |
|    time_elapsed    | 385      |
|    total timesteps | 6946     |
| train/             |          |
|    actor_loss      | 0.823    |
|    critic_loss     | 2.31     |
|    learning_rate   | 0.000993 |
|    n_updates       | 4256     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 248      |
|    ep_rew_mean     | -19.5    |
| time/              |          |
|    episodes        | 32       |
|    fps             | 17       |
|    time_elapsed    | 464      |
|    total timesteps | 7950     |
| train/             |          |
|    actor_loss      | 1        |
|    critic_loss     | 2.12     |
|    learning_rate   | 0.000992 |
|    n_updates       | 5260     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -17.3    |
| time/              |          |
|    episodes        | 36       |
|    fps             | 16       |
|    time_elapsed    | 545      |
|    total timesteps | 8954     |
| train/             |          |
|    actor_loss      | 1.14     |
|    critic_loss     | 2.03     |
|    learning_rate   | 0.000991 |
|    n_updates       | 6264     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -20.4    |
| time/              |          |
|    episodes        | 40       |
|    fps             | 15       |
|    time_elapsed    | 624      |
|    total timesteps | 9958     |
| train/             |          |
|    actor_loss      | 1.24     |
|    critic_loss     | 1.64     |
|    learning_rate   | 0.00099  |
|    n_updates       | 7268     |
---------------------------------
Eval num_timesteps=10000, episode_reward=-30.62 +/- 18.57
Episode length: 251.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 251      |
|    mean_reward     | -30.6    |
| time/              |          |
|    total_timesteps | 10000    |
| train/             |          |
|    actor_loss      | 1.29     |
|    critic_loss     | 2.32     |
|    learning_rate   | 0.00099  |
|    n_updates       | 7519     |
---------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -21.8    |
| time/              |          |
|    episodes        | 44       |
|    fps             | 15       |
|    time_elapsed    | 726      |
|    total timesteps | 10962    |
| train/             |          |
|    actor_loss      | 1.36     |
|    critic_loss     | 1.92     |
|    learning_rate   | 0.000989 |
|    n_updates       | 8272     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -22.6    |
| time/              |          |
|    episodes        | 48       |
|    fps             | 14       |
|    time_elapsed    | 807      |
|    total timesteps | 11966    |
| train/             |          |
|    actor_loss      | 1.55     |
|    critic_loss     | 2.66     |
|    learning_rate   | 0.000988 |
|    n_updates       | 9276     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -22.9    |
| time/              |          |
|    episodes        | 52       |
|    fps             | 14       |
|    time_elapsed    | 886      |
|    total timesteps | 12970    |
| train/             |          |
|    actor_loss      | 1.7      |
|    critic_loss     | 2.26     |
|    learning_rate   | 0.000987 |
|    n_updates       | 10280    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -22.2    |
| time/              |          |
|    episodes        | 56       |
|    fps             | 14       |
|    time_elapsed    | 969      |
|    total timesteps | 13974    |
| train/             |          |
|    actor_loss      | 1.87     |
|    critic_loss     | 2.78     |
|    learning_rate   | 0.000986 |
|    n_updates       | 11284    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -23      |
| time/              |          |
|    episodes        | 60       |
|    fps             | 14       |
|    time_elapsed    | 1050     |
|    total timesteps | 14978    |
| train/             |          |
|    actor_loss      | 2.07     |
|    critic_loss     | 2.81     |
|    learning_rate   | 0.000985 |
|    n_updates       | 12288    |
---------------------------------
Eval num_timesteps=15000, episode_reward=-32.23 +/- 7.68
Episode length: 251.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 251      |
|    mean_reward     | -32.2    |
| time/              |          |
|    total_timesteps | 15000    |
| train/             |          |
|    actor_loss      | 2.09     |
|    critic_loss     | 2.68     |
|    learning_rate   | 0.000985 |
|    n_updates       | 12539    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -22.6    |
| time/              |          |
|    episodes        | 64       |
|    fps             | 13       |
|    time_elapsed    | 1150     |
|    total timesteps | 15982    |
| train/             |          |
|    actor_loss      | 2.19     |
|    critic_loss     | 2.67     |
|    learning_rate   | 0.000984 |
|    n_updates       | 13292    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -21.3    |
| time/              |          |
|    episodes        | 68       |
|    fps             | 13       |
|    time_elapsed    | 1229     |
|    total timesteps | 16962    |
| train/             |          |
|    actor_loss      | 2.31     |
|    critic_loss     | 2.68     |
|    learning_rate   | 0.000983 |
|    n_updates       | 14272    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -21      |
| time/              |          |
|    episodes        | 72       |
|    fps             | 13       |
|    time_elapsed    | 1309     |
|    total timesteps | 17966    |
| train/             |          |
|    actor_loss      | 2.43     |
|    critic_loss     | 2.62     |
|    learning_rate   | 0.000982 |
|    n_updates       | 15276    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -20.9    |
| time/              |          |
|    episodes        | 76       |
|    fps             | 13       |
|    time_elapsed    | 1390     |
|    total timesteps | 18970    |
| train/             |          |
|    actor_loss      | 2.55     |
|    critic_loss     | 2.33     |
|    learning_rate   | 0.000981 |
|    n_updates       | 16280    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -19.9    |
| time/              |          |
|    episodes        | 80       |
|    fps             | 13       |
|    time_elapsed    | 1469     |
|    total timesteps | 19974    |
| train/             |          |
|    actor_loss      | 2.66     |
|    critic_loss     | 2.21     |
|    learning_rate   | 0.00098  |
|    n_updates       | 17284    |
---------------------------------
Eval num_timesteps=20000, episode_reward=-36.23 +/- 14.11
Episode length: 251.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 251      |
|    mean_reward     | -36.2    |
| time/              |          |
|    total_timesteps | 20000    |
| train/             |          |
|    actor_loss      | 2.67     |
|    critic_loss     | 2.11     |
|    learning_rate   | 0.00098  |
|    n_updates       | 17535    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -19.8    |
| time/              |          |
|    episodes        | 84       |
|    fps             | 13       |
|    time_elapsed    | 1571     |
|    total timesteps | 20978    |
| train/             |          |
|    actor_loss      | 2.75     |
|    critic_loss     | 2.49     |
|    learning_rate   | 0.000979 |
|    n_updates       | 18288    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -20.3    |
| time/              |          |
|    episodes        | 88       |
|    fps             | 13       |
|    time_elapsed    | 1654     |
|    total timesteps | 21982    |
| train/             |          |
|    actor_loss      | 2.84     |
|    critic_loss     | 2.53     |
|    learning_rate   | 0.000978 |
|    n_updates       | 19292    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -19.2    |
| time/              |          |
|    episodes        | 92       |
|    fps             | 13       |
|    time_elapsed    | 1735     |
|    total timesteps | 22986    |
| train/             |          |
|    actor_loss      | 2.97     |
|    critic_loss     | 3.2      |
|    learning_rate   | 0.000977 |
|    n_updates       | 20296    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -18.6    |
| time/              |          |
|    episodes        | 96       |
|    fps             | 13       |
|    time_elapsed    | 1816     |
|    total timesteps | 23990    |
| train/             |          |
|    actor_loss      | 3.03     |
|    critic_loss     | 2.67     |
|    learning_rate   | 0.000976 |
|    n_updates       | 21300    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -17.9    |
| time/              |          |
|    episodes        | 100      |
|    fps             | 13       |
|    time_elapsed    | 1891     |
|    total timesteps | 24927    |
| train/             |          |
|    actor_loss      | 3.12     |
|    critic_loss     | 2.42     |
|    learning_rate   | 0.000976 |
|    n_updates       | 22237    |
---------------------------------
Eval num_timesteps=25000, episode_reward=-42.58 +/- 19.09
Episode length: 251.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 251      |
|    mean_reward     | -42.6    |
| time/              |          |
|    total_timesteps | 25000    |
| train/             |          |
|    actor_loss      | 3.15     |
|    critic_loss     | 2.8      |
|    learning_rate   | 0.000975 |
|    n_updates       | 22488    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -17      |
| time/              |          |
|    episodes        | 104      |
|    fps             | 13       |
|    time_elapsed    | 1990     |
|    total timesteps | 25931    |
| train/             |          |
|    actor_loss      | 3.21     |
|    critic_loss     | 2.13     |
|    learning_rate   | 0.000975 |
|    n_updates       | 23241    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -16.6    |
| time/              |          |
|    episodes        | 108      |
|    fps             | 13       |
|    time_elapsed    | 2070     |
|    total timesteps | 26935    |
| train/             |          |
|    actor_loss      | 3.27     |
|    critic_loss     | 2.52     |
|    learning_rate   | 0.000974 |
|    n_updates       | 24245    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -16      |
| time/              |          |
|    episodes        | 112      |
|    fps             | 12       |
|    time_elapsed    | 2150     |
|    total timesteps | 27939    |
| train/             |          |
|    actor_loss      | 3.33     |
|    critic_loss     | 2.18     |
|    learning_rate   | 0.000973 |
|    n_updates       | 25249    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -16.9    |
| time/              |          |
|    episodes        | 116      |
|    fps             | 12       |
|    time_elapsed    | 2231     |
|    total timesteps | 28943    |
| train/             |          |
|    actor_loss      | 3.4      |
|    critic_loss     | 2.53     |
|    learning_rate   | 0.000972 |
|    n_updates       | 26253    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -17.8    |
| time/              |          |
|    episodes        | 120      |
|    fps             | 12       |
|    time_elapsed    | 2313     |
|    total timesteps | 29947    |
| train/             |          |
|    actor_loss      | 3.45     |
|    critic_loss     | 2.44     |
|    learning_rate   | 0.000971 |
|    n_updates       | 27257    |
---------------------------------
Eval num_timesteps=30000, episode_reward=-39.10 +/- 12.67
Episode length: 251.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 251      |
|    mean_reward     | -39.1    |
| time/              |          |
|    total_timesteps | 30000    |
| train/             |          |
|    actor_loss      | 3.47     |
|    critic_loss     | 2.37     |
|    learning_rate   | 0.00097  |
|    n_updates       | 27508    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -18      |
| time/              |          |
|    episodes        | 124      |
|    fps             | 12       |
|    time_elapsed    | 2413     |
|    total timesteps | 30951    |
| train/             |          |
|    actor_loss      | 3.48     |
|    critic_loss     | 2.28     |
|    learning_rate   | 0.00097  |
|    n_updates       | 28261    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -18      |
| time/              |          |
|    episodes        | 128      |
|    fps             | 12       |
|    time_elapsed    | 2493     |
|    total timesteps | 31955    |
| train/             |          |
|    actor_loss      | 3.53     |
|    critic_loss     | 2        |
|    learning_rate   | 0.000969 |
|    n_updates       | 29265    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -16.7    |
| time/              |          |
|    episodes        | 132      |
|    fps             | 12       |
|    time_elapsed    | 2575     |
|    total timesteps | 32959    |
| train/             |          |
|    actor_loss      | 3.61     |
|    critic_loss     | 2.39     |
|    learning_rate   | 0.000968 |
|    n_updates       | 30269    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -16.7    |
| time/              |          |
|    episodes        | 136      |
|    fps             | 12       |
|    time_elapsed    | 2656     |
|    total timesteps | 33963    |
| train/             |          |
|    actor_loss      | 3.64     |
|    critic_loss     | 1.84     |
|    learning_rate   | 0.000967 |
|    n_updates       | 31273    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -14.8    |
| time/              |          |
|    episodes        | 140      |
|    fps             | 12       |
|    time_elapsed    | 2736     |
|    total timesteps | 34967    |
| train/             |          |
|    actor_loss      | 3.67     |
|    critic_loss     | 1.69     |
|    learning_rate   | 0.000966 |
|    n_updates       | 32277    |
---------------------------------
Eval num_timesteps=35000, episode_reward=-35.89 +/- 11.40
Episode length: 251.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 251      |
|    mean_reward     | -35.9    |
| time/              |          |
|    total_timesteps | 35000    |
| train/             |          |
|    actor_loss      | 3.7      |
|    critic_loss     | 2.08     |
|    learning_rate   | 0.000965 |
|    n_updates       | 32528    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -14.9    |
| time/              |          |
|    episodes        | 144      |
|    fps             | 12       |
|    time_elapsed    | 2835     |
|    total timesteps | 35971    |
| train/             |          |
|    actor_loss      | 3.7      |
|    critic_loss     | 1.69     |
|    learning_rate   | 0.000965 |
|    n_updates       | 33281    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -14      |
| time/              |          |
|    episodes        | 148      |
|    fps             | 12       |
|    time_elapsed    | 2916     |
|    total timesteps | 36975    |
| train/             |          |
|    actor_loss      | 3.76     |
|    critic_loss     | 2.39     |
|    learning_rate   | 0.000964 |
|    n_updates       | 34285    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -13.6    |
| time/              |          |
|    episodes        | 152      |
|    fps             | 12       |
|    time_elapsed    | 3001     |
|    total timesteps | 37979    |
| train/             |          |
|    actor_loss      | 3.81     |
|    critic_loss     | 2.3      |
|    learning_rate   | 0.000963 |
|    n_updates       | 35289    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -14      |
| time/              |          |
|    episodes        | 156      |
|    fps             | 12       |
|    time_elapsed    | 3084     |
|    total timesteps | 38983    |
| train/             |          |
|    actor_loss      | 3.88     |
|    critic_loss     | 2.43     |
|    learning_rate   | 0.000962 |
|    n_updates       | 36293    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -14.1    |
| time/              |          |
|    episodes        | 160      |
|    fps             | 12       |
|    time_elapsed    | 3167     |
|    total timesteps | 39987    |
| train/             |          |
|    actor_loss      | 3.91     |
|    critic_loss     | 2.42     |
|    learning_rate   | 0.000961 |
|    n_updates       | 37297    |
---------------------------------
Eval num_timesteps=40000, episode_reward=-31.85 +/- 15.23
Episode length: 251.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 251      |
|    mean_reward     | -31.8    |
| time/              |          |
|    total_timesteps | 40000    |
| train/             |          |
|    actor_loss      | 3.9      |
|    critic_loss     | 2.21     |
|    learning_rate   | 0.00096  |
|    n_updates       | 37548    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -14.5    |
| time/              |          |
|    episodes        | 164      |
|    fps             | 12       |
|    time_elapsed    | 3269     |
|    total timesteps | 40991    |
| train/             |          |
|    actor_loss      | 3.97     |
|    critic_loss     | 2.53     |
|    learning_rate   | 0.00096  |
|    n_updates       | 38301    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -15.5    |
| time/              |          |
|    episodes        | 168      |
|    fps             | 12       |
|    time_elapsed    | 3354     |
|    total timesteps | 41995    |
| train/             |          |
|    actor_loss      | 3.99     |
|    critic_loss     | 2.39     |
|    learning_rate   | 0.000959 |
|    n_updates       | 39305    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -15.4    |
| time/              |          |
|    episodes        | 172      |
|    fps             | 12       |
|    time_elapsed    | 3438     |
|    total timesteps | 42999    |
| train/             |          |
|    actor_loss      | 3.96     |
|    critic_loss     | 1.94     |
|    learning_rate   | 0.000958 |
|    n_updates       | 40309    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -15.6    |
| time/              |          |
|    episodes        | 176      |
|    fps             | 12       |
|    time_elapsed    | 3524     |
|    total timesteps | 44003    |
| train/             |          |
|    actor_loss      | 4.04     |
|    critic_loss     | 2.3      |
|    learning_rate   | 0.000957 |
|    n_updates       | 41313    |
---------------------------------
Eval num_timesteps=45000, episode_reward=-32.50 +/- 15.60
Episode length: 251.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 251      |
|    mean_reward     | -32.5    |
| time/              |          |
|    total_timesteps | 45000    |
| train/             |          |
|    actor_loss      | 4.09     |
|    critic_loss     | 2.23     |
|    learning_rate   | 0.000956 |
|    n_updates       | 42317    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -16.5    |
| time/              |          |
|    episodes        | 180      |
|    fps             | 12       |
|    time_elapsed    | 3628     |
|    total timesteps | 45007    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -15.9    |
| time/              |          |
|    episodes        | 184      |
|    fps             | 12       |
|    time_elapsed    | 3715     |
|    total timesteps | 46011    |
| train/             |          |
|    actor_loss      | 4.12     |
|    critic_loss     | 2.46     |
|    learning_rate   | 0.000955 |
|    n_updates       | 43321    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -15.5    |
| time/              |          |
|    episodes        | 188      |
|    fps             | 12       |
|    time_elapsed    | 3802     |
|    total timesteps | 47015    |
| train/             |          |
|    actor_loss      | 4.18     |
|    critic_loss     | 2.28     |
|    learning_rate   | 0.000954 |
|    n_updates       | 44325    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -16.2    |
| time/              |          |
|    episodes        | 192      |
|    fps             | 12       |
|    time_elapsed    | 3889     |
|    total timesteps | 48019    |
| train/             |          |
|    actor_loss      | 4.22     |
|    critic_loss     | 2.16     |
|    learning_rate   | 0.000953 |
|    n_updates       | 45329    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -16.4    |
| time/              |          |
|    episodes        | 196      |
|    fps             | 12       |
|    time_elapsed    | 3981     |
|    total timesteps | 49023    |
| train/             |          |
|    actor_loss      | 4.25     |
|    critic_loss     | 2.08     |
|    learning_rate   | 0.000952 |
|    n_updates       | 46333    |
---------------------------------
Eval num_timesteps=50000, episode_reward=-40.35 +/- 13.72
Episode length: 251.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 251      |
|    mean_reward     | -40.4    |
| time/              |          |
|    total_timesteps | 50000    |
| train/             |          |
|    actor_loss      | 4.23     |
|    critic_loss     | 2.01     |
|    learning_rate   | 0.000951 |
|    n_updates       | 47337    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -17      |
| time/              |          |
|    episodes        | 200      |
|    fps             | 12       |
|    time_elapsed    | 4087     |
|    total timesteps | 50027    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -17.3    |
| time/              |          |
|    episodes        | 204      |
|    fps             | 12       |
|    time_elapsed    | 4177     |
|    total timesteps | 51031    |
| train/             |          |
|    actor_loss      | 4.24     |
|    critic_loss     | 2.33     |
|    learning_rate   | 0.00095  |
|    n_updates       | 48341    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -17.5    |
| time/              |          |
|    episodes        | 208      |
|    fps             | 12       |
|    time_elapsed    | 4265     |
|    total timesteps | 52035    |
| train/             |          |
|    actor_loss      | 4.27     |
|    critic_loss     | 2.14     |
|    learning_rate   | 0.000949 |
|    n_updates       | 49345    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -18.1    |
| time/              |          |
|    episodes        | 212      |
|    fps             | 12       |
|    time_elapsed    | 4355     |
|    total timesteps | 53039    |
| train/             |          |
|    actor_loss      | 4.31     |
|    critic_loss     | 2.12     |
|    learning_rate   | 0.000948 |
|    n_updates       | 50349    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -18.1    |
| time/              |          |
|    episodes        | 216      |
|    fps             | 12       |
|    time_elapsed    | 4444     |
|    total timesteps | 54043    |
| train/             |          |
|    actor_loss      | 4.36     |
|    critic_loss     | 2.49     |
|    learning_rate   | 0.000947 |
|    n_updates       | 51353    |
---------------------------------
Eval num_timesteps=55000, episode_reward=-24.70 +/- 4.63
Episode length: 251.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 251      |
|    mean_reward     | -24.7    |
| time/              |          |
|    total_timesteps | 55000    |
| train/             |          |
|    actor_loss      | 4.36     |
|    critic_loss     | 2.11     |
|    learning_rate   | 0.000946 |
|    n_updates       | 52357    |
---------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -17.9    |
| time/              |          |
|    episodes        | 220      |
|    fps             | 12       |
|    time_elapsed    | 4551     |
|    total timesteps | 55047    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -17.8    |
| time/              |          |
|    episodes        | 224      |
|    fps             | 12       |
|    time_elapsed    | 4641     |
|    total timesteps | 56051    |
| train/             |          |
|    actor_loss      | 4.35     |
|    critic_loss     | 1.99     |
|    learning_rate   | 0.000945 |
|    n_updates       | 53361    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -17.7    |
| time/              |          |
|    episodes        | 228      |
|    fps             | 12       |
|    time_elapsed    | 4732     |
|    total timesteps | 57055    |
| train/             |          |
|    actor_loss      | 4.35     |
|    critic_loss     | 1.68     |
|    learning_rate   | 0.000944 |
|    n_updates       | 54365    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -18.5    |
| time/              |          |
|    episodes        | 232      |
|    fps             | 12       |
|    time_elapsed    | 4822     |
|    total timesteps | 58059    |
| train/             |          |
|    actor_loss      | 4.4      |
|    critic_loss     | 2.53     |
|    learning_rate   | 0.000943 |
|    n_updates       | 55369    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -19      |
| time/              |          |
|    episodes        | 236      |
|    fps             | 12       |
|    time_elapsed    | 4914     |
|    total timesteps | 59063    |
| train/             |          |
|    actor_loss      | 4.46     |
|    critic_loss     | 2.77     |
|    learning_rate   | 0.000942 |
|    n_updates       | 56373    |
---------------------------------
Eval num_timesteps=60000, episode_reward=-45.81 +/- 23.92
Episode length: 251.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 251      |
|    mean_reward     | -45.8    |
| time/              |          |
|    total_timesteps | 60000    |
| train/             |          |
|    actor_loss      | 4.44     |
|    critic_loss     | 1.88     |
|    learning_rate   | 0.000941 |
|    n_updates       | 57377    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -19.6    |
| time/              |          |
|    episodes        | 240      |
|    fps             | 11       |
|    time_elapsed    | 5025     |
|    total timesteps | 60067    |
---------------------------------
Terminated
2021-12-17 14:22:46.480619: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/shandilya/.mujoco/mjpro150/bin
2021-12-17 14:22:46.480655: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
/home/shandilya/Desktop/Projects/NavigationController
Env Type: maze
Task: GoalRewardSimple
Model: <class 'stable_baselines3.td3.td3.TD3'>
Using cpu device
Logging to assets/out/models/exp17/TD3_11
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -11.8    |
| time/              |          |
|    episodes        | 4        |
|    fps             | 68       |
|    time_elapsed    | 14       |
|    total timesteps | 1004     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -21      |
| time/              |          |
|    episodes        | 8        |
|    fps             | 72       |
|    time_elapsed    | 27       |
|    total timesteps | 2008     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -22.8    |
| time/              |          |
|    episodes        | 12       |
|    fps             | 32       |
|    time_elapsed    | 93       |
|    total timesteps | 3012     |
| train/             |          |
|    actor_loss      | 0.129    |
|    critic_loss     | 2.39     |
|    learning_rate   | 0.000997 |
|    n_updates       | 502      |
---------------------------------
2021-12-17 15:54:35.201904: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib/nvidia-470:/usr/local/cuda/lib64:/root/.mujoco/mjpro150/bin:/usr/local/nvidia/lib:/usr/local/nvidia/lib64
2021-12-17 15:54:35.201957: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
/root/trainer
Env Type: maze
Task: GoalRewardSimple
Model: <class 'stable_baselines3.td3.td3.TD3'>
Using cuda device
Logging to assets/out/models/exp17/TD3_16
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -45      |
| time/              |          |
|    episodes        | 4        |
|    fps             | 92       |
|    time_elapsed    | 10       |
|    total timesteps | 1004     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -33.9    |
| time/              |          |
|    episodes        | 8        |
|    fps             | 102      |
|    time_elapsed    | 19       |
|    total timesteps | 2008     |
---------------------------------
Found 1 GPUs for rendering. Using device 0.
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -32.5    |
| time/              |          |
|    episodes        | 12       |
|    fps             | 63       |
|    time_elapsed    | 47       |
|    total timesteps | 3012     |
| train/             |          |
|    actor_loss      | 0.283    |
|    critic_loss     | 3.94     |
|    learning_rate   | 0.000997 |
|    n_updates       | 502      |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 244      |
|    ep_rew_mean     | -22.3    |
| time/              |          |
|    episodes        | 16       |
|    fps             | 42       |
|    time_elapsed    | 90       |
|    total timesteps | 3898     |
| train/             |          |
|    actor_loss      | 0.386    |
|    critic_loss     | 3.04     |
|    learning_rate   | 0.000996 |
|    n_updates       | 1471     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 245      |
|    ep_rew_mean     | -23.4    |
| time/              |          |
|    episodes        | 20       |
|    fps             | 36       |
|    time_elapsed    | 134      |
|    total timesteps | 4902     |
| train/             |          |
|    actor_loss      | 0.549    |
|    critic_loss     | 3.33     |
|    learning_rate   | 0.000995 |
|    n_updates       | 2392     |
---------------------------------
Eval num_timesteps=5000, episode_reward=65.14 +/- 6.81
Episode length: 235.40 +/- 19.20
---------------------------------
| eval/              |          |
|    mean_ep_length  | 235      |
|    mean_reward     | 65.1     |
| time/              |          |
|    total_timesteps | 5000     |
| train/             |          |
|    actor_loss      | 0.588    |
|    critic_loss     | 3.02     |
|    learning_rate   | 0.000995 |
|    n_updates       | 2643     |
---------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 243      |
|    ep_rew_mean     | -19.7    |
| time/              |          |
|    episodes        | 24       |
|    fps             | 30       |
|    time_elapsed    | 189      |
|    total timesteps | 5829     |
| train/             |          |
|    actor_loss      | 0.664    |
|    critic_loss     | 3.08     |
|    learning_rate   | 0.000994 |
|    n_updates       | 3319     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 244      |
|    ep_rew_mean     | -19.4    |
| time/              |          |
|    episodes        | 28       |
|    fps             | 28       |
|    time_elapsed    | 236      |
|    total timesteps | 6833     |
| train/             |          |
|    actor_loss      | 0.819    |
|    critic_loss     | 2.84     |
|    learning_rate   | 0.000993 |
|    n_updates       | 4323     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 245      |
|    ep_rew_mean     | -20.5    |
| time/              |          |
|    episodes        | 32       |
|    fps             | 27       |
|    time_elapsed    | 282      |
|    total timesteps | 7837     |
| train/             |          |
|    actor_loss      | 0.97     |
|    critic_loss     | 2.92     |
|    learning_rate   | 0.000992 |
|    n_updates       | 5327     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 246      |
|    ep_rew_mean     | -18.7    |
| time/              |          |
|    episodes        | 36       |
|    fps             | 26       |
|    time_elapsed    | 329      |
|    total timesteps | 8841     |
| train/             |          |
|    actor_loss      | 1.12     |
|    critic_loss     | 2.77     |
|    learning_rate   | 0.000991 |
|    n_updates       | 6331     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 246      |
|    ep_rew_mean     | -19.1    |
| time/              |          |
|    episodes        | 40       |
|    fps             | 26       |
|    time_elapsed    | 375      |
|    total timesteps | 9845     |
| train/             |          |
|    actor_loss      | 1.24     |
|    critic_loss     | 2.49     |
|    learning_rate   | 0.000991 |
|    n_updates       | 7335     |
---------------------------------
Eval num_timesteps=10000, episode_reward=69.53 +/- 7.76
Episode length: 242.40 +/- 17.20
---------------------------------
| eval/              |          |
|    mean_ep_length  | 242      |
|    mean_reward     | 69.5     |
| time/              |          |
|    total_timesteps | 10000    |
| train/             |          |
|    actor_loss      | 1.28     |
|    critic_loss     | 2.57     |
|    learning_rate   | 0.00099  |
|    n_updates       | 7586     |
---------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 247      |
|    ep_rew_mean     | -19.1    |
| time/              |          |
|    episodes        | 44       |
|    fps             | 24       |
|    time_elapsed    | 435      |
|    total timesteps | 10849    |
| train/             |          |
|    actor_loss      | 1.35     |
|    critic_loss     | 2.86     |
|    learning_rate   | 0.00099  |
|    n_updates       | 8339     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 247      |
|    ep_rew_mean     | -17.5    |
| time/              |          |
|    episodes        | 48       |
|    fps             | 24       |
|    time_elapsed    | 481      |
|    total timesteps | 11853    |
| train/             |          |
|    actor_loss      | 1.45     |
|    critic_loss     | 2.64     |
|    learning_rate   | 0.000989 |
|    n_updates       | 9343     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 247      |
|    ep_rew_mean     | -17.2    |
| time/              |          |
|    episodes        | 52       |
|    fps             | 24       |
|    time_elapsed    | 528      |
|    total timesteps | 12857    |
| train/             |          |
|    actor_loss      | 1.58     |
|    critic_loss     | 3.07     |
|    learning_rate   | 0.000988 |
|    n_updates       | 10347    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 248      |
|    ep_rew_mean     | -16      |
| time/              |          |
|    episodes        | 56       |
|    fps             | 24       |
|    time_elapsed    | 574      |
|    total timesteps | 13861    |
| train/             |          |
|    actor_loss      | 1.64     |
|    critic_loss     | 2.35     |
|    learning_rate   | 0.000987 |
|    n_updates       | 11351    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 248      |
|    ep_rew_mean     | -15.9    |
| time/              |          |
|    episodes        | 60       |
|    fps             | 23       |
|    time_elapsed    | 621      |
|    total timesteps | 14865    |
| train/             |          |
|    actor_loss      | 1.76     |
|    critic_loss     | 2.74     |
|    learning_rate   | 0.000986 |
|    n_updates       | 12355    |
---------------------------------
Eval num_timesteps=15000, episode_reward=70.81 +/- 15.52
Episode length: 238.00 +/- 20.53
---------------------------------
| eval/              |          |
|    mean_ep_length  | 238      |
|    mean_reward     | 70.8     |
| time/              |          |
|    total_timesteps | 15000    |
| train/             |          |
|    actor_loss      | 1.75     |
|    critic_loss     | 2.54     |
|    learning_rate   | 0.000985 |
|    n_updates       | 12606    |
---------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 248      |
|    ep_rew_mean     | -15      |
| time/              |          |
|    episodes        | 64       |
|    fps             | 23       |
|    time_elapsed    | 681      |
|    total timesteps | 15869    |
| train/             |          |
|    actor_loss      | 1.81     |
|    critic_loss     | 2.58     |
|    learning_rate   | 0.000985 |
|    n_updates       | 13359    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 248      |
|    ep_rew_mean     | -14.6    |
| time/              |          |
|    episodes        | 68       |
|    fps             | 23       |
|    time_elapsed    | 727      |
|    total timesteps | 16873    |
| train/             |          |
|    actor_loss      | 1.87     |
|    critic_loss     | 2.25     |
|    learning_rate   | 0.000984 |
|    n_updates       | 14363    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 248      |
|    ep_rew_mean     | -12.9    |
| time/              |          |
|    episodes        | 72       |
|    fps             | 23       |
|    time_elapsed    | 773      |
|    total timesteps | 17877    |
| train/             |          |
|    actor_loss      | 1.96     |
|    critic_loss     | 2.6      |
|    learning_rate   | 0.000983 |
|    n_updates       | 15367    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 248      |
|    ep_rew_mean     | -13.3    |
| time/              |          |
|    episodes        | 76       |
|    fps             | 23       |
|    time_elapsed    | 820      |
|    total timesteps | 18881    |
| train/             |          |
|    actor_loss      | 2.01     |
|    critic_loss     | 2.21     |
|    learning_rate   | 0.000982 |
|    n_updates       | 16371    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 248      |
|    ep_rew_mean     | -12.3    |
| time/              |          |
|    episodes        | 80       |
|    fps             | 22       |
|    time_elapsed    | 863      |
|    total timesteps | 19833    |
| train/             |          |
|    actor_loss      | 2.05     |
|    critic_loss     | 2.37     |
|    learning_rate   | 0.000981 |
|    n_updates       | 17323    |
---------------------------------
Eval num_timesteps=20000, episode_reward=58.11 +/- 5.00
Episode length: 230.60 +/- 25.27
---------------------------------
| eval/              |          |
|    mean_ep_length  | 231      |
|    mean_reward     | 58.1     |
| time/              |          |
|    total_timesteps | 20000    |
| train/             |          |
|    actor_loss      | 2.05     |
|    critic_loss     | 2.24     |
|    learning_rate   | 0.00098  |
|    n_updates       | 17574    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 248      |
|    ep_rew_mean     | -12.4    |
| time/              |          |
|    episodes        | 84       |
|    fps             | 22       |
|    time_elapsed    | 921      |
|    total timesteps | 20837    |
| train/             |          |
|    actor_loss      | 2.06     |
|    critic_loss     | 1.84     |
|    learning_rate   | 0.00098  |
|    n_updates       | 18327    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 248      |
|    ep_rew_mean     | -13.5    |
| time/              |          |
|    episodes        | 88       |
|    fps             | 22       |
|    time_elapsed    | 967      |
|    total timesteps | 21841    |
| train/             |          |
|    actor_loss      | 2.12     |
|    critic_loss     | 2.05     |
|    learning_rate   | 0.000979 |
|    n_updates       | 19331    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 248      |
|    ep_rew_mean     | -13.9    |
| time/              |          |
|    episodes        | 92       |
|    fps             | 22       |
|    time_elapsed    | 1013     |
|    total timesteps | 22845    |
| train/             |          |
|    actor_loss      | 2.16     |
|    critic_loss     | 2.1      |
|    learning_rate   | 0.000978 |
|    n_updates       | 20335    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 248      |
|    ep_rew_mean     | -14.2    |
| time/              |          |
|    episodes        | 96       |
|    fps             | 22       |
|    time_elapsed    | 1058     |
|    total timesteps | 23849    |
| train/             |          |
|    actor_loss      | 2.22     |
|    critic_loss     | 2.9      |
|    learning_rate   | 0.000977 |
|    n_updates       | 21339    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -14.8    |
| time/              |          |
|    episodes        | 100      |
|    fps             | 22       |
|    time_elapsed    | 1104     |
|    total timesteps | 24853    |
| train/             |          |
|    actor_loss      | 2.29     |
|    critic_loss     | 2.51     |
|    learning_rate   | 0.000976 |
|    n_updates       | 22343    |
---------------------------------
Eval num_timesteps=25000, episode_reward=57.79 +/- 15.93
Episode length: 242.40 +/- 17.20
---------------------------------
| eval/              |          |
|    mean_ep_length  | 242      |
|    mean_reward     | 57.8     |
| time/              |          |
|    total_timesteps | 25000    |
| train/             |          |
|    actor_loss      | 2.31     |
|    critic_loss     | 2.54     |
|    learning_rate   | 0.000975 |
|    n_updates       | 22594    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -13.7    |
| time/              |          |
|    episodes        | 104      |
|    fps             | 22       |
|    time_elapsed    | 1162     |
|    total timesteps | 25857    |
| train/             |          |
|    actor_loss      | 2.36     |
|    critic_loss     | 2.7      |
|    learning_rate   | 0.000975 |
|    n_updates       | 23347    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 248      |
|    ep_rew_mean     | -11.6    |
| time/              |          |
|    episodes        | 108      |
|    fps             | 22       |
|    time_elapsed    | 1205     |
|    total timesteps | 26816    |
| train/             |          |
|    actor_loss      | 2.42     |
|    critic_loss     | 3.01     |
|    learning_rate   | 0.000974 |
|    n_updates       | 24306    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 248      |
|    ep_rew_mean     | -10.8    |
| time/              |          |
|    episodes        | 112      |
|    fps             | 22       |
|    time_elapsed    | 1251     |
|    total timesteps | 27820    |
| train/             |          |
|    actor_loss      | 2.44     |
|    critic_loss     | 2.62     |
|    learning_rate   | 0.000973 |
|    n_updates       | 25310    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -12.1    |
| time/              |          |
|    episodes        | 116      |
|    fps             | 22       |
|    time_elapsed    | 1297     |
|    total timesteps | 28824    |
| train/             |          |
|    actor_loss      | 2.47     |
|    critic_loss     | 2.44     |
|    learning_rate   | 0.000972 |
|    n_updates       | 26314    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -12      |
| time/              |          |
|    episodes        | 120      |
|    fps             | 22       |
|    time_elapsed    | 1343     |
|    total timesteps | 29828    |
| train/             |          |
|    actor_loss      | 2.52     |
|    critic_loss     | 2.46     |
|    learning_rate   | 0.000971 |
|    n_updates       | 27318    |
---------------------------------
Eval num_timesteps=30000, episode_reward=56.71 +/- 8.97
Episode length: 230.00 +/- 25.72
---------------------------------
| eval/              |          |
|    mean_ep_length  | 230      |
|    mean_reward     | 56.7     |
| time/              |          |
|    total_timesteps | 30000    |
| train/             |          |
|    actor_loss      | 2.51     |
|    critic_loss     | 1.96     |
|    learning_rate   | 0.00097  |
|    n_updates       | 27569    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -11.7    |
| time/              |          |
|    episodes        | 124      |
|    fps             | 21       |
|    time_elapsed    | 1402     |
|    total timesteps | 30832    |
| train/             |          |
|    actor_loss      | 2.58     |
|    critic_loss     | 2.65     |
|    learning_rate   | 0.00097  |
|    n_updates       | 28322    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -10.8    |
| time/              |          |
|    episodes        | 128      |
|    fps             | 21       |
|    time_elapsed    | 1448     |
|    total timesteps | 31836    |
| train/             |          |
|    actor_loss      | 2.62     |
|    critic_loss     | 2.4      |
|    learning_rate   | 0.000969 |
|    n_updates       | 29326    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -9.06    |
| time/              |          |
|    episodes        | 132      |
|    fps             | 21       |
|    time_elapsed    | 1493     |
|    total timesteps | 32840    |
| train/             |          |
|    actor_loss      | 2.67     |
|    critic_loss     | 2.33     |
|    learning_rate   | 0.000968 |
|    n_updates       | 30330    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -10      |
| time/              |          |
|    episodes        | 136      |
|    fps             | 21       |
|    time_elapsed    | 1539     |
|    total timesteps | 33844    |
| train/             |          |
|    actor_loss      | 2.66     |
|    critic_loss     | 2.39     |
|    learning_rate   | 0.000967 |
|    n_updates       | 31334    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -10.1    |
| time/              |          |
|    episodes        | 140      |
|    fps             | 21       |
|    time_elapsed    | 1585     |
|    total timesteps | 34848    |
| train/             |          |
|    actor_loss      | 2.7      |
|    critic_loss     | 2.35     |
|    learning_rate   | 0.000966 |
|    n_updates       | 32338    |
---------------------------------
Eval num_timesteps=35000, episode_reward=66.42 +/- 18.50
Episode length: 248.00 +/- 6.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 248      |
|    mean_reward     | 66.4     |
| time/              |          |
|    total_timesteps | 35000    |
| train/             |          |
|    actor_loss      | 2.69     |
|    critic_loss     | 2.2      |
|    learning_rate   | 0.000966 |
|    n_updates       | 32589    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -9.38    |
| time/              |          |
|    episodes        | 144      |
|    fps             | 21       |
|    time_elapsed    | 1643     |
|    total timesteps | 35852    |
| train/             |          |
|    actor_loss      | 2.72     |
|    critic_loss     | 2.43     |
|    learning_rate   | 0.000965 |
|    n_updates       | 33342    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -10.3    |
| time/              |          |
|    episodes        | 148      |
|    fps             | 21       |
|    time_elapsed    | 1689     |
|    total timesteps | 36856    |
| train/             |          |
|    actor_loss      | 2.75     |
|    critic_loss     | 2.09     |
|    learning_rate   | 0.000964 |
|    n_updates       | 34346    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -11.2    |
| time/              |          |
|    episodes        | 152      |
|    fps             | 21       |
|    time_elapsed    | 1736     |
|    total timesteps | 37860    |
| train/             |          |
|    actor_loss      | 2.79     |
|    critic_loss     | 2.2      |
|    learning_rate   | 0.000963 |
|    n_updates       | 35350    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -11.5    |
| time/              |          |
|    episodes        | 156      |
|    fps             | 21       |
|    time_elapsed    | 1782     |
|    total timesteps | 38864    |
| train/             |          |
|    actor_loss      | 2.82     |
|    critic_loss     | 2.22     |
|    learning_rate   | 0.000962 |
|    n_updates       | 36354    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -10.5    |
| time/              |          |
|    episodes        | 160      |
|    fps             | 21       |
|    time_elapsed    | 1829     |
|    total timesteps | 39835    |
| train/             |          |
|    actor_loss      | 2.8      |
|    critic_loss     | 1.84     |
|    learning_rate   | 0.000961 |
|    n_updates       | 37358    |
---------------------------------
Eval num_timesteps=40000, episode_reward=63.14 +/- 12.25
Episode length: 240.80 +/- 20.40
---------------------------------
| eval/              |          |
|    mean_ep_length  | 241      |
|    mean_reward     | 63.1     |
| time/              |          |
|    total_timesteps | 40000    |
| train/             |          |
|    actor_loss      | 2.82     |
|    critic_loss     | 2.29     |
|    learning_rate   | 0.000961 |
|    n_updates       | 37576    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -11.1    |
| time/              |          |
|    episodes        | 164      |
|    fps             | 21       |
|    time_elapsed    | 1887     |
|    total timesteps | 40839    |
| train/             |          |
|    actor_loss      | 2.88     |
|    critic_loss     | 2.57     |
|    learning_rate   | 0.00096  |
|    n_updates       | 38329    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -11      |
| time/              |          |
|    episodes        | 168      |
|    fps             | 21       |
|    time_elapsed    | 1933     |
|    total timesteps | 41843    |
| train/             |          |
|    actor_loss      | 2.9      |
|    critic_loss     | 2.2      |
|    learning_rate   | 0.000959 |
|    n_updates       | 39333    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -12.6    |
| time/              |          |
|    episodes        | 172      |
|    fps             | 21       |
|    time_elapsed    | 1978     |
|    total timesteps | 42847    |
| train/             |          |
|    actor_loss      | 2.96     |
|    critic_loss     | 2.42     |
|    learning_rate   | 0.000958 |
|    n_updates       | 40337    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -12.2    |
| time/              |          |
|    episodes        | 176      |
|    fps             | 21       |
|    time_elapsed    | 2024     |
|    total timesteps | 43851    |
| train/             |          |
|    actor_loss      | 2.96     |
|    critic_loss     | 2.22     |
|    learning_rate   | 0.000957 |
|    n_updates       | 41341    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -12.6    |
| time/              |          |
|    episodes        | 180      |
|    fps             | 21       |
|    time_elapsed    | 2070     |
|    total timesteps | 44855    |
| train/             |          |
|    actor_loss      | 2.97     |
|    critic_loss     | 2.07     |
|    learning_rate   | 0.000956 |
|    n_updates       | 42345    |
---------------------------------
Eval num_timesteps=45000, episode_reward=54.74 +/- 2.60
Episode length: 221.40 +/- 24.87
---------------------------------
| eval/              |          |
|    mean_ep_length  | 221      |
|    mean_reward     | 54.7     |
| time/              |          |
|    total_timesteps | 45000    |
| train/             |          |
|    actor_loss      | 2.98     |
|    critic_loss     | 2.26     |
|    learning_rate   | 0.000956 |
|    n_updates       | 42596    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -11.8    |
| time/              |          |
|    episodes        | 184      |
|    fps             | 21       |
|    time_elapsed    | 2127     |
|    total timesteps | 45859    |
| train/             |          |
|    actor_loss      | 3.02     |
|    critic_loss     | 2.74     |
|    learning_rate   | 0.000955 |
|    n_updates       | 43349    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -10.8    |
| time/              |          |
|    episodes        | 188      |
|    fps             | 21       |
|    time_elapsed    | 2172     |
|    total timesteps | 46863    |
| train/             |          |
|    actor_loss      | 3.09     |
|    critic_loss     | 2.84     |
|    learning_rate   | 0.000954 |
|    n_updates       | 44353    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -10      |
| time/              |          |
|    episodes        | 192      |
|    fps             | 21       |
|    time_elapsed    | 2218     |
|    total timesteps | 47867    |
| train/             |          |
|    actor_loss      | 3.11     |
|    critic_loss     | 2.58     |
|    learning_rate   | 0.000953 |
|    n_updates       | 45357    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -10.6    |
| time/              |          |
|    episodes        | 196      |
|    fps             | 21       |
|    time_elapsed    | 2264     |
|    total timesteps | 48871    |
| train/             |          |
|    actor_loss      | 3.12     |
|    critic_loss     | 2.3      |
|    learning_rate   | 0.000952 |
|    n_updates       | 46361    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -8.92    |
| time/              |          |
|    episodes        | 200      |
|    fps             | 21       |
|    time_elapsed    | 2307     |
|    total timesteps | 49822    |
| train/             |          |
|    actor_loss      | 3.11     |
|    critic_loss     | 2.17     |
|    learning_rate   | 0.000951 |
|    n_updates       | 47312    |
---------------------------------
Eval num_timesteps=50000, episode_reward=60.67 +/- 6.32
Episode length: 233.00 +/- 22.08
---------------------------------
| eval/              |          |
|    mean_ep_length  | 233      |
|    mean_reward     | 60.7     |
| time/              |          |
|    total_timesteps | 50000    |
| train/             |          |
|    actor_loss      | 3.12     |
|    critic_loss     | 2.17     |
|    learning_rate   | 0.000951 |
|    n_updates       | 47563    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -8.54    |
| time/              |          |
|    episodes        | 204      |
|    fps             | 21       |
|    time_elapsed    | 2365     |
|    total timesteps | 50826    |
| train/             |          |
|    actor_loss      | 3.09     |
|    critic_loss     | 2.33     |
|    learning_rate   | 0.00095  |
|    n_updates       | 48316    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -10      |
| time/              |          |
|    episodes        | 208      |
|    fps             | 21       |
|    time_elapsed    | 2411     |
|    total timesteps | 51830    |
| train/             |          |
|    actor_loss      | 3.12     |
|    critic_loss     | 2.58     |
|    learning_rate   | 0.000949 |
|    n_updates       | 49320    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -9.73    |
| time/              |          |
|    episodes        | 212      |
|    fps             | 21       |
|    time_elapsed    | 2457     |
|    total timesteps | 52834    |
| train/             |          |
|    actor_loss      | 3.06     |
|    critic_loss     | 1.85     |
|    learning_rate   | 0.000948 |
|    n_updates       | 50324    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -9.59    |
| time/              |          |
|    episodes        | 216      |
|    fps             | 21       |
|    time_elapsed    | 2503     |
|    total timesteps | 53838    |
| train/             |          |
|    actor_loss      | 3.05     |
|    critic_loss     | 1.95     |
|    learning_rate   | 0.000947 |
|    n_updates       | 51328    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -9.27    |
| time/              |          |
|    episodes        | 220      |
|    fps             | 21       |
|    time_elapsed    | 2549     |
|    total timesteps | 54842    |
| train/             |          |
|    actor_loss      | 3.07     |
|    critic_loss     | 2.33     |
|    learning_rate   | 0.000946 |
|    n_updates       | 52332    |
---------------------------------
Eval num_timesteps=55000, episode_reward=69.46 +/- 16.13
Episode length: 240.60 +/- 19.33
---------------------------------
| eval/              |          |
|    mean_ep_length  | 241      |
|    mean_reward     | 69.5     |
| time/              |          |
|    total_timesteps | 55000    |
| train/             |          |
|    actor_loss      | 3.06     |
|    critic_loss     | 2.04     |
|    learning_rate   | 0.000946 |
|    n_updates       | 52583    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -7.97    |
| time/              |          |
|    episodes        | 224      |
|    fps             | 21       |
|    time_elapsed    | 2606     |
|    total timesteps | 55846    |
| train/             |          |
|    actor_loss      | 3.06     |
|    critic_loss     | 2.21     |
|    learning_rate   | 0.000945 |
|    n_updates       | 53336    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -8.6     |
| time/              |          |
|    episodes        | 228      |
|    fps             | 21       |
|    time_elapsed    | 2651     |
|    total timesteps | 56850    |
| train/             |          |
|    actor_loss      | 3.07     |
|    critic_loss     | 2.19     |
|    learning_rate   | 0.000944 |
|    n_updates       | 54340    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -9.3     |
| time/              |          |
|    episodes        | 232      |
|    fps             | 21       |
|    time_elapsed    | 2696     |
|    total timesteps | 57854    |
| train/             |          |
|    actor_loss      | 3.07     |
|    critic_loss     | 2.03     |
|    learning_rate   | 0.000943 |
|    n_updates       | 55344    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -8.31    |
| time/              |          |
|    episodes        | 236      |
|    fps             | 21       |
|    time_elapsed    | 2741     |
|    total timesteps | 58785    |
| train/             |          |
|    actor_loss      | 3.06     |
|    critic_loss     | 2.01     |
|    learning_rate   | 0.000942 |
|    n_updates       | 56348    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -7.05    |
| time/              |          |
|    episodes        | 240      |
|    fps             | 21       |
|    time_elapsed    | 2783     |
|    total timesteps | 59789    |
| train/             |          |
|    actor_loss      | 3.1      |
|    critic_loss     | 2.59     |
|    learning_rate   | 0.000941 |
|    n_updates       | 57279    |
---------------------------------
Eval num_timesteps=60000, episode_reward=62.65 +/- 14.60
Episode length: 240.40 +/- 21.20
---------------------------------
| eval/              |          |
|    mean_ep_length  | 240      |
|    mean_reward     | 62.7     |
| time/              |          |
|    total_timesteps | 60000    |
| train/             |          |
|    actor_loss      | 3.11     |
|    critic_loss     | 2.3      |
|    learning_rate   | 0.000941 |
|    n_updates       | 57530    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -5.87    |
| time/              |          |
|    episodes        | 244      |
|    fps             | 21       |
|    time_elapsed    | 2842     |
|    total timesteps | 60793    |
| train/             |          |
|    actor_loss      | 3.05     |
|    critic_loss     | 2.03     |
|    learning_rate   | 0.00094  |
|    n_updates       | 58283    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -5.56    |
| time/              |          |
|    episodes        | 248      |
|    fps             | 21       |
|    time_elapsed    | 2888     |
|    total timesteps | 61797    |
| train/             |          |
|    actor_loss      | 3.05     |
|    critic_loss     | 2.07     |
|    learning_rate   | 0.000939 |
|    n_updates       | 59287    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -4.02    |
| time/              |          |
|    episodes        | 252      |
|    fps             | 21       |
|    time_elapsed    | 2934     |
|    total timesteps | 62801    |
| train/             |          |
|    actor_loss      | 3.03     |
|    critic_loss     | 1.92     |
|    learning_rate   | 0.000938 |
|    n_updates       | 60291    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -4.09    |
| time/              |          |
|    episodes        | 256      |
|    fps             | 21       |
|    time_elapsed    | 2980     |
|    total timesteps | 63805    |
| train/             |          |
|    actor_loss      | 2.98     |
|    critic_loss     | 1.8      |
|    learning_rate   | 0.000937 |
|    n_updates       | 61295    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -4.43    |
| time/              |          |
|    episodes        | 260      |
|    fps             | 21       |
|    time_elapsed    | 3025     |
|    total timesteps | 64809    |
| train/             |          |
|    actor_loss      | 3        |
|    critic_loss     | 2.19     |
|    learning_rate   | 0.000936 |
|    n_updates       | 62299    |
---------------------------------
Eval num_timesteps=65000, episode_reward=64.62 +/- 8.42
Episode length: 232.20 +/- 23.16
---------------------------------
| eval/              |          |
|    mean_ep_length  | 232      |
|    mean_reward     | 64.6     |
| time/              |          |
|    total_timesteps | 65000    |
| train/             |          |
|    actor_loss      | 2.97     |
|    critic_loss     | 1.85     |
|    learning_rate   | 0.000936 |
|    n_updates       | 62550    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -3.12    |
| time/              |          |
|    episodes        | 264      |
|    fps             | 21       |
|    time_elapsed    | 3082     |
|    total timesteps | 65812    |
| train/             |          |
|    actor_loss      | 2.93     |
|    critic_loss     | 1.83     |
|    learning_rate   | 0.000935 |
|    n_updates       | 63302    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -3.52    |
| time/              |          |
|    episodes        | 268      |
|    fps             | 21       |
|    time_elapsed    | 3127     |
|    total timesteps | 66816    |
| train/             |          |
|    actor_loss      | 2.91     |
|    critic_loss     | 1.75     |
|    learning_rate   | 0.000934 |
|    n_updates       | 64306    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -2.28    |
| time/              |          |
|    episodes        | 272      |
|    fps             | 21       |
|    time_elapsed    | 3172     |
|    total timesteps | 67820    |
| train/             |          |
|    actor_loss      | 2.91     |
|    critic_loss     | 2.07     |
|    learning_rate   | 0.000933 |
|    n_updates       | 65310    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -1.19    |
| time/              |          |
|    episodes        | 276      |
|    fps             | 21       |
|    time_elapsed    | 3218     |
|    total timesteps | 68824    |
| train/             |          |
|    actor_loss      | 2.89     |
|    critic_loss     | 2.15     |
|    learning_rate   | 0.000932 |
|    n_updates       | 66314    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -1.03    |
| time/              |          |
|    episodes        | 280      |
|    fps             | 21       |
|    time_elapsed    | 3262     |
|    total timesteps | 69798    |
| train/             |          |
|    actor_loss      | 2.88     |
|    critic_loss     | 2.01     |
|    learning_rate   | 0.000931 |
|    n_updates       | 67288    |
---------------------------------
Eval num_timesteps=70000, episode_reward=66.37 +/- 5.90
Episode length: 242.40 +/- 17.20
---------------------------------
| eval/              |          |
|    mean_ep_length  | 242      |
|    mean_reward     | 66.4     |
| time/              |          |
|    total_timesteps | 70000    |
| train/             |          |
|    actor_loss      | 2.88     |
|    critic_loss     | 2.2      |
|    learning_rate   | 0.000931 |
|    n_updates       | 67539    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -0.715   |
| time/              |          |
|    episodes        | 284      |
|    fps             | 21       |
|    time_elapsed    | 3322     |
|    total timesteps | 70802    |
| train/             |          |
|    actor_loss      | 2.84     |
|    critic_loss     | 2        |
|    learning_rate   | 0.00093  |
|    n_updates       | 68292    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -0.382   |
| time/              |          |
|    episodes        | 288      |
|    fps             | 21       |
|    time_elapsed    | 3367     |
|    total timesteps | 71806    |
| train/             |          |
|    actor_loss      | 2.83     |
|    critic_loss     | 2.29     |
|    learning_rate   | 0.000929 |
|    n_updates       | 69296    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | 0.372    |
| time/              |          |
|    episodes        | 292      |
|    fps             | 21       |
|    time_elapsed    | 3412     |
|    total timesteps | 72808    |
| train/             |          |
|    actor_loss      | 2.84     |
|    critic_loss     | 2.39     |
|    learning_rate   | 0.000928 |
|    n_updates       | 70300    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | 1.79     |
| time/              |          |
|    episodes        | 296      |
|    fps             | 21       |
|    time_elapsed    | 3456     |
|    total timesteps | 73767    |
| train/             |          |
|    actor_loss      | 2.81     |
|    critic_loss     | 2.13     |
|    learning_rate   | 0.000927 |
|    n_updates       | 71257    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | 0.436    |
| time/              |          |
|    episodes        | 300      |
|    fps             | 21       |
|    time_elapsed    | 3501     |
|    total timesteps | 74771    |
| train/             |          |
|    actor_loss      | 2.78     |
|    critic_loss     | 2.17     |
|    learning_rate   | 0.000926 |
|    n_updates       | 72261    |
---------------------------------
Eval num_timesteps=75000, episode_reward=67.56 +/- 5.69
Episode length: 251.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 251      |
|    mean_reward     | 67.6     |
| time/              |          |
|    total_timesteps | 75000    |
| train/             |          |
|    actor_loss      | 2.76     |
|    critic_loss     | 1.86     |
|    learning_rate   | 0.000926 |
|    n_updates       | 72512    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | 0.156    |
| time/              |          |
|    episodes        | 304      |
|    fps             | 21       |
|    time_elapsed    | 3559     |
|    total timesteps | 75775    |
| train/             |          |
|    actor_loss      | 2.73     |
|    critic_loss     | 1.96     |
|    learning_rate   | 0.000925 |
|    n_updates       | 73265    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | 0.693    |
| time/              |          |
|    episodes        | 308      |
|    fps             | 21       |
|    time_elapsed    | 3602     |
|    total timesteps | 76738    |
| train/             |          |
|    actor_loss      | 2.73     |
|    critic_loss     | 2.02     |
|    learning_rate   | 0.000924 |
|    n_updates       | 74228    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | 0.259    |
| time/              |          |
|    episodes        | 312      |
|    fps             | 21       |
|    time_elapsed    | 3648     |
|    total timesteps | 77742    |
| train/             |          |
|    actor_loss      | 2.69     |
|    critic_loss     | 1.92     |
|    learning_rate   | 0.000923 |
|    n_updates       | 75232    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | 0.43     |
| time/              |          |
|    episodes        | 316      |
|    fps             | 21       |
|    time_elapsed    | 3693     |
|    total timesteps | 78746    |
| train/             |          |
|    actor_loss      | 2.67     |
|    critic_loss     | 1.89     |
|    learning_rate   | 0.000922 |
|    n_updates       | 76236    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | 1.33     |
| time/              |          |
|    episodes        | 320      |
|    fps             | 21       |
|    time_elapsed    | 3738     |
|    total timesteps | 79750    |
| train/             |          |
|    actor_loss      | 2.66     |
|    critic_loss     | 2.1      |
|    learning_rate   | 0.000921 |
|    n_updates       | 77240    |
---------------------------------
Eval num_timesteps=80000, episode_reward=64.92 +/- 9.64
Episode length: 233.40 +/- 21.59
---------------------------------
| eval/              |          |
|    mean_ep_length  | 233      |
|    mean_reward     | 64.9     |
| time/              |          |
|    total_timesteps | 80000    |
| train/             |          |
|    actor_loss      | 2.66     |
|    critic_loss     | 2.08     |
|    learning_rate   | 0.000921 |
|    n_updates       | 77491    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -0.572   |
| time/              |          |
|    episodes        | 324      |
|    fps             | 21       |
|    time_elapsed    | 3796     |
|    total timesteps | 80754    |
| train/             |          |
|    actor_loss      | 2.68     |
|    critic_loss     | 2        |
|    learning_rate   | 0.00092  |
|    n_updates       | 78244    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -1.55    |
| time/              |          |
|    episodes        | 328      |
|    fps             | 21       |
|    time_elapsed    | 3841     |
|    total timesteps | 81758    |
| train/             |          |
|    actor_loss      | 2.69     |
|    critic_loss     | 2.35     |
|    learning_rate   | 0.000919 |
|    n_updates       | 79248    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -0.716   |
| time/              |          |
|    episodes        | 332      |
|    fps             | 21       |
|    time_elapsed    | 3886     |
|    total timesteps | 82762    |
| train/             |          |
|    actor_loss      | 2.67     |
|    critic_loss     | 2.34     |
|    learning_rate   | 0.000918 |
|    n_updates       | 80252    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -1.02    |
| time/              |          |
|    episodes        | 336      |
|    fps             | 21       |
|    time_elapsed    | 3931     |
|    total timesteps | 83766    |
| train/             |          |
|    actor_loss      | 2.59     |
|    critic_loss     | 1.43     |
|    learning_rate   | 0.000917 |
|    n_updates       | 81256    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -1.84    |
| time/              |          |
|    episodes        | 340      |
|    fps             | 21       |
|    time_elapsed    | 3977     |
|    total timesteps | 84770    |
| train/             |          |
|    actor_loss      | 2.58     |
|    critic_loss     | 1.99     |
|    learning_rate   | 0.000916 |
|    n_updates       | 82260    |
---------------------------------
Eval num_timesteps=85000, episode_reward=60.92 +/- 11.35
Episode length: 220.80 +/- 24.70
---------------------------------
| eval/              |          |
|    mean_ep_length  | 221      |
|    mean_reward     | 60.9     |
| time/              |          |
|    total_timesteps | 85000    |
| train/             |          |
|    actor_loss      | 2.57     |
|    critic_loss     | 1.83     |
|    learning_rate   | 0.000916 |
|    n_updates       | 82511    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -3.28    |
| time/              |          |
|    episodes        | 344      |
|    fps             | 21       |
|    time_elapsed    | 4034     |
|    total timesteps | 85774    |
| train/             |          |
|    actor_loss      | 2.62     |
|    critic_loss     | 2.53     |
|    learning_rate   | 0.000915 |
|    n_updates       | 83264    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -4       |
| time/              |          |
|    episodes        | 348      |
|    fps             | 21       |
|    time_elapsed    | 4080     |
|    total timesteps | 86778    |
| train/             |          |
|    actor_loss      | 2.54     |
|    critic_loss     | 1.77     |
|    learning_rate   | 0.000914 |
|    n_updates       | 84268    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -4.18    |
| time/              |          |
|    episodes        | 352      |
|    fps             | 21       |
|    time_elapsed    | 4127     |
|    total timesteps | 87782    |
| train/             |          |
|    actor_loss      | 2.57     |
|    critic_loss     | 2.1      |
|    learning_rate   | 0.000913 |
|    n_updates       | 85272    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -4.6     |
| time/              |          |
|    episodes        | 356      |
|    fps             | 21       |
|    time_elapsed    | 4172     |
|    total timesteps | 88786    |
| train/             |          |
|    actor_loss      | 2.54     |
|    critic_loss     | 1.81     |
|    learning_rate   | 0.000912 |
|    n_updates       | 86276    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -4.52    |
| time/              |          |
|    episodes        | 360      |
|    fps             | 21       |
|    time_elapsed    | 4217     |
|    total timesteps | 89790    |
| train/             |          |
|    actor_loss      | 2.5      |
|    critic_loss     | 1.57     |
|    learning_rate   | 0.000911 |
|    n_updates       | 87280    |
---------------------------------
Eval num_timesteps=90000, episode_reward=52.56 +/- 22.16
Episode length: 230.60 +/- 24.99
---------------------------------
| eval/              |          |
|    mean_ep_length  | 231      |
|    mean_reward     | 52.6     |
| time/              |          |
|    total_timesteps | 90000    |
| train/             |          |
|    actor_loss      | 2.5      |
|    critic_loss     | 1.89     |
|    learning_rate   | 0.000911 |
|    n_updates       | 87531    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -5.77    |
| time/              |          |
|    episodes        | 364      |
|    fps             | 21       |
|    time_elapsed    | 4275     |
|    total timesteps | 90794    |
| train/             |          |
|    actor_loss      | 2.49     |
|    critic_loss     | 1.94     |
|    learning_rate   | 0.00091  |
|    n_updates       | 88284    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -5.51    |
| time/              |          |
|    episodes        | 368      |
|    fps             | 21       |
|    time_elapsed    | 4320     |
|    total timesteps | 91798    |
| train/             |          |
|    actor_loss      | 2.5      |
|    critic_loss     | 2.47     |
|    learning_rate   | 0.000909 |
|    n_updates       | 89288    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -6.24    |
| time/              |          |
|    episodes        | 372      |
|    fps             | 21       |
|    time_elapsed    | 4365     |
|    total timesteps | 92802    |
| train/             |          |
|    actor_loss      | 2.46     |
|    critic_loss     | 1.88     |
|    learning_rate   | 0.000908 |
|    n_updates       | 90292    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -7.49    |
| time/              |          |
|    episodes        | 376      |
|    fps             | 21       |
|    time_elapsed    | 4410     |
|    total timesteps | 93806    |
| train/             |          |
|    actor_loss      | 2.45     |
|    critic_loss     | 1.97     |
|    learning_rate   | 0.000907 |
|    n_updates       | 91296    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -7.76    |
| time/              |          |
|    episodes        | 380      |
|    fps             | 21       |
|    time_elapsed    | 4455     |
|    total timesteps | 94810    |
| train/             |          |
|    actor_loss      | 2.43     |
|    critic_loss     | 1.98     |
|    learning_rate   | 0.000906 |
|    n_updates       | 92300    |
---------------------------------
Eval num_timesteps=95000, episode_reward=66.56 +/- 11.54
Episode length: 219.00 +/- 26.75
---------------------------------
| eval/              |          |
|    mean_ep_length  | 219      |
|    mean_reward     | 66.6     |
| time/              |          |
|    total_timesteps | 95000    |
| train/             |          |
|    actor_loss      | 2.43     |
|    critic_loss     | 1.76     |
|    learning_rate   | 0.000906 |
|    n_updates       | 92551    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -8.5     |
| time/              |          |
|    episodes        | 384      |
|    fps             | 21       |
|    time_elapsed    | 4511     |
|    total timesteps | 95814    |
| train/             |          |
|    actor_loss      | 2.44     |
|    critic_loss     | 2.01     |
|    learning_rate   | 0.000905 |
|    n_updates       | 93304    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -9.35    |
| time/              |          |
|    episodes        | 388      |
|    fps             | 21       |
|    time_elapsed    | 4557     |
|    total timesteps | 96818    |
| train/             |          |
|    actor_loss      | 2.46     |
|    critic_loss     | 2.18     |
|    learning_rate   | 0.000904 |
|    n_updates       | 94308    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -10      |
| time/              |          |
|    episodes        | 392      |
|    fps             | 21       |
|    time_elapsed    | 4602     |
|    total timesteps | 97790    |
| train/             |          |
|    actor_loss      | 2.48     |
|    critic_loss     | 2.13     |
|    learning_rate   | 0.000903 |
|    n_updates       | 95312    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -10      |
| time/              |          |
|    episodes        | 396      |
|    fps             | 21       |
|    time_elapsed    | 4646     |
|    total timesteps | 98794    |
| train/             |          |
|    actor_loss      | 2.47     |
|    critic_loss     | 2.17     |
|    learning_rate   | 0.000902 |
|    n_updates       | 96284    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -9.79    |
| time/              |          |
|    episodes        | 400      |
|    fps             | 21       |
|    time_elapsed    | 4693     |
|    total timesteps | 99798    |
| train/             |          |
|    actor_loss      | 2.43     |
|    critic_loss     | 1.77     |
|    learning_rate   | 0.000901 |
|    n_updates       | 97288    |
---------------------------------
Eval num_timesteps=100000, episode_reward=66.43 +/- 11.88
Episode length: 251.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 251      |
|    mean_reward     | 66.4     |
| time/              |          |
|    total_timesteps | 100000   |
| train/             |          |
|    actor_loss      | 2.44     |
|    critic_loss     | 1.94     |
|    learning_rate   | 0.000901 |
|    n_updates       | 97539    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -10.4    |
| time/              |          |
|    episodes        | 404      |
|    fps             | 21       |
|    time_elapsed    | 4752     |
|    total timesteps | 100802   |
| train/             |          |
|    actor_loss      | 2.42     |
|    critic_loss     | 2.12     |
|    learning_rate   | 0.0009   |
|    n_updates       | 98292    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -11      |
| time/              |          |
|    episodes        | 408      |
|    fps             | 21       |
|    time_elapsed    | 4797     |
|    total timesteps | 101806   |
| train/             |          |
|    actor_loss      | 2.43     |
|    critic_loss     | 2.19     |
|    learning_rate   | 0.000899 |
|    n_updates       | 99296    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -11.3    |
| time/              |          |
|    episodes        | 412      |
|    fps             | 21       |
|    time_elapsed    | 4843     |
|    total timesteps | 102810   |
| train/             |          |
|    actor_loss      | 2.45     |
|    critic_loss     | 1.84     |
|    learning_rate   | 0.000898 |
|    n_updates       | 100300   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -9.89    |
| time/              |          |
|    episodes        | 416      |
|    fps             | 21       |
|    time_elapsed    | 4887     |
|    total timesteps | 103781   |
| train/             |          |
|    actor_loss      | 2.43     |
|    critic_loss     | 2.19     |
|    learning_rate   | 0.000898 |
|    n_updates       | 101271   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -10.6    |
| time/              |          |
|    episodes        | 420      |
|    fps             | 21       |
|    time_elapsed    | 4932     |
|    total timesteps | 104785   |
| train/             |          |
|    actor_loss      | 2.42     |
|    critic_loss     | 2.32     |
|    learning_rate   | 0.000897 |
|    n_updates       | 102275   |
---------------------------------
Eval num_timesteps=105000, episode_reward=66.94 +/- 6.44
Episode length: 239.40 +/- 23.20
---------------------------------
| eval/              |          |
|    mean_ep_length  | 239      |
|    mean_reward     | 66.9     |
| time/              |          |
|    total_timesteps | 105000   |
| train/             |          |
|    actor_loss      | 2.38     |
|    critic_loss     | 1.61     |
|    learning_rate   | 0.000896 |
|    n_updates       | 102526   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -9.72    |
| time/              |          |
|    episodes        | 424      |
|    fps             | 21       |
|    time_elapsed    | 4989     |
|    total timesteps | 105789   |
| train/             |          |
|    actor_loss      | 2.38     |
|    critic_loss     | 1.76     |
|    learning_rate   | 0.000896 |
|    n_updates       | 103279   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -8.47    |
| time/              |          |
|    episodes        | 428      |
|    fps             | 21       |
|    time_elapsed    | 5034     |
|    total timesteps | 106793   |
| train/             |          |
|    actor_loss      | 2.39     |
|    critic_loss     | 2.15     |
|    learning_rate   | 0.000895 |
|    n_updates       | 104283   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -10.1    |
| time/              |          |
|    episodes        | 432      |
|    fps             | 21       |
|    time_elapsed    | 5079     |
|    total timesteps | 107797   |
| train/             |          |
|    actor_loss      | 2.37     |
|    critic_loss     | 1.93     |
|    learning_rate   | 0.000894 |
|    n_updates       | 105287   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -10.4    |
| time/              |          |
|    episodes        | 436      |
|    fps             | 21       |
|    time_elapsed    | 5124     |
|    total timesteps | 108801   |
| train/             |          |
|    actor_loss      | 2.36     |
|    critic_loss     | 1.94     |
|    learning_rate   | 0.000893 |
|    n_updates       | 106291   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -10.1    |
| time/              |          |
|    episodes        | 440      |
|    fps             | 21       |
|    time_elapsed    | 5169     |
|    total timesteps | 109805   |
| train/             |          |
|    actor_loss      | 2.33     |
|    critic_loss     | 1.84     |
|    learning_rate   | 0.000892 |
|    n_updates       | 107295   |
---------------------------------
Eval num_timesteps=110000, episode_reward=64.43 +/- 24.53
Episode length: 250.80 +/- 0.40
---------------------------------
| eval/              |          |
|    mean_ep_length  | 251      |
|    mean_reward     | 64.4     |
| time/              |          |
|    total_timesteps | 110000   |
| train/             |          |
|    actor_loss      | 2.33     |
|    critic_loss     | 2        |
|    learning_rate   | 0.000891 |
|    n_updates       | 107546   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -10.6    |
| time/              |          |
|    episodes        | 444      |
|    fps             | 21       |
|    time_elapsed    | 5227     |
|    total timesteps | 110809   |
| train/             |          |
|    actor_loss      | 2.35     |
|    critic_loss     | 1.75     |
|    learning_rate   | 0.000891 |
|    n_updates       | 108299   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -9.06    |
| time/              |          |
|    episodes        | 448      |
|    fps             | 21       |
|    time_elapsed    | 5273     |
|    total timesteps | 111799   |
| train/             |          |
|    actor_loss      | 2.34     |
|    critic_loss     | 1.81     |
|    learning_rate   | 0.00089  |
|    n_updates       | 109289   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -9       |
| time/              |          |
|    episodes        | 452      |
|    fps             | 21       |
|    time_elapsed    | 5319     |
|    total timesteps | 112803   |
| train/             |          |
|    actor_loss      | 2.34     |
|    critic_loss     | 1.98     |
|    learning_rate   | 0.000889 |
|    n_updates       | 110293   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -8.54    |
| time/              |          |
|    episodes        | 456      |
|    fps             | 21       |
|    time_elapsed    | 5365     |
|    total timesteps | 113807   |
| train/             |          |
|    actor_loss      | 2.33     |
|    critic_loss     | 2        |
|    learning_rate   | 0.000888 |
|    n_updates       | 111297   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -9.05    |
| time/              |          |
|    episodes        | 460      |
|    fps             | 21       |
|    time_elapsed    | 5411     |
|    total timesteps | 114811   |
| train/             |          |
|    actor_loss      | 2.31     |
|    critic_loss     | 1.86     |
|    learning_rate   | 0.000887 |
|    n_updates       | 112301   |
---------------------------------
Eval num_timesteps=115000, episode_reward=69.24 +/- 10.62
Episode length: 233.60 +/- 22.32
---------------------------------
| eval/              |          |
|    mean_ep_length  | 234      |
|    mean_reward     | 69.2     |
| time/              |          |
|    total_timesteps | 115000   |
| train/             |          |
|    actor_loss      | 2.31     |
|    critic_loss     | 1.62     |
|    learning_rate   | 0.000886 |
|    n_updates       | 112552   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -8.36    |
| time/              |          |
|    episodes        | 464      |
|    fps             | 21       |
|    time_elapsed    | 5469     |
|    total timesteps | 115815   |
| train/             |          |
|    actor_loss      | 2.28     |
|    critic_loss     | 1.69     |
|    learning_rate   | 0.000886 |
|    n_updates       | 113305   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -8.24    |
| time/              |          |
|    episodes        | 468      |
|    fps             | 21       |
|    time_elapsed    | 5514     |
|    total timesteps | 116819   |
| train/             |          |
|    actor_loss      | 2.29     |
|    critic_loss     | 1.96     |
|    learning_rate   | 0.000885 |
|    n_updates       | 114309   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -7.67    |
| time/              |          |
|    episodes        | 472      |
|    fps             | 21       |
|    time_elapsed    | 5559     |
|    total timesteps | 117823   |
| train/             |          |
|    actor_loss      | 2.3      |
|    critic_loss     | 2.14     |
|    learning_rate   | 0.000884 |
|    n_updates       | 115313   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -7.08    |
| time/              |          |
|    episodes        | 476      |
|    fps             | 21       |
|    time_elapsed    | 5602     |
|    total timesteps | 118765   |
| train/             |          |
|    actor_loss      | 2.29     |
|    critic_loss     | 1.79     |
|    learning_rate   | 0.000883 |
|    n_updates       | 116255   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -7.15    |
| time/              |          |
|    episodes        | 480      |
|    fps             | 21       |
|    time_elapsed    | 5645     |
|    total timesteps | 119716   |
| train/             |          |
|    actor_loss      | 2.33     |
|    critic_loss     | 2.31     |
|    learning_rate   | 0.000882 |
|    n_updates       | 117206   |
---------------------------------
Eval num_timesteps=120000, episode_reward=69.40 +/- 8.61
Episode length: 242.00 +/- 18.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 242      |
|    mean_reward     | 69.4     |
| time/              |          |
|    total_timesteps | 120000   |
| train/             |          |
|    actor_loss      | 2.33     |
|    critic_loss     | 2.28     |
|    learning_rate   | 0.000881 |
|    n_updates       | 117708   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -8.41    |
| time/              |          |
|    episodes        | 484      |
|    fps             | 21       |
|    time_elapsed    | 5702     |
|    total timesteps | 120720   |
| train/             |          |
|    actor_loss      | 2.36     |
|    critic_loss     | 2.82     |
|    learning_rate   | 0.000881 |
|    n_updates       | 118210   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -7.66    |
| time/              |          |
|    episodes        | 488      |
|    fps             | 21       |
|    time_elapsed    | 5749     |
|    total timesteps | 121724   |
| train/             |          |
|    actor_loss      | 2.35     |
|    critic_loss     | 1.85     |
|    learning_rate   | 0.00088  |
|    n_updates       | 119214   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -7.35    |
| time/              |          |
|    episodes        | 492      |
|    fps             | 21       |
|    time_elapsed    | 5792     |
|    total timesteps | 122681   |
| train/             |          |
|    actor_loss      | 2.36     |
|    critic_loss     | 1.65     |
|    learning_rate   | 0.000879 |
|    n_updates       | 120171   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -7.68    |
| time/              |          |
|    episodes        | 496      |
|    fps             | 21       |
|    time_elapsed    | 5838     |
|    total timesteps | 123685   |
| train/             |          |
|    actor_loss      | 2.33     |
|    critic_loss     | 1.36     |
|    learning_rate   | 0.000878 |
|    n_updates       | 121175   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -6.64    |
| time/              |          |
|    episodes        | 500      |
|    fps             | 21       |
|    time_elapsed    | 5885     |
|    total timesteps | 124689   |
| train/             |          |
|    actor_loss      | 2.33     |
|    critic_loss     | 1.68     |
|    learning_rate   | 0.000877 |
|    n_updates       | 122179   |
---------------------------------
Eval num_timesteps=125000, episode_reward=70.03 +/- 17.28
Episode length: 251.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 251      |
|    mean_reward     | 70       |
| time/              |          |
|    total_timesteps | 125000   |
| train/             |          |
|    actor_loss      | 2.34     |
|    critic_loss     | 1.97     |
|    learning_rate   | 0.000876 |
|    n_updates       | 122681   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -5.73    |
| time/              |          |
|    episodes        | 504      |
|    fps             | 21       |
|    time_elapsed    | 5943     |
|    total timesteps | 125693   |
| train/             |          |
|    actor_loss      | 2.34     |
|    critic_loss     | 2.05     |
|    learning_rate   | 0.000876 |
|    n_updates       | 123183   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -6.1     |
| time/              |          |
|    episodes        | 508      |
|    fps             | 21       |
|    time_elapsed    | 5990     |
|    total timesteps | 126697   |
| train/             |          |
|    actor_loss      | 2.31     |
|    critic_loss     | 1.52     |
|    learning_rate   | 0.000875 |
|    n_updates       | 124187   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -5.57    |
| time/              |          |
|    episodes        | 512      |
|    fps             | 21       |
|    time_elapsed    | 6035     |
|    total timesteps | 127701   |
| train/             |          |
|    actor_loss      | 2.36     |
|    critic_loss     | 2.36     |
|    learning_rate   | 0.000874 |
|    n_updates       | 125191   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -5.98    |
| time/              |          |
|    episodes        | 516      |
|    fps             | 21       |
|    time_elapsed    | 6080     |
|    total timesteps | 128705   |
| train/             |          |
|    actor_loss      | 2.37     |
|    critic_loss     | 2.6      |
|    learning_rate   | 0.000873 |
|    n_updates       | 126195   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 248      |
|    ep_rew_mean     | -3.95    |
| time/              |          |
|    episodes        | 520      |
|    fps             | 21       |
|    time_elapsed    | 6120     |
|    total timesteps | 129545   |
| train/             |          |
|    actor_loss      | 2.34     |
|    critic_loss     | 2.11     |
|    learning_rate   | 0.000872 |
|    n_updates       | 127084   |
---------------------------------
Eval num_timesteps=130000, episode_reward=71.98 +/- 3.07
Episode length: 251.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 251      |
|    mean_reward     | 72       |
| time/              |          |
|    total_timesteps | 130000   |
| train/             |          |
|    actor_loss      | 2.31     |
|    critic_loss     | 1.93     |
|    learning_rate   | 0.000872 |
|    n_updates       | 127537   |
---------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 248      |
|    ep_rew_mean     | -5.24    |
| time/              |          |
|    episodes        | 524      |
|    fps             | 21       |
|    time_elapsed    | 6177     |
|    total timesteps | 130549   |
| train/             |          |
|    actor_loss      | 2.34     |
|    critic_loss     | 2.65     |
|    learning_rate   | 0.000871 |
|    n_updates       | 128039   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 248      |
|    ep_rew_mean     | -5.87    |
| time/              |          |
|    episodes        | 528      |
|    fps             | 21       |
|    time_elapsed    | 6223     |
|    total timesteps | 131553   |
| train/             |          |
|    actor_loss      | 2.34     |
|    critic_loss     | 1.91     |
|    learning_rate   | 0.00087  |
|    n_updates       | 129043   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 248      |
|    ep_rew_mean     | -5.7     |
| time/              |          |
|    episodes        | 532      |
|    fps             | 21       |
|    time_elapsed    | 6269     |
|    total timesteps | 132557   |
| train/             |          |
|    actor_loss      | 2.33     |
|    critic_loss     | 1.91     |
|    learning_rate   | 0.000869 |
|    n_updates       | 130047   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 248      |
|    ep_rew_mean     | -5.45    |
| time/              |          |
|    episodes        | 536      |
|    fps             | 21       |
|    time_elapsed    | 6314     |
|    total timesteps | 133561   |
| train/             |          |
|    actor_loss      | 2.3      |
|    critic_loss     | 1.92     |
|    learning_rate   | 0.000868 |
|    n_updates       | 131051   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 248      |
|    ep_rew_mean     | -4.79    |
| time/              |          |
|    episodes        | 540      |
|    fps             | 21       |
|    time_elapsed    | 6359     |
|    total timesteps | 134565   |
| train/             |          |
|    actor_loss      | 2.28     |
|    critic_loss     | 1.68     |
|    learning_rate   | 0.000867 |
|    n_updates       | 132055   |
---------------------------------
Eval num_timesteps=135000, episode_reward=58.67 +/- 14.65
Episode length: 231.20 +/- 24.50
---------------------------------
| eval/              |          |
|    mean_ep_length  | 231      |
|    mean_reward     | 58.7     |
| time/              |          |
|    total_timesteps | 135000   |
| train/             |          |
|    actor_loss      | 2.29     |
|    critic_loss     | 2.03     |
|    learning_rate   | 0.000867 |
|    n_updates       | 132557   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 247      |
|    ep_rew_mean     | -3.28    |
| time/              |          |
|    episodes        | 544      |
|    fps             | 21       |
|    time_elapsed    | 6416     |
|    total timesteps | 135544   |
| train/             |          |
|    actor_loss      | 2.3      |
|    critic_loss     | 1.95     |
|    learning_rate   | 0.000866 |
|    n_updates       | 133059   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 247      |
|    ep_rew_mean     | -4.32    |
| time/              |          |
|    episodes        | 548      |
|    fps             | 21       |
|    time_elapsed    | 6460     |
|    total timesteps | 136548   |
| train/             |          |
|    actor_loss      | 2.29     |
|    critic_loss     | 1.8      |
|    learning_rate   | 0.000865 |
|    n_updates       | 134038   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 247      |
|    ep_rew_mean     | -5.1     |
| time/              |          |
|    episodes        | 552      |
|    fps             | 21       |
|    time_elapsed    | 6505     |
|    total timesteps | 137552   |
| train/             |          |
|    actor_loss      | 2.32     |
|    critic_loss     | 2.19     |
|    learning_rate   | 0.000864 |
|    n_updates       | 135042   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 247      |
|    ep_rew_mean     | -4.94    |
| time/              |          |
|    episodes        | 556      |
|    fps             | 21       |
|    time_elapsed    | 6551     |
|    total timesteps | 138556   |
| train/             |          |
|    actor_loss      | 2.29     |
|    critic_loss     | 1.94     |
|    learning_rate   | 0.000863 |
|    n_updates       | 136046   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 247      |
|    ep_rew_mean     | -4.47    |
| time/              |          |
|    episodes        | 560      |
|    fps             | 21       |
|    time_elapsed    | 6596     |
|    total timesteps | 139560   |
| train/             |          |
|    actor_loss      | 2.3      |
|    critic_loss     | 2.29     |
|    learning_rate   | 0.000862 |
|    n_updates       | 137050   |
---------------------------------
Eval num_timesteps=140000, episode_reward=63.50 +/- 9.35
Episode length: 242.20 +/- 17.60
---------------------------------
| eval/              |          |
|    mean_ep_length  | 242      |
|    mean_reward     | 63.5     |
| time/              |          |
|    total_timesteps | 140000   |
| train/             |          |
|    actor_loss      | 2.31     |
|    critic_loss     | 2.36     |
|    learning_rate   | 0.000862 |
|    n_updates       | 137552   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 247      |
|    ep_rew_mean     | -5.24    |
| time/              |          |
|    episodes        | 564      |
|    fps             | 21       |
|    time_elapsed    | 6655     |
|    total timesteps | 140564   |
| train/             |          |
|    actor_loss      | 2.31     |
|    critic_loss     | 1.74     |
|    learning_rate   | 0.000861 |
|    n_updates       | 138054   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 247      |
|    ep_rew_mean     | -4.36    |
| time/              |          |
|    episodes        | 568      |
|    fps             | 21       |
|    time_elapsed    | 6698     |
|    total timesteps | 141498   |
| train/             |          |
|    actor_loss      | 2.27     |
|    critic_loss     | 1.55     |
|    learning_rate   | 0.00086  |
|    n_updates       | 138988   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 247      |
|    ep_rew_mean     | -4.01    |
| time/              |          |
|    episodes        | 572      |
|    fps             | 21       |
|    time_elapsed    | 6742     |
|    total timesteps | 142478   |
| train/             |          |
|    actor_loss      | 2.27     |
|    critic_loss     | 2.23     |
|    learning_rate   | 0.000859 |
|    n_updates       | 139968   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 247      |
|    ep_rew_mean     | -5.75    |
| time/              |          |
|    episodes        | 576      |
|    fps             | 21       |
|    time_elapsed    | 6787     |
|    total timesteps | 143482   |
| train/             |          |
|    actor_loss      | 2.28     |
|    critic_loss     | 2.08     |
|    learning_rate   | 0.000858 |
|    n_updates       | 140972   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 248      |
|    ep_rew_mean     | -5.72    |
| time/              |          |
|    episodes        | 580      |
|    fps             | 21       |
|    time_elapsed    | 6832     |
|    total timesteps | 144486   |
| train/             |          |
|    actor_loss      | 2.23     |
|    critic_loss     | 1.85     |
|    learning_rate   | 0.000857 |
|    n_updates       | 141976   |
---------------------------------
Eval num_timesteps=145000, episode_reward=67.88 +/- 6.43
Episode length: 251.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 251      |
|    mean_reward     | 67.9     |
| time/              |          |
|    total_timesteps | 145000   |
| train/             |          |
|    actor_loss      | 2.22     |
|    critic_loss     | 1.74     |
|    learning_rate   | 0.000856 |
|    n_updates       | 142729   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 248      |
|    ep_rew_mean     | -5.37    |
| time/              |          |
|    episodes        | 584      |
|    fps             | 21       |
|    time_elapsed    | 6890     |
|    total timesteps | 145490   |
| train/             |          |
|    actor_loss      | 2.21     |
|    critic_loss     | 1.79     |
|    learning_rate   | 0.000856 |
|    n_updates       | 142980   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 248      |
|    ep_rew_mean     | -5.86    |
| time/              |          |
|    episodes        | 588      |
|    fps             | 21       |
|    time_elapsed    | 6935     |
|    total timesteps | 146494   |
| train/             |          |
|    actor_loss      | 2.24     |
|    critic_loss     | 1.9      |
|    learning_rate   | 0.000855 |
|    n_updates       | 143984   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 248      |
|    ep_rew_mean     | -6.03    |
| time/              |          |
|    episodes        | 592      |
|    fps             | 21       |
|    time_elapsed    | 6980     |
|    total timesteps | 147498   |
| train/             |          |
|    actor_loss      | 2.23     |
|    critic_loss     | 1.75     |
|    learning_rate   | 0.000854 |
|    n_updates       | 144988   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 248      |
|    ep_rew_mean     | -6.6     |
| time/              |          |
|    episodes        | 596      |
|    fps             | 21       |
|    time_elapsed    | 7025     |
|    total timesteps | 148502   |
| train/             |          |
|    actor_loss      | 2.24     |
|    critic_loss     | 1.9      |
|    learning_rate   | 0.000853 |
|    n_updates       | 145992   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 248      |
|    ep_rew_mean     | -7.4     |
| time/              |          |
|    episodes        | 600      |
|    fps             | 21       |
|    time_elapsed    | 7071     |
|    total timesteps | 149506   |
| train/             |          |
|    actor_loss      | 2.2      |
|    critic_loss     | 1.85     |
|    learning_rate   | 0.000852 |
|    n_updates       | 146996   |
---------------------------------
Eval num_timesteps=150000, episode_reward=67.58 +/- 6.61
Episode length: 242.80 +/- 16.40
---------------------------------
| eval/              |          |
|    mean_ep_length  | 243      |
|    mean_reward     | 67.6     |
| time/              |          |
|    total_timesteps | 150000   |
| train/             |          |
|    actor_loss      | 2.19     |
|    critic_loss     | 1.6      |
|    learning_rate   | 0.000852 |
|    n_updates       | 147498   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 248      |
|    ep_rew_mean     | -6.83    |
| time/              |          |
|    episodes        | 604      |
|    fps             | 21       |
|    time_elapsed    | 7128     |
|    total timesteps | 150510   |
| train/             |          |
|    actor_loss      | 2.17     |
|    critic_loss     | 1.76     |
|    learning_rate   | 0.000851 |
|    n_updates       | 148000   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 248      |
|    ep_rew_mean     | -6.76    |
| time/              |          |
|    episodes        | 608      |
|    fps             | 21       |
|    time_elapsed    | 7171     |
|    total timesteps | 151453   |
| train/             |          |
|    actor_loss      | 2.17     |
|    critic_loss     | 1.75     |
|    learning_rate   | 0.00085  |
|    n_updates       | 148943   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 248      |
|    ep_rew_mean     | -7.78    |
| time/              |          |
|    episodes        | 612      |
|    fps             | 21       |
|    time_elapsed    | 7216     |
|    total timesteps | 152457   |
| train/             |          |
|    actor_loss      | 2.21     |
|    critic_loss     | 2.02     |
|    learning_rate   | 0.000849 |
|    n_updates       | 149947   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 248      |
|    ep_rew_mean     | -9.63    |
| time/              |          |
|    episodes        | 616      |
|    fps             | 21       |
|    time_elapsed    | 7262     |
|    total timesteps | 153461   |
| train/             |          |
|    actor_loss      | 2.22     |
|    critic_loss     | 2.09     |
|    learning_rate   | 0.000848 |
|    n_updates       | 150951   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -10.7    |
| time/              |          |
|    episodes        | 620      |
|    fps             | 21       |
|    time_elapsed    | 7307     |
|    total timesteps | 154465   |
| train/             |          |
|    actor_loss      | 2.22     |
|    critic_loss     | 1.77     |
|    learning_rate   | 0.000847 |
|    n_updates       | 151955   |
---------------------------------
Eval num_timesteps=155000, episode_reward=65.67 +/- 6.89
Episode length: 230.80 +/- 25.08
---------------------------------
| eval/              |          |
|    mean_ep_length  | 231      |
|    mean_reward     | 65.7     |
| time/              |          |
|    total_timesteps | 155000   |
| train/             |          |
|    actor_loss      | 2.22     |
|    critic_loss     | 2.09     |
|    learning_rate   | 0.000847 |
|    n_updates       | 152708   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -10.6    |
| time/              |          |
|    episodes        | 624      |
|    fps             | 21       |
|    time_elapsed    | 7363     |
|    total timesteps | 155469   |
| train/             |          |
|    actor_loss      | 2.24     |
|    critic_loss     | 2.29     |
|    learning_rate   | 0.000846 |
|    n_updates       | 152959   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -9.61    |
| time/              |          |
|    episodes        | 628      |
|    fps             | 21       |
|    time_elapsed    | 7409     |
|    total timesteps | 156473   |
| train/             |          |
|    actor_loss      | 2.22     |
|    critic_loss     | 2.24     |
|    learning_rate   | 0.000845 |
|    n_updates       | 153963   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -10.7    |
| time/              |          |
|    episodes        | 632      |
|    fps             | 21       |
|    time_elapsed    | 7452     |
|    total timesteps | 157423   |
| train/             |          |
|    actor_loss      | 2.22     |
|    critic_loss     | 2.29     |
|    learning_rate   | 0.000844 |
|    n_updates       | 154913   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -10.7    |
| time/              |          |
|    episodes        | 636      |
|    fps             | 21       |
|    time_elapsed    | 7498     |
|    total timesteps | 158427   |
| train/             |          |
|    actor_loss      | 2.2      |
|    critic_loss     | 1.81     |
|    learning_rate   | 0.000843 |
|    n_updates       | 155917   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 248      |
|    ep_rew_mean     | -10.3    |
| time/              |          |
|    episodes        | 640      |
|    fps             | 21       |
|    time_elapsed    | 7544     |
|    total timesteps | 159367   |
| train/             |          |
|    actor_loss      | 2.22     |
|    critic_loss     | 2.23     |
|    learning_rate   | 0.000842 |
|    n_updates       | 156921   |
---------------------------------
Eval num_timesteps=160000, episode_reward=70.72 +/- 15.63
Episode length: 231.00 +/- 24.79
---------------------------------
| eval/              |          |
|    mean_ep_length  | 231      |
|    mean_reward     | 70.7     |
| time/              |          |
|    total_timesteps | 160000   |
| train/             |          |
|    actor_loss      | 2.23     |
|    critic_loss     | 2.08     |
|    learning_rate   | 0.000842 |
|    n_updates       | 157610   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 248      |
|    ep_rew_mean     | -12.4    |
| time/              |          |
|    episodes        | 644      |
|    fps             | 21       |
|    time_elapsed    | 7599     |
|    total timesteps | 160371   |
| train/             |          |
|    actor_loss      | 2.2      |
|    critic_loss     | 1.7      |
|    learning_rate   | 0.000841 |
|    n_updates       | 157861   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 248      |
|    ep_rew_mean     | -12.5    |
| time/              |          |
|    episodes        | 648      |
|    fps             | 21       |
|    time_elapsed    | 7645     |
|    total timesteps | 161375   |
| train/             |          |
|    actor_loss      | 2.22     |
|    critic_loss     | 2        |
|    learning_rate   | 0.00084  |
|    n_updates       | 158865   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 248      |
|    ep_rew_mean     | -12.2    |
| time/              |          |
|    episodes        | 652      |
|    fps             | 21       |
|    time_elapsed    | 7692     |
|    total timesteps | 162379   |
| train/             |          |
|    actor_loss      | 2.18     |
|    critic_loss     | 2        |
|    learning_rate   | 0.000839 |
|    n_updates       | 159869   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 248      |
|    ep_rew_mean     | -12.5    |
| time/              |          |
|    episodes        | 656      |
|    fps             | 21       |
|    time_elapsed    | 7738     |
|    total timesteps | 163383   |
| train/             |          |
|    actor_loss      | 2.16     |
|    critic_loss     | 2.04     |
|    learning_rate   | 0.000838 |
|    n_updates       | 160873   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 248      |
|    ep_rew_mean     | -12.8    |
| time/              |          |
|    episodes        | 660      |
|    fps             | 21       |
|    time_elapsed    | 7783     |
|    total timesteps | 164387   |
| train/             |          |
|    actor_loss      | 2.19     |
|    critic_loss     | 1.85     |
|    learning_rate   | 0.000838 |
|    n_updates       | 161877   |
---------------------------------
Eval num_timesteps=165000, episode_reward=64.11 +/- 15.54
Episode length: 251.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 251      |
|    mean_reward     | 64.1     |
| time/              |          |
|    total_timesteps | 165000   |
| train/             |          |
|    actor_loss      | 2.15     |
|    critic_loss     | 1.84     |
|    learning_rate   | 0.000837 |
|    n_updates       | 162630   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 248      |
|    ep_rew_mean     | -12      |
| time/              |          |
|    episodes        | 664      |
|    fps             | 21       |
|    time_elapsed    | 7840     |
|    total timesteps | 165335   |
| train/             |          |
|    actor_loss      | 2.16     |
|    critic_loss     | 1.89     |
|    learning_rate   | 0.000837 |
|    n_updates       | 162825   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 248      |
|    ep_rew_mean     | -13.1    |
| time/              |          |
|    episodes        | 668      |
|    fps             | 21       |
|    time_elapsed    | 7886     |
|    total timesteps | 166339   |
| train/             |          |
|    actor_loss      | 2.13     |
|    critic_loss     | 1.85     |
|    learning_rate   | 0.000836 |
|    n_updates       | 163829   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -14      |
| time/              |          |
|    episodes        | 672      |
|    fps             | 21       |
|    time_elapsed    | 7931     |
|    total timesteps | 167343   |
| train/             |          |
|    actor_loss      | 2.14     |
|    critic_loss     | 2.27     |
|    learning_rate   | 0.000835 |
|    n_updates       | 164833   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -11.9    |
| time/              |          |
|    episodes        | 676      |
|    fps             | 21       |
|    time_elapsed    | 7976     |
|    total timesteps | 168347   |
| train/             |          |
|    actor_loss      | 2.13     |
|    critic_loss     | 1.96     |
|    learning_rate   | 0.000834 |
|    n_updates       | 165837   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -11.7    |
| time/              |          |
|    episodes        | 680      |
|    fps             | 21       |
|    time_elapsed    | 8021     |
|    total timesteps | 169351   |
| train/             |          |
|    actor_loss      | 2.15     |
|    critic_loss     | 2.06     |
|    learning_rate   | 0.000833 |
|    n_updates       | 166841   |
---------------------------------
Eval num_timesteps=170000, episode_reward=68.21 +/- 8.05
Episode length: 251.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 251      |
|    mean_reward     | 68.2     |
| time/              |          |
|    total_timesteps | 170000   |
| train/             |          |
|    actor_loss      | 2.16     |
|    critic_loss     | 1.83     |
|    learning_rate   | 0.000832 |
|    n_updates       | 167594   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -10.5    |
| time/              |          |
|    episodes        | 684      |
|    fps             | 21       |
|    time_elapsed    | 8078     |
|    total timesteps | 170355   |
| train/             |          |
|    actor_loss      | 2.15     |
|    critic_loss     | 2.16     |
|    learning_rate   | 0.000832 |
|    n_updates       | 167845   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -10.3    |
| time/              |          |
|    episodes        | 688      |
|    fps             | 21       |
|    time_elapsed    | 8124     |
|    total timesteps | 171359   |
| train/             |          |
|    actor_loss      | 2.19     |
|    critic_loss     | 1.92     |
|    learning_rate   | 0.000831 |
|    n_updates       | 168849   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 248      |
|    ep_rew_mean     | -9.82    |
| time/              |          |
|    episodes        | 692      |
|    fps             | 21       |
|    time_elapsed    | 8169     |
|    total timesteps | 172335   |
| train/             |          |
|    actor_loss      | 2.23     |
|    critic_loss     | 2.19     |
|    learning_rate   | 0.00083  |
|    n_updates       | 169825   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 248      |
|    ep_rew_mean     | -8.94    |
| time/              |          |
|    episodes        | 696      |
|    fps             | 21       |
|    time_elapsed    | 8214     |
|    total timesteps | 173339   |
| train/             |          |
|    actor_loss      | 2.22     |
|    critic_loss     | 1.82     |
|    learning_rate   | 0.000829 |
|    n_updates       | 170829   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 248      |
|    ep_rew_mean     | -9.28    |
| time/              |          |
|    episodes        | 700      |
|    fps             | 21       |
|    time_elapsed    | 8260     |
|    total timesteps | 174343   |
| train/             |          |
|    actor_loss      | 2.24     |
|    critic_loss     | 1.96     |
|    learning_rate   | 0.000828 |
|    n_updates       | 171833   |
---------------------------------
Eval num_timesteps=175000, episode_reward=66.37 +/- 6.69
Episode length: 241.80 +/- 18.40
---------------------------------
| eval/              |          |
|    mean_ep_length  | 242      |
|    mean_reward     | 66.4     |
| time/              |          |
|    total_timesteps | 175000   |
| train/             |          |
|    actor_loss      | 2.24     |
|    critic_loss     | 2.02     |
|    learning_rate   | 0.000827 |
|    n_updates       | 172575   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 248      |
|    ep_rew_mean     | -8.6     |
| time/              |          |
|    episodes        | 704      |
|    fps             | 21       |
|    time_elapsed    | 8316     |
|    total timesteps | 175336   |
| train/             |          |
|    actor_loss      | 2.24     |
|    critic_loss     | 2.14     |
|    learning_rate   | 0.000827 |
|    n_updates       | 172826   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -8.04    |
| time/              |          |
|    episodes        | 708      |
|    fps             | 21       |
|    time_elapsed    | 8362     |
|    total timesteps | 176340   |
| train/             |          |
|    actor_loss      | 2.21     |
|    critic_loss     | 2.02     |
|    learning_rate   | 0.000826 |
|    n_updates       | 173830   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -7.3     |
| time/              |          |
|    episodes        | 712      |
|    fps             | 21       |
|    time_elapsed    | 8407     |
|    total timesteps | 177344   |
| train/             |          |
|    actor_loss      | 2.19     |
|    critic_loss     | 1.93     |
|    learning_rate   | 0.000825 |
|    n_updates       | 174834   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -5.42    |
| time/              |          |
|    episodes        | 716      |
|    fps             | 21       |
|    time_elapsed    | 8452     |
|    total timesteps | 178326   |
| train/             |          |
|    actor_loss      | 2.18     |
|    critic_loss     | 1.87     |
|    learning_rate   | 0.000824 |
|    n_updates       | 175816   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 248      |
|    ep_rew_mean     | -5.4     |
| time/              |          |
|    episodes        | 720      |
|    fps             | 21       |
|    time_elapsed    | 8498     |
|    total timesteps | 179297   |
| train/             |          |
|    actor_loss      | 2.2      |
|    critic_loss     | 2.16     |
|    learning_rate   | 0.000823 |
|    n_updates       | 176820   |
---------------------------------
Eval num_timesteps=180000, episode_reward=65.88 +/- 5.19
Episode length: 242.60 +/- 16.80
---------------------------------
| eval/              |          |
|    mean_ep_length  | 243      |
|    mean_reward     | 65.9     |
| time/              |          |
|    total_timesteps | 180000   |
| train/             |          |
|    actor_loss      | 2.17     |
|    critic_loss     | 1.87     |
|    learning_rate   | 0.000822 |
|    n_updates       | 177540   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 247      |
|    ep_rew_mean     | -4.74    |
| time/              |          |
|    episodes        | 724      |
|    fps             | 21       |
|    time_elapsed    | 8553     |
|    total timesteps | 180172   |
| train/             |          |
|    actor_loss      | 2.19     |
|    critic_loss     | 2.12     |
|    learning_rate   | 0.000822 |
|    n_updates       | 177791   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 247      |
|    ep_rew_mean     | -5.73    |
| time/              |          |
|    episodes        | 728      |
|    fps             | 21       |
|    time_elapsed    | 8593     |
|    total timesteps | 181176   |
| train/             |          |
|    actor_loss      | 2.19     |
|    critic_loss     | 2.08     |
|    learning_rate   | 0.000821 |
|    n_updates       | 178666   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 248      |
|    ep_rew_mean     | -4.22    |
| time/              |          |
|    episodes        | 732      |
|    fps             | 21       |
|    time_elapsed    | 8639     |
|    total timesteps | 182180   |
| train/             |          |
|    actor_loss      | 2.13     |
|    critic_loss     | 1.65     |
|    learning_rate   | 0.00082  |
|    n_updates       | 179670   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 248      |
|    ep_rew_mean     | -4.96    |
| time/              |          |
|    episodes        | 736      |
|    fps             | 21       |
|    time_elapsed    | 8685     |
|    total timesteps | 183184   |
| train/             |          |
|    actor_loss      | 2.14     |
|    critic_loss     | 1.86     |
|    learning_rate   | 0.000819 |
|    n_updates       | 180674   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 248      |
|    ep_rew_mean     | -6.61    |
| time/              |          |
|    episodes        | 740      |
|    fps             | 21       |
|    time_elapsed    | 8731     |
|    total timesteps | 184188   |
| train/             |          |
|    actor_loss      | 2.17     |
|    critic_loss     | 1.98     |
|    learning_rate   | 0.000818 |
|    n_updates       | 181678   |
---------------------------------
Eval num_timesteps=185000, episode_reward=59.47 +/- 6.51
Episode length: 229.40 +/- 26.58
---------------------------------
| eval/              |          |
|    mean_ep_length  | 229      |
|    mean_reward     | 59.5     |
| time/              |          |
|    total_timesteps | 185000   |
| train/             |          |
|    actor_loss      | 2.13     |
|    critic_loss     | 1.83     |
|    learning_rate   | 0.000817 |
|    n_updates       | 182682   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 248      |
|    ep_rew_mean     | -5.39    |
| time/              |          |
|    episodes        | 744      |
|    fps             | 21       |
|    time_elapsed    | 8788     |
|    total timesteps | 185192   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 248      |
|    ep_rew_mean     | -3.53    |
| time/              |          |
|    episodes        | 748      |
|    fps             | 21       |
|    time_elapsed    | 8834     |
|    total timesteps | 186196   |
| train/             |          |
|    actor_loss      | 2.14     |
|    critic_loss     | 1.75     |
|    learning_rate   | 0.000816 |
|    n_updates       | 183686   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 248      |
|    ep_rew_mean     | -3.83    |
| time/              |          |
|    episodes        | 752      |
|    fps             | 21       |
|    time_elapsed    | 8879     |
|    total timesteps | 187200   |
| train/             |          |
|    actor_loss      | 2.12     |
|    critic_loss     | 2        |
|    learning_rate   | 0.000815 |
|    n_updates       | 184690   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 248      |
|    ep_rew_mean     | -3.1     |
| time/              |          |
|    episodes        | 756      |
|    fps             | 21       |
|    time_elapsed    | 8925     |
|    total timesteps | 188204   |
| train/             |          |
|    actor_loss      | 2.12     |
|    critic_loss     | 2.32     |
|    learning_rate   | 0.000814 |
|    n_updates       | 185694   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 248      |
|    ep_rew_mean     | -2.37    |
| time/              |          |
|    episodes        | 760      |
|    fps             | 21       |
|    time_elapsed    | 8970     |
|    total timesteps | 189208   |
| train/             |          |
|    actor_loss      | 2.11     |
|    critic_loss     | 1.78     |
|    learning_rate   | 0.000813 |
|    n_updates       | 186698   |
---------------------------------
Eval num_timesteps=190000, episode_reward=61.89 +/- 14.00
Episode length: 224.20 +/- 21.94
---------------------------------
| eval/              |          |
|    mean_ep_length  | 224      |
|    mean_reward     | 61.9     |
| time/              |          |
|    total_timesteps | 190000   |
| train/             |          |
|    actor_loss      | 2.09     |
|    critic_loss     | 1.84     |
|    learning_rate   | 0.000812 |
|    n_updates       | 187636   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 248      |
|    ep_rew_mean     | -2.23    |
| time/              |          |
|    episodes        | 764      |
|    fps             | 21       |
|    time_elapsed    | 9024     |
|    total timesteps | 190146   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 248      |
|    ep_rew_mean     | -2.35    |
| time/              |          |
|    episodes        | 768      |
|    fps             | 21       |
|    time_elapsed    | 9069     |
|    total timesteps | 191150   |
| train/             |          |
|    actor_loss      | 2.06     |
|    critic_loss     | 1.93     |
|    learning_rate   | 0.000811 |
|    n_updates       | 188640   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 248      |
|    ep_rew_mean     | -2.13    |
| time/              |          |
|    episodes        | 772      |
|    fps             | 21       |
|    time_elapsed    | 9114     |
|    total timesteps | 192154   |
| train/             |          |
|    actor_loss      | 2.06     |
|    critic_loss     | 2.02     |
|    learning_rate   | 0.00081  |
|    n_updates       | 189644   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 248      |
|    ep_rew_mean     | -3.23    |
| time/              |          |
|    episodes        | 776      |
|    fps             | 21       |
|    time_elapsed    | 9159     |
|    total timesteps | 193158   |
| train/             |          |
|    actor_loss      | 2.06     |
|    critic_loss     | 1.93     |
|    learning_rate   | 0.000809 |
|    n_updates       | 190648   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 248      |
|    ep_rew_mean     | -3.66    |
| time/              |          |
|    episodes        | 780      |
|    fps             | 21       |
|    time_elapsed    | 9205     |
|    total timesteps | 194162   |
| train/             |          |
|    actor_loss      | 2.05     |
|    critic_loss     | 1.85     |
|    learning_rate   | 0.000808 |
|    n_updates       | 191652   |
---------------------------------
Eval num_timesteps=195000, episode_reward=66.63 +/- 10.22
Episode length: 232.20 +/- 23.03
---------------------------------
| eval/              |          |
|    mean_ep_length  | 232      |
|    mean_reward     | 66.6     |
| time/              |          |
|    total_timesteps | 195000   |
| train/             |          |
|    actor_loss      | 2.02     |
|    critic_loss     | 1.41     |
|    learning_rate   | 0.000807 |
|    n_updates       | 192656   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 248      |
|    ep_rew_mean     | -4.82    |
| time/              |          |
|    episodes        | 784      |
|    fps             | 21       |
|    time_elapsed    | 9262     |
|    total timesteps | 195166   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 248      |
|    ep_rew_mean     | -5.08    |
| time/              |          |
|    episodes        | 788      |
|    fps             | 21       |
|    time_elapsed    | 9307     |
|    total timesteps | 196170   |
| train/             |          |
|    actor_loss      | 2.04     |
|    critic_loss     | 1.98     |
|    learning_rate   | 0.000806 |
|    n_updates       | 193660   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 248      |
|    ep_rew_mean     | -6.79    |
| time/              |          |
|    episodes        | 792      |
|    fps             | 21       |
|    time_elapsed    | 9353     |
|    total timesteps | 197174   |
| train/             |          |
|    actor_loss      | 2.04     |
|    critic_loss     | 1.73     |
|    learning_rate   | 0.000805 |
|    n_updates       | 194664   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 248      |
|    ep_rew_mean     | -6.61    |
| time/              |          |
|    episodes        | 796      |
|    fps             | 21       |
|    time_elapsed    | 9398     |
|    total timesteps | 198178   |
| train/             |          |
|    actor_loss      | 2.04     |
|    critic_loss     | 2        |
|    learning_rate   | 0.000804 |
|    n_updates       | 195668   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 248      |
|    ep_rew_mean     | -6.7     |
| time/              |          |
|    episodes        | 800      |
|    fps             | 21       |
|    time_elapsed    | 9443     |
|    total timesteps | 199182   |
| train/             |          |
|    actor_loss      | 2.04     |
|    critic_loss     | 1.9      |
|    learning_rate   | 0.000803 |
|    n_updates       | 196672   |
---------------------------------
Eval num_timesteps=200000, episode_reward=64.77 +/- 7.31
Episode length: 232.00 +/- 23.53
---------------------------------
| eval/              |          |
|    mean_ep_length  | 232      |
|    mean_reward     | 64.8     |
| time/              |          |
|    total_timesteps | 200000   |
| train/             |          |
|    actor_loss      | 2.04     |
|    critic_loss     | 1.78     |
|    learning_rate   | 0.000802 |
|    n_updates       | 197676   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 248      |
|    ep_rew_mean     | -8.47    |
| time/              |          |
|    episodes        | 804      |
|    fps             | 21       |
|    time_elapsed    | 9500     |
|    total timesteps | 200186   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 248      |
|    ep_rew_mean     | -7.89    |
| time/              |          |
|    episodes        | 808      |
|    fps             | 21       |
|    time_elapsed    | 9546     |
|    total timesteps | 201190   |
| train/             |          |
|    actor_loss      | 2.04     |
|    critic_loss     | 1.91     |
|    learning_rate   | 0.000801 |
|    n_updates       | 198680   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 248      |
|    ep_rew_mean     | -7.08    |
| time/              |          |
|    episodes        | 812      |
|    fps             | 21       |
|    time_elapsed    | 9592     |
|    total timesteps | 202194   |
| train/             |          |
|    actor_loss      | 2.03     |
|    critic_loss     | 1.76     |
|    learning_rate   | 0.0008   |
|    n_updates       | 199684   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -7.28    |
| time/              |          |
|    episodes        | 816      |
|    fps             | 21       |
|    time_elapsed    | 9638     |
|    total timesteps | 203198   |
| train/             |          |
|    actor_loss      | 2.05     |
|    critic_loss     | 1.87     |
|    learning_rate   | 0.000799 |
|    n_updates       | 200688   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -8.22    |
| time/              |          |
|    episodes        | 820      |
|    fps             | 21       |
|    time_elapsed    | 9684     |
|    total timesteps | 204202   |
| train/             |          |
|    actor_loss      | 2.02     |
|    critic_loss     | 1.98     |
|    learning_rate   | 0.000798 |
|    n_updates       | 201692   |
---------------------------------
Eval num_timesteps=205000, episode_reward=61.05 +/- 5.24
Episode length: 240.00 +/- 22.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 240      |
|    mean_reward     | 61       |
| time/              |          |
|    total_timesteps | 205000   |
| train/             |          |
|    actor_loss      | 2.04     |
|    critic_loss     | 2.17     |
|    learning_rate   | 0.000797 |
|    n_updates       | 202696   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -9.05    |
| time/              |          |
|    episodes        | 824      |
|    fps             | 21       |
|    time_elapsed    | 9741     |
|    total timesteps | 205206   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -8.65    |
| time/              |          |
|    episodes        | 828      |
|    fps             | 21       |
|    time_elapsed    | 9787     |
|    total timesteps | 206210   |
| train/             |          |
|    actor_loss      | 2.03     |
|    critic_loss     | 2        |
|    learning_rate   | 0.000796 |
|    n_updates       | 203700   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -8.12    |
| time/              |          |
|    episodes        | 832      |
|    fps             | 21       |
|    time_elapsed    | 9832     |
|    total timesteps | 207204   |
| train/             |          |
|    actor_loss      | 2.02     |
|    critic_loss     | 1.7      |
|    learning_rate   | 0.000795 |
|    n_updates       | 204694   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -6.81    |
| time/              |          |
|    episodes        | 836      |
|    fps             | 21       |
|    time_elapsed    | 9877     |
|    total timesteps | 208208   |
| train/             |          |
|    actor_loss      | 2.01     |
|    critic_loss     | 1.57     |
|    learning_rate   | 0.000794 |
|    n_updates       | 205698   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -6.07    |
| time/              |          |
|    episodes        | 840      |
|    fps             | 21       |
|    time_elapsed    | 9922     |
|    total timesteps | 209212   |
| train/             |          |
|    actor_loss      | 1.98     |
|    critic_loss     | 1.5      |
|    learning_rate   | 0.000793 |
|    n_updates       | 206702   |
---------------------------------
Eval num_timesteps=210000, episode_reward=67.41 +/- 9.10
Episode length: 230.40 +/- 25.47
---------------------------------
| eval/              |          |
|    mean_ep_length  | 230      |
|    mean_reward     | 67.4     |
| time/              |          |
|    total_timesteps | 210000   |
| train/             |          |
|    actor_loss      | 1.98     |
|    critic_loss     | 1.75     |
|    learning_rate   | 0.000792 |
|    n_updates       | 207706   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -5.75    |
| time/              |          |
|    episodes        | 844      |
|    fps             | 21       |
|    time_elapsed    | 9979     |
|    total timesteps | 210216   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -6.88    |
| time/              |          |
|    episodes        | 848      |
|    fps             | 21       |
|    time_elapsed    | 10024    |
|    total timesteps | 211220   |
| train/             |          |
|    actor_loss      | 2.02     |
|    critic_loss     | 1.74     |
|    learning_rate   | 0.000791 |
|    n_updates       | 208710   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -6.82    |
| time/              |          |
|    episodes        | 852      |
|    fps             | 21       |
|    time_elapsed    | 10070    |
|    total timesteps | 212224   |
| train/             |          |
|    actor_loss      | 2.02     |
|    critic_loss     | 2.02     |
|    learning_rate   | 0.00079  |
|    n_updates       | 209714   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -7       |
| time/              |          |
|    episodes        | 856      |
|    fps             | 21       |
|    time_elapsed    | 10115    |
|    total timesteps | 213228   |
| train/             |          |
|    actor_loss      | 2        |
|    critic_loss     | 1.73     |
|    learning_rate   | 0.000789 |
|    n_updates       | 210718   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -7.85    |
| time/              |          |
|    episodes        | 860      |
|    fps             | 21       |
|    time_elapsed    | 10160    |
|    total timesteps | 214232   |
| train/             |          |
|    actor_loss      | 2.03     |
|    critic_loss     | 1.8      |
|    learning_rate   | 0.000788 |
|    n_updates       | 211722   |
---------------------------------
Eval num_timesteps=215000, episode_reward=64.96 +/- 9.09
Episode length: 232.00 +/- 23.29
---------------------------------
| eval/              |          |
|    mean_ep_length  | 232      |
|    mean_reward     | 65       |
| time/              |          |
|    total_timesteps | 215000   |
| train/             |          |
|    actor_loss      | 2.02     |
|    critic_loss     | 1.87     |
|    learning_rate   | 0.000787 |
|    n_updates       | 212726   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -7.66    |
| time/              |          |
|    episodes        | 864      |
|    fps             | 21       |
|    time_elapsed    | 10218    |
|    total timesteps | 215236   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -8.06    |
| time/              |          |
|    episodes        | 868      |
|    fps             | 21       |
|    time_elapsed    | 10261    |
|    total timesteps | 216197   |
| train/             |          |
|    actor_loss      | 1.99     |
|    critic_loss     | 1.49     |
|    learning_rate   | 0.000786 |
|    n_updates       | 213687   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -8.55    |
| time/              |          |
|    episodes        | 872      |
|    fps             | 21       |
|    time_elapsed    | 10306    |
|    total timesteps | 217201   |
| train/             |          |
|    actor_loss      | 2        |
|    critic_loss     | 1.87     |
|    learning_rate   | 0.000785 |
|    n_updates       | 214691   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -7.63    |
| time/              |          |
|    episodes        | 876      |
|    fps             | 21       |
|    time_elapsed    | 10350    |
|    total timesteps | 218192   |
| train/             |          |
|    actor_loss      | 2.04     |
|    critic_loss     | 1.95     |
|    learning_rate   | 0.000784 |
|    n_updates       | 215682   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -7.69    |
| time/              |          |
|    episodes        | 880      |
|    fps             | 21       |
|    time_elapsed    | 10396    |
|    total timesteps | 219196   |
| train/             |          |
|    actor_loss      | 2.02     |
|    critic_loss     | 1.96     |
|    learning_rate   | 0.000783 |
|    n_updates       | 216686   |
---------------------------------
Eval num_timesteps=220000, episode_reward=75.63 +/- 10.27
Episode length: 242.60 +/- 16.80
---------------------------------
| eval/              |          |
|    mean_ep_length  | 243      |
|    mean_reward     | 75.6     |
| time/              |          |
|    total_timesteps | 220000   |
| train/             |          |
|    actor_loss      | 2.06     |
|    critic_loss     | 2.34     |
|    learning_rate   | 0.000782 |
|    n_updates       | 217690   |
---------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -6.45    |
| time/              |          |
|    episodes        | 884      |
|    fps             | 21       |
|    time_elapsed    | 10454    |
|    total timesteps | 220200   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -6.04    |
| time/              |          |
|    episodes        | 888      |
|    fps             | 21       |
|    time_elapsed    | 10500    |
|    total timesteps | 221204   |
| train/             |          |
|    actor_loss      | 2.06     |
|    critic_loss     | 2.44     |
|    learning_rate   | 0.000781 |
|    n_updates       | 218694   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -3.56    |
| time/              |          |
|    episodes        | 892      |
|    fps             | 21       |
|    time_elapsed    | 10545    |
|    total timesteps | 222185   |
| train/             |          |
|    actor_loss      | 2.07     |
|    critic_loss     | 2.32     |
|    learning_rate   | 0.00078  |
|    n_updates       | 219675   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -4.17    |
| time/              |          |
|    episodes        | 896      |
|    fps             | 21       |
|    time_elapsed    | 10590    |
|    total timesteps | 223189   |
| train/             |          |
|    actor_loss      | 2.04     |
|    critic_loss     | 2.12     |
|    learning_rate   | 0.000779 |
|    n_updates       | 220679   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -3.38    |
| time/              |          |
|    episodes        | 900      |
|    fps             | 21       |
|    time_elapsed    | 10636    |
|    total timesteps | 224193   |
| train/             |          |
|    actor_loss      | 2.03     |
|    critic_loss     | 1.82     |
|    learning_rate   | 0.000778 |
|    n_updates       | 221683   |
---------------------------------
Eval num_timesteps=225000, episode_reward=74.57 +/- 13.44
Episode length: 250.20 +/- 1.60
---------------------------------
| eval/              |          |
|    mean_ep_length  | 250      |
|    mean_reward     | 74.6     |
| time/              |          |
|    total_timesteps | 225000   |
| train/             |          |
|    actor_loss      | 2.06     |
|    critic_loss     | 2.43     |
|    learning_rate   | 0.000777 |
|    n_updates       | 222687   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -3.78    |
| time/              |          |
|    episodes        | 904      |
|    fps             | 21       |
|    time_elapsed    | 10695    |
|    total timesteps | 225197   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -4.71    |
| time/              |          |
|    episodes        | 908      |
|    fps             | 21       |
|    time_elapsed    | 10741    |
|    total timesteps | 226201   |
| train/             |          |
|    actor_loss      | 2.05     |
|    critic_loss     | 1.56     |
|    learning_rate   | 0.000776 |
|    n_updates       | 223691   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -4.55    |
| time/              |          |
|    episodes        | 912      |
|    fps             | 21       |
|    time_elapsed    | 10786    |
|    total timesteps | 227133   |
| train/             |          |
|    actor_loss      | 2.03     |
|    critic_loss     | 1.84     |
|    learning_rate   | 0.000775 |
|    n_updates       | 224695   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -5.05    |
| time/              |          |
|    episodes        | 916      |
|    fps             | 21       |
|    time_elapsed    | 10829    |
|    total timesteps | 228117   |
| train/             |          |
|    actor_loss      | 2.04     |
|    critic_loss     | 1.73     |
|    learning_rate   | 0.000774 |
|    n_updates       | 225627   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -3.2     |
| time/              |          |
|    episodes        | 920      |
|    fps             | 21       |
|    time_elapsed    | 10874    |
|    total timesteps | 229121   |
| train/             |          |
|    actor_loss      | 2.03     |
|    critic_loss     | 1.75     |
|    learning_rate   | 0.000773 |
|    n_updates       | 226611   |
---------------------------------
Eval num_timesteps=230000, episode_reward=61.24 +/- 27.07
Episode length: 242.20 +/- 17.60
---------------------------------
| eval/              |          |
|    mean_ep_length  | 242      |
|    mean_reward     | 61.2     |
| time/              |          |
|    total_timesteps | 230000   |
| train/             |          |
|    actor_loss      | 1.99     |
|    critic_loss     | 1.39     |
|    learning_rate   | 0.000772 |
|    n_updates       | 227613   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -2.18    |
| time/              |          |
|    episodes        | 924      |
|    fps             | 21       |
|    time_elapsed    | 10932    |
|    total timesteps | 230123   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -2.17    |
| time/              |          |
|    episodes        | 928      |
|    fps             | 21       |
|    time_elapsed    | 10977    |
|    total timesteps | 231127   |
| train/             |          |
|    actor_loss      | 1.98     |
|    critic_loss     | 1.8      |
|    learning_rate   | 0.000771 |
|    n_updates       | 228617   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -3.33    |
| time/              |          |
|    episodes        | 932      |
|    fps             | 21       |
|    time_elapsed    | 11024    |
|    total timesteps | 232131   |
| train/             |          |
|    actor_loss      | 1.97     |
|    critic_loss     | 1.85     |
|    learning_rate   | 0.00077  |
|    n_updates       | 229621   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -4.03    |
| time/              |          |
|    episodes        | 936      |
|    fps             | 21       |
|    time_elapsed    | 11069    |
|    total timesteps | 233135   |
| train/             |          |
|    actor_loss      | 1.97     |
|    critic_loss     | 1.76     |
|    learning_rate   | 0.000769 |
|    n_updates       | 230625   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -4.65    |
| time/              |          |
|    episodes        | 940      |
|    fps             | 21       |
|    time_elapsed    | 11115    |
|    total timesteps | 234139   |
| train/             |          |
|    actor_loss      | 1.98     |
|    critic_loss     | 1.72     |
|    learning_rate   | 0.000768 |
|    n_updates       | 231629   |
---------------------------------
Eval num_timesteps=235000, episode_reward=72.12 +/- 6.38
Episode length: 251.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 251      |
|    mean_reward     | 72.1     |
| time/              |          |
|    total_timesteps | 235000   |
| train/             |          |
|    actor_loss      | 1.96     |
|    critic_loss     | 2.1      |
|    learning_rate   | 0.000767 |
|    n_updates       | 232633   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -5.79    |
| time/              |          |
|    episodes        | 944      |
|    fps             | 21       |
|    time_elapsed    | 11172    |
|    total timesteps | 235143   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -5.64    |
| time/              |          |
|    episodes        | 948      |
|    fps             | 21       |
|    time_elapsed    | 11217    |
|    total timesteps | 236147   |
| train/             |          |
|    actor_loss      | 1.93     |
|    critic_loss     | 1.38     |
|    learning_rate   | 0.000766 |
|    n_updates       | 233637   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -5.15    |
| time/              |          |
|    episodes        | 952      |
|    fps             | 21       |
|    time_elapsed    | 11263    |
|    total timesteps | 237151   |
| train/             |          |
|    actor_loss      | 1.98     |
|    critic_loss     | 2.02     |
|    learning_rate   | 0.000765 |
|    n_updates       | 234641   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -5.76    |
| time/              |          |
|    episodes        | 956      |
|    fps             | 21       |
|    time_elapsed    | 11308    |
|    total timesteps | 238155   |
| train/             |          |
|    actor_loss      | 2        |
|    critic_loss     | 2.1      |
|    learning_rate   | 0.000764 |
|    n_updates       | 235645   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -4.5     |
| time/              |          |
|    episodes        | 960      |
|    fps             | 21       |
|    time_elapsed    | 11353    |
|    total timesteps | 239159   |
| train/             |          |
|    actor_loss      | 2.01     |
|    critic_loss     | 1.97     |
|    learning_rate   | 0.000763 |
|    n_updates       | 236649   |
---------------------------------
Eval num_timesteps=240000, episode_reward=60.15 +/- 17.92
Episode length: 251.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 251      |
|    mean_reward     | 60.2     |
| time/              |          |
|    total_timesteps | 240000   |
| train/             |          |
|    actor_loss      | 2.01     |
|    critic_loss     | 1.64     |
|    learning_rate   | 0.000762 |
|    n_updates       | 237653   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -4.4     |
| time/              |          |
|    episodes        | 964      |
|    fps             | 21       |
|    time_elapsed    | 11410    |
|    total timesteps | 240163   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -3.19    |
| time/              |          |
|    episodes        | 968      |
|    fps             | 21       |
|    time_elapsed    | 11455    |
|    total timesteps | 241167   |
| train/             |          |
|    actor_loss      | 1.99     |
|    critic_loss     | 1.44     |
|    learning_rate   | 0.000761 |
|    n_updates       | 238657   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -3.18    |
| time/              |          |
|    episodes        | 972      |
|    fps             | 21       |
|    time_elapsed    | 11501    |
|    total timesteps | 242171   |
| train/             |          |
|    actor_loss      | 1.98     |
|    critic_loss     | 1.87     |
|    learning_rate   | 0.00076  |
|    n_updates       | 239661   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -3.48    |
| time/              |          |
|    episodes        | 976      |
|    fps             | 21       |
|    time_elapsed    | 11546    |
|    total timesteps | 243175   |
| train/             |          |
|    actor_loss      | 1.98     |
|    critic_loss     | 2.07     |
|    learning_rate   | 0.00076  |
|    n_updates       | 240665   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -2.86    |
| time/              |          |
|    episodes        | 980      |
|    fps             | 21       |
|    time_elapsed    | 11590    |
|    total timesteps | 244109   |
| train/             |          |
|    actor_loss      | 1.96     |
|    critic_loss     | 1.82     |
|    learning_rate   | 0.000759 |
|    n_updates       | 241628   |
---------------------------------
Eval num_timesteps=245000, episode_reward=47.58 +/- 27.11
Episode length: 249.80 +/- 2.40
---------------------------------
| eval/              |          |
|    mean_ep_length  | 250      |
|    mean_reward     | 47.6     |
| time/              |          |
|    total_timesteps | 245000   |
| train/             |          |
|    actor_loss      | 1.95     |
|    critic_loss     | 2.02     |
|    learning_rate   | 0.000758 |
|    n_updates       | 242560   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -1.94    |
| time/              |          |
|    episodes        | 984      |
|    fps             | 21       |
|    time_elapsed    | 11644    |
|    total timesteps | 245070   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -1.98    |
| time/              |          |
|    episodes        | 988      |
|    fps             | 21       |
|    time_elapsed    | 11690    |
|    total timesteps | 246074   |
| train/             |          |
|    actor_loss      | 1.92     |
|    critic_loss     | 1.8      |
|    learning_rate   | 0.000757 |
|    n_updates       | 243564   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -3.61    |
| time/              |          |
|    episodes        | 992      |
|    fps             | 21       |
|    time_elapsed    | 11735    |
|    total timesteps | 247078   |
| train/             |          |
|    actor_loss      | 1.97     |
|    critic_loss     | 2.1      |
|    learning_rate   | 0.000756 |
|    n_updates       | 244568   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -3.31    |
| time/              |          |
|    episodes        | 996      |
|    fps             | 21       |
|    time_elapsed    | 11780    |
|    total timesteps | 248082   |
| train/             |          |
|    actor_loss      | 1.96     |
|    critic_loss     | 1.98     |
|    learning_rate   | 0.000755 |
|    n_updates       | 245572   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -3.59    |
| time/              |          |
|    episodes        | 1000     |
|    fps             | 21       |
|    time_elapsed    | 11826    |
|    total timesteps | 249086   |
| train/             |          |
|    actor_loss      | 1.96     |
|    critic_loss     | 1.9      |
|    learning_rate   | 0.000754 |
|    n_updates       | 246576   |
---------------------------------
Eval num_timesteps=250000, episode_reward=68.36 +/- 9.05
Episode length: 241.40 +/- 19.20
---------------------------------
| eval/              |          |
|    mean_ep_length  | 241      |
|    mean_reward     | 68.4     |
| time/              |          |
|    total_timesteps | 250000   |
| train/             |          |
|    actor_loss      | 1.95     |
|    critic_loss     | 2.06     |
|    learning_rate   | 0.000753 |
|    n_updates       | 247580   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -2.2     |
| time/              |          |
|    episodes        | 1004     |
|    fps             | 21       |
|    time_elapsed    | 11883    |
|    total timesteps | 250090   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -2.65    |
| time/              |          |
|    episodes        | 1008     |
|    fps             | 21       |
|    time_elapsed    | 11928    |
|    total timesteps | 251094   |
| train/             |          |
|    actor_loss      | 1.94     |
|    critic_loss     | 2.07     |
|    learning_rate   | 0.000752 |
|    n_updates       | 248584   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -3.8     |
| time/              |          |
|    episodes        | 1012     |
|    fps             | 21       |
|    time_elapsed    | 11972    |
|    total timesteps | 252098   |
| train/             |          |
|    actor_loss      | 1.93     |
|    critic_loss     | 1.68     |
|    learning_rate   | 0.000751 |
|    n_updates       | 249588   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -3.93    |
| time/              |          |
|    episodes        | 1016     |
|    fps             | 21       |
|    time_elapsed    | 12019    |
|    total timesteps | 253102   |
| train/             |          |
|    actor_loss      | 1.89     |
|    critic_loss     | 1.89     |
|    learning_rate   | 0.00075  |
|    n_updates       | 250592   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -5.81    |
| time/              |          |
|    episodes        | 1020     |
|    fps             | 21       |
|    time_elapsed    | 12064    |
|    total timesteps | 254106   |
| train/             |          |
|    actor_loss      | 1.89     |
|    critic_loss     | 1.73     |
|    learning_rate   | 0.000749 |
|    n_updates       | 251596   |
---------------------------------
Eval num_timesteps=255000, episode_reward=70.15 +/- 15.09
Episode length: 250.00 +/- 2.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 250      |
|    mean_reward     | 70.2     |
| time/              |          |
|    total_timesteps | 255000   |
| train/             |          |
|    actor_loss      | 1.9      |
|    critic_loss     | 1.93     |
|    learning_rate   | 0.000748 |
|    n_updates       | 252600   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -6.71    |
| time/              |          |
|    episodes        | 1024     |
|    fps             | 21       |
|    time_elapsed    | 12121    |
|    total timesteps | 255110   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -6.2     |
| time/              |          |
|    episodes        | 1028     |
|    fps             | 21       |
|    time_elapsed    | 12167    |
|    total timesteps | 256114   |
| train/             |          |
|    actor_loss      | 1.87     |
|    critic_loss     | 1.47     |
|    learning_rate   | 0.000747 |
|    n_updates       | 253604   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -5.98    |
| time/              |          |
|    episodes        | 1032     |
|    fps             | 21       |
|    time_elapsed    | 12212    |
|    total timesteps | 257118   |
| train/             |          |
|    actor_loss      | 1.84     |
|    critic_loss     | 1.34     |
|    learning_rate   | 0.000746 |
|    n_updates       | 254608   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -5.34    |
| time/              |          |
|    episodes        | 1036     |
|    fps             | 21       |
|    time_elapsed    | 12253    |
|    total timesteps | 258012   |
| train/             |          |
|    actor_loss      | 1.87     |
|    critic_loss     | 2.06     |
|    learning_rate   | 0.000745 |
|    n_updates       | 255502   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -5.11    |
| time/              |          |
|    episodes        | 1040     |
|    fps             | 21       |
|    time_elapsed    | 12298    |
|    total timesteps | 259016   |
| train/             |          |
|    actor_loss      | 1.85     |
|    critic_loss     | 1.76     |
|    learning_rate   | 0.000744 |
|    n_updates       | 256506   |
---------------------------------
Eval num_timesteps=260000, episode_reward=77.28 +/- 7.09
Episode length: 251.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 251      |
|    mean_reward     | 77.3     |
| time/              |          |
|    total_timesteps | 260000   |
| train/             |          |
|    actor_loss      | 1.83     |
|    critic_loss     | 1.9      |
|    learning_rate   | 0.000743 |
|    n_updates       | 257510   |
---------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -5.36    |
| time/              |          |
|    episodes        | 1044     |
|    fps             | 21       |
|    time_elapsed    | 12356    |
|    total timesteps | 260020   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -6.42    |
| time/              |          |
|    episodes        | 1048     |
|    fps             | 21       |
|    time_elapsed    | 12401    |
|    total timesteps | 261024   |
| train/             |          |
|    actor_loss      | 1.86     |
|    critic_loss     | 1.8      |
|    learning_rate   | 0.000742 |
|    n_updates       | 258514   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -5.99    |
| time/              |          |
|    episodes        | 1052     |
|    fps             | 21       |
|    time_elapsed    | 12446    |
|    total timesteps | 262028   |
| train/             |          |
|    actor_loss      | 1.86     |
|    critic_loss     | 1.74     |
|    learning_rate   | 0.000741 |
|    n_updates       | 259518   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -5.5     |
| time/              |          |
|    episodes        | 1056     |
|    fps             | 21       |
|    time_elapsed    | 12491    |
|    total timesteps | 263032   |
| train/             |          |
|    actor_loss      | 1.85     |
|    critic_loss     | 1.83     |
|    learning_rate   | 0.00074  |
|    n_updates       | 260522   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -6.58    |
| time/              |          |
|    episodes        | 1060     |
|    fps             | 21       |
|    time_elapsed    | 12536    |
|    total timesteps | 264036   |
| train/             |          |
|    actor_loss      | 1.86     |
|    critic_loss     | 1.81     |
|    learning_rate   | 0.000739 |
|    n_updates       | 261526   |
---------------------------------
Eval num_timesteps=265000, episode_reward=62.39 +/- 12.82
Episode length: 218.80 +/- 26.32
---------------------------------
| eval/              |          |
|    mean_ep_length  | 219      |
|    mean_reward     | 62.4     |
| time/              |          |
|    total_timesteps | 265000   |
| train/             |          |
|    actor_loss      | 1.87     |
|    critic_loss     | 1.93     |
|    learning_rate   | 0.000738 |
|    n_updates       | 262530   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -7.73    |
| time/              |          |
|    episodes        | 1064     |
|    fps             | 21       |
|    time_elapsed    | 12591    |
|    total timesteps | 265040   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -8.38    |
| time/              |          |
|    episodes        | 1068     |
|    fps             | 21       |
|    time_elapsed    | 12636    |
|    total timesteps | 266044   |
| train/             |          |
|    actor_loss      | 1.86     |
|    critic_loss     | 1.67     |
|    learning_rate   | 0.000737 |
|    n_updates       | 263534   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -7.98    |
| time/              |          |
|    episodes        | 1072     |
|    fps             | 21       |
|    time_elapsed    | 12682    |
|    total timesteps | 267048   |
| train/             |          |
|    actor_loss      | 1.86     |
|    critic_loss     | 2.07     |
|    learning_rate   | 0.000736 |
|    n_updates       | 264538   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -7.67    |
| time/              |          |
|    episodes        | 1076     |
|    fps             | 21       |
|    time_elapsed    | 12727    |
|    total timesteps | 268045   |
| train/             |          |
|    actor_loss      | 1.88     |
|    critic_loss     | 2.13     |
|    learning_rate   | 0.000735 |
|    n_updates       | 265542   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -8.5     |
| time/              |          |
|    episodes        | 1080     |
|    fps             | 21       |
|    time_elapsed    | 12772    |
|    total timesteps | 269049   |
| train/             |          |
|    actor_loss      | 1.88     |
|    critic_loss     | 1.98     |
|    learning_rate   | 0.000734 |
|    n_updates       | 266539   |
---------------------------------
Eval num_timesteps=270000, episode_reward=65.78 +/- 7.57
Episode length: 239.60 +/- 22.80
---------------------------------
| eval/              |          |
|    mean_ep_length  | 240      |
|    mean_reward     | 65.8     |
| time/              |          |
|    total_timesteps | 270000   |
| train/             |          |
|    actor_loss      | 1.9      |
|    critic_loss     | 2.22     |
|    learning_rate   | 0.000733 |
|    n_updates       | 267543   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -9.65    |
| time/              |          |
|    episodes        | 1084     |
|    fps             | 21       |
|    time_elapsed    | 12830    |
|    total timesteps | 270053   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -9.32    |
| time/              |          |
|    episodes        | 1088     |
|    fps             | 21       |
|    time_elapsed    | 12875    |
|    total timesteps | 271057   |
| train/             |          |
|    actor_loss      | 1.86     |
|    critic_loss     | 1.65     |
|    learning_rate   | 0.000732 |
|    n_updates       | 268547   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -8.16    |
| time/              |          |
|    episodes        | 1092     |
|    fps             | 21       |
|    time_elapsed    | 12919    |
|    total timesteps | 272012   |
| train/             |          |
|    actor_loss      | 1.85     |
|    critic_loss     | 1.54     |
|    learning_rate   | 0.000731 |
|    n_updates       | 269542   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -7.34    |
| time/              |          |
|    episodes        | 1096     |
|    fps             | 21       |
|    time_elapsed    | 12963    |
|    total timesteps | 273016   |
| train/             |          |
|    actor_loss      | 1.84     |
|    critic_loss     | 2.02     |
|    learning_rate   | 0.00073  |
|    n_updates       | 270506   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -7.4     |
| time/              |          |
|    episodes        | 1100     |
|    fps             | 21       |
|    time_elapsed    | 13009    |
|    total timesteps | 274020   |
| train/             |          |
|    actor_loss      | 1.84     |
|    critic_loss     | 1.84     |
|    learning_rate   | 0.000729 |
|    n_updates       | 271510   |
---------------------------------
Eval num_timesteps=275000, episode_reward=65.16 +/- 30.53
Episode length: 250.20 +/- 1.60
---------------------------------
| eval/              |          |
|    mean_ep_length  | 250      |
|    mean_reward     | 65.2     |
| time/              |          |
|    total_timesteps | 275000   |
| train/             |          |
|    actor_loss      | 1.81     |
|    critic_loss     | 1.58     |
|    learning_rate   | 0.000728 |
|    n_updates       | 272514   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -7.73    |
| time/              |          |
|    episodes        | 1104     |
|    fps             | 21       |
|    time_elapsed    | 13067    |
|    total timesteps | 275004   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -7.5     |
| time/              |          |
|    episodes        | 1108     |
|    fps             | 21       |
|    time_elapsed    | 13112    |
|    total timesteps | 276008   |
| train/             |          |
|    actor_loss      | 1.82     |
|    critic_loss     | 1.8      |
|    learning_rate   | 0.000727 |
|    n_updates       | 273498   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -6.93    |
| time/              |          |
|    episodes        | 1112     |
|    fps             | 21       |
|    time_elapsed    | 13157    |
|    total timesteps | 277001   |
| train/             |          |
|    actor_loss      | 1.79     |
|    critic_loss     | 1.49     |
|    learning_rate   | 0.000726 |
|    n_updates       | 274502   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -6.99    |
| time/              |          |
|    episodes        | 1116     |
|    fps             | 21       |
|    time_elapsed    | 13202    |
|    total timesteps | 278005   |
| train/             |          |
|    actor_loss      | 1.81     |
|    critic_loss     | 1.92     |
|    learning_rate   | 0.000725 |
|    n_updates       | 275495   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -6.98    |
| time/              |          |
|    episodes        | 1120     |
|    fps             | 21       |
|    time_elapsed    | 13246    |
|    total timesteps | 279009   |
| train/             |          |
|    actor_loss      | 1.83     |
|    critic_loss     | 2.06     |
|    learning_rate   | 0.000724 |
|    n_updates       | 276499   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -5.65    |
| time/              |          |
|    episodes        | 1124     |
|    fps             | 21       |
|    time_elapsed    | 13290    |
|    total timesteps | 279991   |
| train/             |          |
|    actor_loss      | 1.82     |
|    critic_loss     | 1.93     |
|    learning_rate   | 0.000723 |
|    n_updates       | 277481   |
---------------------------------
Eval num_timesteps=280000, episode_reward=71.42 +/- 11.32
Episode length: 240.40 +/- 21.20
---------------------------------
| eval/              |          |
|    mean_ep_length  | 240      |
|    mean_reward     | 71.4     |
| time/              |          |
|    total_timesteps | 280000   |
| train/             |          |
|    actor_loss      | 1.83     |
|    critic_loss     | 1.92     |
|    learning_rate   | 0.000723 |
|    n_updates       | 277732   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -6.69    |
| time/              |          |
|    episodes        | 1128     |
|    fps             | 21       |
|    time_elapsed    | 13348    |
|    total timesteps | 280995   |
| train/             |          |
|    actor_loss      | 1.83     |
|    critic_loss     | 1.84     |
|    learning_rate   | 0.000722 |
|    n_updates       | 278485   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -6.62    |
| time/              |          |
|    episodes        | 1132     |
|    fps             | 21       |
|    time_elapsed    | 13394    |
|    total timesteps | 281999   |
| train/             |          |
|    actor_loss      | 1.85     |
|    critic_loss     | 2.19     |
|    learning_rate   | 0.000721 |
|    n_updates       | 279489   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -7.5     |
| time/              |          |
|    episodes        | 1136     |
|    fps             | 21       |
|    time_elapsed    | 13439    |
|    total timesteps | 283003   |
| train/             |          |
|    actor_loss      | 1.84     |
|    critic_loss     | 1.96     |
|    learning_rate   | 0.00072  |
|    n_updates       | 280493   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -8.24    |
| time/              |          |
|    episodes        | 1140     |
|    fps             | 21       |
|    time_elapsed    | 13484    |
|    total timesteps | 284007   |
| train/             |          |
|    actor_loss      | 1.82     |
|    critic_loss     | 1.75     |
|    learning_rate   | 0.000719 |
|    n_updates       | 281497   |
---------------------------------
Eval num_timesteps=285000, episode_reward=67.88 +/- 11.94
Episode length: 232.60 +/- 22.68
---------------------------------
| eval/              |          |
|    mean_ep_length  | 233      |
|    mean_reward     | 67.9     |
| time/              |          |
|    total_timesteps | 285000   |
| train/             |          |
|    actor_loss      | 1.84     |
|    critic_loss     | 1.79     |
|    learning_rate   | 0.000718 |
|    n_updates       | 282501   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -8.09    |
| time/              |          |
|    episodes        | 1144     |
|    fps             | 21       |
|    time_elapsed    | 13541    |
|    total timesteps | 285011   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -7.54    |
| time/              |          |
|    episodes        | 1148     |
|    fps             | 21       |
|    time_elapsed    | 13585    |
|    total timesteps | 286015   |
| train/             |          |
|    actor_loss      | 1.83     |
|    critic_loss     | 1.63     |
|    learning_rate   | 0.000717 |
|    n_updates       | 283505   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -8       |
| time/              |          |
|    episodes        | 1152     |
|    fps             | 21       |
|    time_elapsed    | 13631    |
|    total timesteps | 287019   |
| train/             |          |
|    actor_loss      | 1.82     |
|    critic_loss     | 1.82     |
|    learning_rate   | 0.000716 |
|    n_updates       | 284509   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -8.51    |
| time/              |          |
|    episodes        | 1156     |
|    fps             | 21       |
|    time_elapsed    | 13677    |
|    total timesteps | 288023   |
| train/             |          |
|    actor_loss      | 1.82     |
|    critic_loss     | 1.86     |
|    learning_rate   | 0.000715 |
|    n_updates       | 285513   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -7.95    |
| time/              |          |
|    episodes        | 1160     |
|    fps             | 21       |
|    time_elapsed    | 13722    |
|    total timesteps | 289007   |
| train/             |          |
|    actor_loss      | 1.83     |
|    critic_loss     | 2.02     |
|    learning_rate   | 0.000714 |
|    n_updates       | 286497   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -7.05    |
| time/              |          |
|    episodes        | 1164     |
|    fps             | 21       |
|    time_elapsed    | 13765    |
|    total timesteps | 289961   |
| train/             |          |
|    actor_loss      | 1.85     |
|    critic_loss     | 2.16     |
|    learning_rate   | 0.000713 |
|    n_updates       | 287451   |
---------------------------------
Eval num_timesteps=290000, episode_reward=67.07 +/- 7.06
Episode length: 227.20 +/- 29.15
---------------------------------
| eval/              |          |
|    mean_ep_length  | 227      |
|    mean_reward     | 67.1     |
| time/              |          |
|    total_timesteps | 290000   |
| train/             |          |
|    actor_loss      | 1.84     |
|    critic_loss     | 1.79     |
|    learning_rate   | 0.000713 |
|    n_updates       | 287702   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -7.06    |
| time/              |          |
|    episodes        | 1168     |
|    fps             | 21       |
|    time_elapsed    | 13823    |
|    total timesteps | 290965   |
| train/             |          |
|    actor_loss      | 1.85     |
|    critic_loss     | 1.9      |
|    learning_rate   | 0.000712 |
|    n_updates       | 288455   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -7.59    |
| time/              |          |
|    episodes        | 1172     |
|    fps             | 21       |
|    time_elapsed    | 13869    |
|    total timesteps | 291969   |
| train/             |          |
|    actor_loss      | 1.85     |
|    critic_loss     | 2.07     |
|    learning_rate   | 0.000711 |
|    n_updates       | 289459   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -8.53    |
| time/              |          |
|    episodes        | 1176     |
|    fps             | 21       |
|    time_elapsed    | 13915    |
|    total timesteps | 292973   |
| train/             |          |
|    actor_loss      | 1.87     |
|    critic_loss     | 2.05     |
|    learning_rate   | 0.00071  |
|    n_updates       | 290463   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 248      |
|    ep_rew_mean     | -6.8     |
| time/              |          |
|    episodes        | 1180     |
|    fps             | 21       |
|    time_elapsed    | 13956    |
|    total timesteps | 293866   |
| train/             |          |
|    actor_loss      | 1.88     |
|    critic_loss     | 1.99     |
|    learning_rate   | 0.000709 |
|    n_updates       | 291356   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 248      |
|    ep_rew_mean     | -8.41    |
| time/              |          |
|    episodes        | 1184     |
|    fps             | 21       |
|    time_elapsed    | 14001    |
|    total timesteps | 294870   |
| train/             |          |
|    actor_loss      | 1.88     |
|    critic_loss     | 2.19     |
|    learning_rate   | 0.000708 |
|    n_updates       | 292360   |
---------------------------------
Eval num_timesteps=295000, episode_reward=57.09 +/- 12.98
Episode length: 231.80 +/- 23.93
---------------------------------
| eval/              |          |
|    mean_ep_length  | 232      |
|    mean_reward     | 57.1     |
| time/              |          |
|    total_timesteps | 295000   |
| train/             |          |
|    actor_loss      | 1.91     |
|    critic_loss     | 2.23     |
|    learning_rate   | 0.000708 |
|    n_updates       | 292611   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 248      |
|    ep_rew_mean     | -8.57    |
| time/              |          |
|    episodes        | 1188     |
|    fps             | 21       |
|    time_elapsed    | 14059    |
|    total timesteps | 295874   |
| train/             |          |
|    actor_loss      | 1.94     |
|    critic_loss     | 1.85     |
|    learning_rate   | 0.000707 |
|    n_updates       | 293364   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -10.1    |
| time/              |          |
|    episodes        | 1192     |
|    fps             | 21       |
|    time_elapsed    | 14105    |
|    total timesteps | 296878   |
| train/             |          |
|    actor_loss      | 1.94     |
|    critic_loss     | 1.81     |
|    learning_rate   | 0.000706 |
|    n_updates       | 294368   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 248      |
|    ep_rew_mean     | -10.8    |
| time/              |          |
|    episodes        | 1196     |
|    fps             | 21       |
|    time_elapsed    | 14149    |
|    total timesteps | 297859   |
| train/             |          |
|    actor_loss      | 1.92     |
|    critic_loss     | 1.93     |
|    learning_rate   | 0.000705 |
|    n_updates       | 295349   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 248      |
|    ep_rew_mean     | -9.77    |
| time/              |          |
|    episodes        | 1200     |
|    fps             | 21       |
|    time_elapsed    | 14195    |
|    total timesteps | 298863   |
| train/             |          |
|    actor_loss      | 1.95     |
|    critic_loss     | 1.8      |
|    learning_rate   | 0.000704 |
|    n_updates       | 296353   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -10.2    |
| time/              |          |
|    episodes        | 1204     |
|    fps             | 21       |
|    time_elapsed    | 14241    |
|    total timesteps | 299867   |
| train/             |          |
|    actor_loss      | 1.93     |
|    critic_loss     | 2.17     |
|    learning_rate   | 0.000703 |
|    n_updates       | 297357   |
---------------------------------
Eval num_timesteps=300000, episode_reward=69.91 +/- 5.11
Episode length: 251.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 251      |
|    mean_reward     | 69.9     |
| time/              |          |
|    total_timesteps | 300000   |
| train/             |          |
|    actor_loss      | 1.92     |
|    critic_loss     | 1.96     |
|    learning_rate   | 0.000703 |
|    n_updates       | 297608   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -9.18    |
| time/              |          |
|    episodes        | 1208     |
|    fps             | 21       |
|    time_elapsed    | 14300    |
|    total timesteps | 300871   |
| train/             |          |
|    actor_loss      | 1.91     |
|    critic_loss     | 1.74     |
|    learning_rate   | 0.000702 |
|    n_updates       | 298361   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -9.43    |
| time/              |          |
|    episodes        | 1212     |
|    fps             | 21       |
|    time_elapsed    | 14346    |
|    total timesteps | 301875   |
| train/             |          |
|    actor_loss      | 1.9      |
|    critic_loss     | 2.17     |
|    learning_rate   | 0.000701 |
|    n_updates       | 299365   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -8.98    |
| time/              |          |
|    episodes        | 1216     |
|    fps             | 21       |
|    time_elapsed    | 14392    |
|    total timesteps | 302879   |
| train/             |          |
|    actor_loss      | 1.92     |
|    critic_loss     | 2        |
|    learning_rate   | 0.0007   |
|    n_updates       | 300369   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -9.41    |
| time/              |          |
|    episodes        | 1220     |
|    fps             | 21       |
|    time_elapsed    | 14437    |
|    total timesteps | 303883   |
| train/             |          |
|    actor_loss      | 1.91     |
|    critic_loss     | 1.47     |
|    learning_rate   | 0.000699 |
|    n_updates       | 301373   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -10.5    |
| time/              |          |
|    episodes        | 1224     |
|    fps             | 21       |
|    time_elapsed    | 14483    |
|    total timesteps | 304887   |
| train/             |          |
|    actor_loss      | 1.92     |
|    critic_loss     | 1.85     |
|    learning_rate   | 0.000698 |
|    n_updates       | 302377   |
---------------------------------
Eval num_timesteps=305000, episode_reward=57.64 +/- 24.00
Episode length: 251.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 251      |
|    mean_reward     | 57.6     |
| time/              |          |
|    total_timesteps | 305000   |
| train/             |          |
|    actor_loss      | 1.92     |
|    critic_loss     | 1.87     |
|    learning_rate   | 0.000698 |
|    n_updates       | 302628   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -10.4    |
| time/              |          |
|    episodes        | 1228     |
|    fps             | 21       |
|    time_elapsed    | 14541    |
|    total timesteps | 305891   |
| train/             |          |
|    actor_loss      | 1.91     |
|    critic_loss     | 1.52     |
|    learning_rate   | 0.000697 |
|    n_updates       | 303381   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -9.64    |
| time/              |          |
|    episodes        | 1232     |
|    fps             | 21       |
|    time_elapsed    | 14586    |
|    total timesteps | 306851   |
| train/             |          |
|    actor_loss      | 1.93     |
|    critic_loss     | 1.63     |
|    learning_rate   | 0.000696 |
|    n_updates       | 304385   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -8.64    |
| time/              |          |
|    episodes        | 1236     |
|    fps             | 21       |
|    time_elapsed    | 14631    |
|    total timesteps | 307855   |
| train/             |          |
|    actor_loss      | 1.94     |
|    critic_loss     | 2.12     |
|    learning_rate   | 0.000695 |
|    n_updates       | 305345   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -7.31    |
| time/              |          |
|    episodes        | 1240     |
|    fps             | 21       |
|    time_elapsed    | 14677    |
|    total timesteps | 308859   |
| train/             |          |
|    actor_loss      | 1.94     |
|    critic_loss     | 2.02     |
|    learning_rate   | 0.000694 |
|    n_updates       | 306349   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -7.84    |
| time/              |          |
|    episodes        | 1244     |
|    fps             | 21       |
|    time_elapsed    | 14723    |
|    total timesteps | 309863   |
| train/             |          |
|    actor_loss      | 1.94     |
|    critic_loss     | 1.67     |
|    learning_rate   | 0.000693 |
|    n_updates       | 307353   |
---------------------------------
Eval num_timesteps=310000, episode_reward=63.39 +/- 5.82
Episode length: 240.00 +/- 22.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 240      |
|    mean_reward     | 63.4     |
| time/              |          |
|    total_timesteps | 310000   |
| train/             |          |
|    actor_loss      | 1.95     |
|    critic_loss     | 1.82     |
|    learning_rate   | 0.000693 |
|    n_updates       | 307604   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 248      |
|    ep_rew_mean     | -6.53    |
| time/              |          |
|    episodes        | 1248     |
|    fps             | 21       |
|    time_elapsed    | 14781    |
|    total timesteps | 310845   |
| train/             |          |
|    actor_loss      | 1.94     |
|    critic_loss     | 1.9      |
|    learning_rate   | 0.000692 |
|    n_updates       | 308357   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 248      |
|    ep_rew_mean     | -6.59    |
| time/              |          |
|    episodes        | 1252     |
|    fps             | 21       |
|    time_elapsed    | 14824    |
|    total timesteps | 311817   |
| train/             |          |
|    actor_loss      | 1.93     |
|    critic_loss     | 1.67     |
|    learning_rate   | 0.000692 |
|    n_updates       | 309307   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 248      |
|    ep_rew_mean     | -5.58    |
| time/              |          |
|    episodes        | 1256     |
|    fps             | 21       |
|    time_elapsed    | 14867    |
|    total timesteps | 312784   |
| train/             |          |
|    actor_loss      | 1.94     |
|    critic_loss     | 2.07     |
|    learning_rate   | 0.000691 |
|    n_updates       | 310274   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 248      |
|    ep_rew_mean     | -6.4     |
| time/              |          |
|    episodes        | 1260     |
|    fps             | 21       |
|    time_elapsed    | 14913    |
|    total timesteps | 313788   |
| train/             |          |
|    actor_loss      | 1.92     |
|    critic_loss     | 1.86     |
|    learning_rate   | 0.00069  |
|    n_updates       | 311278   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 248      |
|    ep_rew_mean     | -7.53    |
| time/              |          |
|    episodes        | 1264     |
|    fps             | 21       |
|    time_elapsed    | 14958    |
|    total timesteps | 314792   |
| train/             |          |
|    actor_loss      | 1.91     |
|    critic_loss     | 1.95     |
|    learning_rate   | 0.000689 |
|    n_updates       | 312282   |
---------------------------------
Eval num_timesteps=315000, episode_reward=61.21 +/- 10.51
Episode length: 243.00 +/- 16.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 243      |
|    mean_reward     | 61.2     |
| time/              |          |
|    total_timesteps | 315000   |
| train/             |          |
|    actor_loss      | 1.93     |
|    critic_loss     | 2.05     |
|    learning_rate   | 0.000688 |
|    n_updates       | 312533   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 248      |
|    ep_rew_mean     | -7.29    |
| time/              |          |
|    episodes        | 1268     |
|    fps             | 21       |
|    time_elapsed    | 15015    |
|    total timesteps | 315796   |
| train/             |          |
|    actor_loss      | 1.91     |
|    critic_loss     | 1.88     |
|    learning_rate   | 0.000688 |
|    n_updates       | 313286   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 248      |
|    ep_rew_mean     | -6.96    |
| time/              |          |
|    episodes        | 1272     |
|    fps             | 21       |
|    time_elapsed    | 15061    |
|    total timesteps | 316800   |
| train/             |          |
|    actor_loss      | 1.89     |
|    critic_loss     | 1.28     |
|    learning_rate   | 0.000687 |
|    n_updates       | 314290   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 248      |
|    ep_rew_mean     | -6.69    |
| time/              |          |
|    episodes        | 1276     |
|    fps             | 21       |
|    time_elapsed    | 15106    |
|    total timesteps | 317804   |
| train/             |          |
|    actor_loss      | 1.88     |
|    critic_loss     | 1.94     |
|    learning_rate   | 0.000686 |
|    n_updates       | 315294   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -8.16    |
| time/              |          |
|    episodes        | 1280     |
|    fps             | 21       |
|    time_elapsed    | 15152    |
|    total timesteps | 318808   |
| train/             |          |
|    actor_loss      | 1.88     |
|    critic_loss     | 1.68     |
|    learning_rate   | 0.000685 |
|    n_updates       | 316298   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -7.76    |
| time/              |          |
|    episodes        | 1284     |
|    fps             | 21       |
|    time_elapsed    | 15197    |
|    total timesteps | 319812   |
| train/             |          |
|    actor_loss      | 1.88     |
|    critic_loss     | 2.08     |
|    learning_rate   | 0.000684 |
|    n_updates       | 317302   |
---------------------------------
Eval num_timesteps=320000, episode_reward=70.52 +/- 4.05
Episode length: 251.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 251      |
|    mean_reward     | 70.5     |
| time/              |          |
|    total_timesteps | 320000   |
| train/             |          |
|    actor_loss      | 1.88     |
|    critic_loss     | 1.74     |
|    learning_rate   | 0.000683 |
|    n_updates       | 317553   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -7.68    |
| time/              |          |
|    episodes        | 1288     |
|    fps             | 21       |
|    time_elapsed    | 15256    |
|    total timesteps | 320816   |
| train/             |          |
|    actor_loss      | 1.91     |
|    critic_loss     | 2.47     |
|    learning_rate   | 0.000683 |
|    n_updates       | 318306   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -7.89    |
| time/              |          |
|    episodes        | 1292     |
|    fps             | 21       |
|    time_elapsed    | 15302    |
|    total timesteps | 321820   |
| train/             |          |
|    actor_loss      | 1.93     |
|    critic_loss     | 2.13     |
|    learning_rate   | 0.000682 |
|    n_updates       | 319310   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -8.64    |
| time/              |          |
|    episodes        | 1296     |
|    fps             | 21       |
|    time_elapsed    | 15347    |
|    total timesteps | 322824   |
| train/             |          |
|    actor_loss      | 1.93     |
|    critic_loss     | 1.91     |
|    learning_rate   | 0.000681 |
|    n_updates       | 320314   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -9.83    |
| time/              |          |
|    episodes        | 1300     |
|    fps             | 21       |
|    time_elapsed    | 15393    |
|    total timesteps | 323828   |
| train/             |          |
|    actor_loss      | 1.93     |
|    critic_loss     | 2.12     |
|    learning_rate   | 0.00068  |
|    n_updates       | 321318   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -9.85    |
| time/              |          |
|    episodes        | 1304     |
|    fps             | 21       |
|    time_elapsed    | 15438    |
|    total timesteps | 324832   |
| train/             |          |
|    actor_loss      | 1.96     |
|    critic_loss     | 1.71     |
|    learning_rate   | 0.000679 |
|    n_updates       | 322322   |
---------------------------------
Eval num_timesteps=325000, episode_reward=48.81 +/- 18.51
Episode length: 241.60 +/- 18.80
---------------------------------
| eval/              |          |
|    mean_ep_length  | 242      |
|    mean_reward     | 48.8     |
| time/              |          |
|    total_timesteps | 325000   |
| train/             |          |
|    actor_loss      | 1.93     |
|    critic_loss     | 1.66     |
|    learning_rate   | 0.000678 |
|    n_updates       | 322573   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -10.2    |
| time/              |          |
|    episodes        | 1308     |
|    fps             | 21       |
|    time_elapsed    | 15495    |
|    total timesteps | 325807   |
| train/             |          |
|    actor_loss      | 1.96     |
|    critic_loss     | 2.03     |
|    learning_rate   | 0.000678 |
|    n_updates       | 323326   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -9.4     |
| time/              |          |
|    episodes        | 1312     |
|    fps             | 21       |
|    time_elapsed    | 15539    |
|    total timesteps | 326799   |
| train/             |          |
|    actor_loss      | 1.97     |
|    critic_loss     | 2.18     |
|    learning_rate   | 0.000677 |
|    n_updates       | 324289   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -10.7    |
| time/              |          |
|    episodes        | 1316     |
|    fps             | 21       |
|    time_elapsed    | 15586    |
|    total timesteps | 327803   |
| train/             |          |
|    actor_loss      | 1.97     |
|    critic_loss     | 1.71     |
|    learning_rate   | 0.000676 |
|    n_updates       | 325293   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -10.6    |
| time/              |          |
|    episodes        | 1320     |
|    fps             | 21       |
|    time_elapsed    | 15632    |
|    total timesteps | 328807   |
| train/             |          |
|    actor_loss      | 1.98     |
|    critic_loss     | 1.82     |
|    learning_rate   | 0.000675 |
|    n_updates       | 326297   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -10.9    |
| time/              |          |
|    episodes        | 1324     |
|    fps             | 21       |
|    time_elapsed    | 15677    |
|    total timesteps | 329811   |
| train/             |          |
|    actor_loss      | 2        |
|    critic_loss     | 1.89     |
|    learning_rate   | 0.000674 |
|    n_updates       | 327301   |
---------------------------------
Eval num_timesteps=330000, episode_reward=71.04 +/- 10.37
Episode length: 241.60 +/- 18.80
---------------------------------
| eval/              |          |
|    mean_ep_length  | 242      |
|    mean_reward     | 71       |
| time/              |          |
|    total_timesteps | 330000   |
| train/             |          |
|    actor_loss      | 2        |
|    critic_loss     | 2.01     |
|    learning_rate   | 0.000673 |
|    n_updates       | 327552   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -10.5    |
| time/              |          |
|    episodes        | 1328     |
|    fps             | 21       |
|    time_elapsed    | 15736    |
|    total timesteps | 330815   |
| train/             |          |
|    actor_loss      | 2        |
|    critic_loss     | 1.86     |
|    learning_rate   | 0.000673 |
|    n_updates       | 328305   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -10.3    |
| time/              |          |
|    episodes        | 1332     |
|    fps             | 21       |
|    time_elapsed    | 15779    |
|    total timesteps | 331770   |
| train/             |          |
|    actor_loss      | 2.03     |
|    critic_loss     | 2.19     |
|    learning_rate   | 0.000672 |
|    n_updates       | 329260   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -11.8    |
| time/              |          |
|    episodes        | 1336     |
|    fps             | 21       |
|    time_elapsed    | 15825    |
|    total timesteps | 332774   |
| train/             |          |
|    actor_loss      | 2.01     |
|    critic_loss     | 1.81     |
|    learning_rate   | 0.000671 |
|    n_updates       | 330264   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -12.4    |
| time/              |          |
|    episodes        | 1340     |
|    fps             | 21       |
|    time_elapsed    | 15871    |
|    total timesteps | 333778   |
| train/             |          |
|    actor_loss      | 2.04     |
|    critic_loss     | 1.84     |
|    learning_rate   | 0.00067  |
|    n_updates       | 331268   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -11.2    |
| time/              |          |
|    episodes        | 1344     |
|    fps             | 21       |
|    time_elapsed    | 15917    |
|    total timesteps | 334782   |
| train/             |          |
|    actor_loss      | 2.07     |
|    critic_loss     | 1.91     |
|    learning_rate   | 0.000669 |
|    n_updates       | 332272   |
---------------------------------
Eval num_timesteps=335000, episode_reward=62.67 +/- 15.81
Episode length: 251.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 251      |
|    mean_reward     | 62.7     |
| time/              |          |
|    total_timesteps | 335000   |
| train/             |          |
|    actor_loss      | 2.06     |
|    critic_loss     | 1.97     |
|    learning_rate   | 0.000669 |
|    n_updates       | 332523   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -12.6    |
| time/              |          |
|    episodes        | 1348     |
|    fps             | 21       |
|    time_elapsed    | 15976    |
|    total timesteps | 335786   |
| train/             |          |
|    actor_loss      | 2.03     |
|    critic_loss     | 1.81     |
|    learning_rate   | 0.000668 |
|    n_updates       | 333276   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -12.2    |
| time/              |          |
|    episodes        | 1352     |
|    fps             | 21       |
|    time_elapsed    | 16020    |
|    total timesteps | 336747   |
| train/             |          |
|    actor_loss      | 2.04     |
|    critic_loss     | 2.19     |
|    learning_rate   | 0.000667 |
|    n_updates       | 334237   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -13.3    |
| time/              |          |
|    episodes        | 1356     |
|    fps             | 21       |
|    time_elapsed    | 16066    |
|    total timesteps | 337751   |
| train/             |          |
|    actor_loss      | 1.99     |
|    critic_loss     | 1.49     |
|    learning_rate   | 0.000666 |
|    n_updates       | 335241   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -13.2    |
| time/              |          |
|    episodes        | 1360     |
|    fps             | 21       |
|    time_elapsed    | 16112    |
|    total timesteps | 338755   |
| train/             |          |
|    actor_loss      | 1.99     |
|    critic_loss     | 1.73     |
|    learning_rate   | 0.000665 |
|    n_updates       | 336245   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -12.6    |
| time/              |          |
|    episodes        | 1364     |
|    fps             | 21       |
|    time_elapsed    | 16159    |
|    total timesteps | 339759   |
| train/             |          |
|    actor_loss      | 2.01     |
|    critic_loss     | 2.34     |
|    learning_rate   | 0.000664 |
|    n_updates       | 337249   |
---------------------------------
Eval num_timesteps=340000, episode_reward=65.91 +/- 13.06
Episode length: 251.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 251      |
|    mean_reward     | 65.9     |
| time/              |          |
|    total_timesteps | 340000   |
| train/             |          |
|    actor_loss      | 2.04     |
|    critic_loss     | 2.37     |
|    learning_rate   | 0.000664 |
|    n_updates       | 337500   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -12.2    |
| time/              |          |
|    episodes        | 1368     |
|    fps             | 21       |
|    time_elapsed    | 16218    |
|    total timesteps | 340763   |
| train/             |          |
|    actor_loss      | 2.02     |
|    critic_loss     | 1.84     |
|    learning_rate   | 0.000663 |
|    n_updates       | 338253   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -12.3    |
| time/              |          |
|    episodes        | 1372     |
|    fps             | 21       |
|    time_elapsed    | 16263    |
|    total timesteps | 341767   |
| train/             |          |
|    actor_loss      | 1.99     |
|    critic_loss     | 1.65     |
|    learning_rate   | 0.000662 |
|    n_updates       | 339257   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -11.9    |
| time/              |          |
|    episodes        | 1376     |
|    fps             | 21       |
|    time_elapsed    | 16308    |
|    total timesteps | 342771   |
| train/             |          |
|    actor_loss      | 2.01     |
|    critic_loss     | 2.24     |
|    learning_rate   | 0.000661 |
|    n_updates       | 340261   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -11.5    |
| time/              |          |
|    episodes        | 1380     |
|    fps             | 21       |
|    time_elapsed    | 16354    |
|    total timesteps | 343775   |
| train/             |          |
|    actor_loss      | 2.03     |
|    critic_loss     | 2.44     |
|    learning_rate   | 0.00066  |
|    n_updates       | 341265   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -11.2    |
| time/              |          |
|    episodes        | 1384     |
|    fps             | 21       |
|    time_elapsed    | 16399    |
|    total timesteps | 344779   |
| train/             |          |
|    actor_loss      | 2.02     |
|    critic_loss     | 1.83     |
|    learning_rate   | 0.000659 |
|    n_updates       | 342269   |
---------------------------------
Eval num_timesteps=345000, episode_reward=66.55 +/- 6.04
Episode length: 251.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 251      |
|    mean_reward     | 66.5     |
| time/              |          |
|    total_timesteps | 345000   |
| train/             |          |
|    actor_loss      | 2.04     |
|    critic_loss     | 1.93     |
|    learning_rate   | 0.000659 |
|    n_updates       | 342520   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -11.6    |
| time/              |          |
|    episodes        | 1388     |
|    fps             | 21       |
|    time_elapsed    | 16458    |
|    total timesteps | 345783   |
| train/             |          |
|    actor_loss      | 2.05     |
|    critic_loss     | 1.87     |
|    learning_rate   | 0.000658 |
|    n_updates       | 343273   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -11.3    |
| time/              |          |
|    episodes        | 1392     |
|    fps             | 21       |
|    time_elapsed    | 16503    |
|    total timesteps | 346787   |
| train/             |          |
|    actor_loss      | 2.05     |
|    critic_loss     | 1.81     |
|    learning_rate   | 0.000657 |
|    n_updates       | 344277   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -10.7    |
| time/              |          |
|    episodes        | 1396     |
|    fps             | 21       |
|    time_elapsed    | 16548    |
|    total timesteps | 347791   |
| train/             |          |
|    actor_loss      | 2.06     |
|    critic_loss     | 2.08     |
|    learning_rate   | 0.000656 |
|    n_updates       | 345281   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -9.06    |
| time/              |          |
|    episodes        | 1400     |
|    fps             | 21       |
|    time_elapsed    | 16592    |
|    total timesteps | 348767   |
| train/             |          |
|    actor_loss      | 2.07     |
|    critic_loss     | 2.1      |
|    learning_rate   | 0.000655 |
|    n_updates       | 346257   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -8.57    |
| time/              |          |
|    episodes        | 1404     |
|    fps             | 21       |
|    time_elapsed    | 16637    |
|    total timesteps | 349771   |
| train/             |          |
|    actor_loss      | 2.05     |
|    critic_loss     | 1.71     |
|    learning_rate   | 0.000654 |
|    n_updates       | 347261   |
---------------------------------
Eval num_timesteps=350000, episode_reward=68.50 +/- 8.49
Episode length: 239.80 +/- 22.40
---------------------------------
| eval/              |          |
|    mean_ep_length  | 240      |
|    mean_reward     | 68.5     |
| time/              |          |
|    total_timesteps | 350000   |
| train/             |          |
|    actor_loss      | 2.06     |
|    critic_loss     | 2.21     |
|    learning_rate   | 0.000654 |
|    n_updates       | 347512   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -8       |
| time/              |          |
|    episodes        | 1408     |
|    fps             | 21       |
|    time_elapsed    | 16691    |
|    total timesteps | 350686   |
| train/             |          |
|    actor_loss      | 2.06     |
|    critic_loss     | 1.79     |
|    learning_rate   | 0.000653 |
|    n_updates       | 348176   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -8.43    |
| time/              |          |
|    episodes        | 1412     |
|    fps             | 21       |
|    time_elapsed    | 16736    |
|    total timesteps | 351690   |
| train/             |          |
|    actor_loss      | 2.05     |
|    critic_loss     | 1.87     |
|    learning_rate   | 0.000652 |
|    n_updates       | 349180   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 248      |
|    ep_rew_mean     | -6.96    |
| time/              |          |
|    episodes        | 1416     |
|    fps             | 21       |
|    time_elapsed    | 16781    |
|    total timesteps | 352626   |
| train/             |          |
|    actor_loss      | 2.03     |
|    critic_loss     | 1.75     |
|    learning_rate   | 0.000651 |
|    n_updates       | 350184   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 248      |
|    ep_rew_mean     | -6.24    |
| time/              |          |
|    episodes        | 1420     |
|    fps             | 21       |
|    time_elapsed    | 16823    |
|    total timesteps | 353630   |
| train/             |          |
|    actor_loss      | 2.06     |
|    critic_loss     | 2.09     |
|    learning_rate   | 0.00065  |
|    n_updates       | 351120   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 248      |
|    ep_rew_mean     | -6.05    |
| time/              |          |
|    episodes        | 1424     |
|    fps             | 21       |
|    time_elapsed    | 16869    |
|    total timesteps | 354634   |
| train/             |          |
|    actor_loss      | 2.05     |
|    critic_loss     | 1.92     |
|    learning_rate   | 0.000649 |
|    n_updates       | 352124   |
---------------------------------
Eval num_timesteps=355000, episode_reward=63.86 +/- 13.83
Episode length: 251.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 251      |
|    mean_reward     | 63.9     |
| time/              |          |
|    total_timesteps | 355000   |
| train/             |          |
|    actor_loss      | 2.04     |
|    critic_loss     | 1.94     |
|    learning_rate   | 0.000649 |
|    n_updates       | 352626   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 248      |
|    ep_rew_mean     | -6.78    |
| time/              |          |
|    episodes        | 1428     |
|    fps             | 21       |
|    time_elapsed    | 16927    |
|    total timesteps | 355638   |
| train/             |          |
|    actor_loss      | 2.04     |
|    critic_loss     | 1.96     |
|    learning_rate   | 0.000648 |
|    n_updates       | 353128   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -8.35    |
| time/              |          |
|    episodes        | 1432     |
|    fps             | 21       |
|    time_elapsed    | 16973    |
|    total timesteps | 356642   |
| train/             |          |
|    actor_loss      | 2.04     |
|    critic_loss     | 2.21     |
|    learning_rate   | 0.000647 |
|    n_updates       | 354132   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -7.58    |
| time/              |          |
|    episodes        | 1436     |
|    fps             | 21       |
|    time_elapsed    | 17019    |
|    total timesteps | 357646   |
| train/             |          |
|    actor_loss      | 2.01     |
|    critic_loss     | 1.61     |
|    learning_rate   | 0.000646 |
|    n_updates       | 355136   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -6.61    |
| time/              |          |
|    episodes        | 1440     |
|    fps             | 21       |
|    time_elapsed    | 17064    |
|    total timesteps | 358650   |
| train/             |          |
|    actor_loss      | 2.02     |
|    critic_loss     | 2.14     |
|    learning_rate   | 0.000645 |
|    n_updates       | 356140   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -6.62    |
| time/              |          |
|    episodes        | 1444     |
|    fps             | 21       |
|    time_elapsed    | 17109    |
|    total timesteps | 359654   |
| train/             |          |
|    actor_loss      | 2        |
|    critic_loss     | 1.93     |
|    learning_rate   | 0.000644 |
|    n_updates       | 357144   |
---------------------------------
Eval num_timesteps=360000, episode_reward=70.60 +/- 11.60
Episode length: 236.20 +/- 23.24
---------------------------------
| eval/              |          |
|    mean_ep_length  | 236      |
|    mean_reward     | 70.6     |
| time/              |          |
|    total_timesteps | 360000   |
| train/             |          |
|    actor_loss      | 2.01     |
|    critic_loss     | 1.62     |
|    learning_rate   | 0.000644 |
|    n_updates       | 357646   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -6.6     |
| time/              |          |
|    episodes        | 1448     |
|    fps             | 21       |
|    time_elapsed    | 17166    |
|    total timesteps | 360658   |
| train/             |          |
|    actor_loss      | 2.01     |
|    critic_loss     | 2.17     |
|    learning_rate   | 0.000643 |
|    n_updates       | 358148   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -6.68    |
| time/              |          |
|    episodes        | 1452     |
|    fps             | 21       |
|    time_elapsed    | 17212    |
|    total timesteps | 361662   |
| train/             |          |
|    actor_loss      | 2        |
|    critic_loss     | 1.82     |
|    learning_rate   | 0.000642 |
|    n_updates       | 359152   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -6.34    |
| time/              |          |
|    episodes        | 1456     |
|    fps             | 21       |
|    time_elapsed    | 17256    |
|    total timesteps | 362666   |
| train/             |          |
|    actor_loss      | 2.02     |
|    critic_loss     | 2.21     |
|    learning_rate   | 0.000641 |
|    n_updates       | 360156   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -6.35    |
| time/              |          |
|    episodes        | 1460     |
|    fps             | 21       |
|    time_elapsed    | 17302    |
|    total timesteps | 363670   |
| train/             |          |
|    actor_loss      | 2.05     |
|    critic_loss     | 2.21     |
|    learning_rate   | 0.00064  |
|    n_updates       | 361160   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -7.7     |
| time/              |          |
|    episodes        | 1464     |
|    fps             | 21       |
|    time_elapsed    | 17347    |
|    total timesteps | 364674   |
| train/             |          |
|    actor_loss      | 2.04     |
|    critic_loss     | 1.76     |
|    learning_rate   | 0.000639 |
|    n_updates       | 362164   |
---------------------------------
Eval num_timesteps=365000, episode_reward=66.58 +/- 8.64
Episode length: 251.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 251      |
|    mean_reward     | 66.6     |
| time/              |          |
|    total_timesteps | 365000   |
| train/             |          |
|    actor_loss      | 2.03     |
|    critic_loss     | 1.86     |
|    learning_rate   | 0.000639 |
|    n_updates       | 362666   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -7.9     |
| time/              |          |
|    episodes        | 1468     |
|    fps             | 21       |
|    time_elapsed    | 17406    |
|    total timesteps | 365678   |
| train/             |          |
|    actor_loss      | 2.06     |
|    critic_loss     | 1.86     |
|    learning_rate   | 0.000638 |
|    n_updates       | 363168   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -8.38    |
| time/              |          |
|    episodes        | 1472     |
|    fps             | 21       |
|    time_elapsed    | 17452    |
|    total timesteps | 366682   |
| train/             |          |
|    actor_loss      | 2.04     |
|    critic_loss     | 2.11     |
|    learning_rate   | 0.000637 |
|    n_updates       | 364172   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -7.89    |
| time/              |          |
|    episodes        | 1476     |
|    fps             | 21       |
|    time_elapsed    | 17499    |
|    total timesteps | 367686   |
| train/             |          |
|    actor_loss      | 2.03     |
|    critic_loss     | 1.7      |
|    learning_rate   | 0.000636 |
|    n_updates       | 365176   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -8.53    |
| time/              |          |
|    episodes        | 1480     |
|    fps             | 21       |
|    time_elapsed    | 17544    |
|    total timesteps | 368690   |
| train/             |          |
|    actor_loss      | 2.06     |
|    critic_loss     | 2.07     |
|    learning_rate   | 0.000635 |
|    n_updates       | 366180   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -8.57    |
| time/              |          |
|    episodes        | 1484     |
|    fps             | 21       |
|    time_elapsed    | 17590    |
|    total timesteps | 369694   |
| train/             |          |
|    actor_loss      | 2.07     |
|    critic_loss     | 2.12     |
|    learning_rate   | 0.000634 |
|    n_updates       | 367184   |
---------------------------------
Eval num_timesteps=370000, episode_reward=61.50 +/- 7.78
Episode length: 241.60 +/- 18.80
---------------------------------
| eval/              |          |
|    mean_ep_length  | 242      |
|    mean_reward     | 61.5     |
| time/              |          |
|    total_timesteps | 370000   |
| train/             |          |
|    actor_loss      | 2.07     |
|    critic_loss     | 1.74     |
|    learning_rate   | 0.000634 |
|    n_updates       | 367686   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -8.56    |
| time/              |          |
|    episodes        | 1488     |
|    fps             | 21       |
|    time_elapsed    | 17647    |
|    total timesteps | 370698   |
| train/             |          |
|    actor_loss      | 2.07     |
|    critic_loss     | 1.96     |
|    learning_rate   | 0.000633 |
|    n_updates       | 368188   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -8.37    |
| time/              |          |
|    episodes        | 1492     |
|    fps             | 21       |
|    time_elapsed    | 17693    |
|    total timesteps | 371702   |
| train/             |          |
|    actor_loss      | 2.07     |
|    critic_loss     | 2.09     |
|    learning_rate   | 0.000632 |
|    n_updates       | 369192   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -8.38    |
| time/              |          |
|    episodes        | 1496     |
|    fps             | 21       |
|    time_elapsed    | 17736    |
|    total timesteps | 372667   |
| train/             |          |
|    actor_loss      | 2.08     |
|    critic_loss     | 2.04     |
|    learning_rate   | 0.000631 |
|    n_updates       | 370157   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -10.2    |
| time/              |          |
|    episodes        | 1500     |
|    fps             | 21       |
|    time_elapsed    | 17782    |
|    total timesteps | 373671   |
| train/             |          |
|    actor_loss      | 2.07     |
|    critic_loss     | 1.49     |
|    learning_rate   | 0.00063  |
|    n_updates       | 371161   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -10.2    |
| time/              |          |
|    episodes        | 1504     |
|    fps             | 21       |
|    time_elapsed    | 17827    |
|    total timesteps | 374675   |
| train/             |          |
|    actor_loss      | 2.13     |
|    critic_loss     | 2.47     |
|    learning_rate   | 0.000629 |
|    n_updates       | 372165   |
---------------------------------
Eval num_timesteps=375000, episode_reward=69.17 +/- 10.30
Episode length: 241.00 +/- 20.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 241      |
|    mean_reward     | 69.2     |
| time/              |          |
|    total_timesteps | 375000   |
| train/             |          |
|    actor_loss      | 2.1      |
|    critic_loss     | 1.69     |
|    learning_rate   | 0.000629 |
|    n_updates       | 372667   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -9.95    |
| time/              |          |
|    episodes        | 1508     |
|    fps             | 21       |
|    time_elapsed    | 17884    |
|    total timesteps | 375638   |
| train/             |          |
|    actor_loss      | 2.13     |
|    critic_loss     | 2.1      |
|    learning_rate   | 0.000628 |
|    n_updates       | 373169   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -10.3    |
| time/              |          |
|    episodes        | 1512     |
|    fps             | 21       |
|    time_elapsed    | 17928    |
|    total timesteps | 376642   |
| train/             |          |
|    actor_loss      | 2.12     |
|    critic_loss     | 2.09     |
|    learning_rate   | 0.000627 |
|    n_updates       | 374132   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -9.93    |
| time/              |          |
|    episodes        | 1516     |
|    fps             | 21       |
|    time_elapsed    | 17974    |
|    total timesteps | 377646   |
| train/             |          |
|    actor_loss      | 2.12     |
|    critic_loss     | 1.93     |
|    learning_rate   | 0.000626 |
|    n_updates       | 375136   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -9.92    |
| time/              |          |
|    episodes        | 1520     |
|    fps             | 21       |
|    time_elapsed    | 18019    |
|    total timesteps | 378650   |
| train/             |          |
|    actor_loss      | 2.13     |
|    critic_loss     | 1.89     |
|    learning_rate   | 0.000625 |
|    n_updates       | 376140   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -10.3    |
| time/              |          |
|    episodes        | 1524     |
|    fps             | 21       |
|    time_elapsed    | 18064    |
|    total timesteps | 379654   |
| train/             |          |
|    actor_loss      | 2.14     |
|    critic_loss     | 2.14     |
|    learning_rate   | 0.000624 |
|    n_updates       | 377144   |
---------------------------------
Eval num_timesteps=380000, episode_reward=58.44 +/- 19.97
Episode length: 237.20 +/- 21.30
---------------------------------
| eval/              |          |
|    mean_ep_length  | 237      |
|    mean_reward     | 58.4     |
| time/              |          |
|    total_timesteps | 380000   |
| train/             |          |
|    actor_loss      | 2.14     |
|    critic_loss     | 2.11     |
|    learning_rate   | 0.000624 |
|    n_updates       | 377646   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -9.34    |
| time/              |          |
|    episodes        | 1528     |
|    fps             | 21       |
|    time_elapsed    | 18123    |
|    total timesteps | 380658   |
| train/             |          |
|    actor_loss      | 2.15     |
|    critic_loss     | 2.12     |
|    learning_rate   | 0.000623 |
|    n_updates       | 378148   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -8.61    |
| time/              |          |
|    episodes        | 1532     |
|    fps             | 21       |
|    time_elapsed    | 18169    |
|    total timesteps | 381662   |
| train/             |          |
|    actor_loss      | 2.17     |
|    critic_loss     | 1.8      |
|    learning_rate   | 0.000622 |
|    n_updates       | 379152   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -7.84    |
| time/              |          |
|    episodes        | 1536     |
|    fps             | 21       |
|    time_elapsed    | 18215    |
|    total timesteps | 382666   |
| train/             |          |
|    actor_loss      | 2.19     |
|    critic_loss     | 1.97     |
|    learning_rate   | 0.000621 |
|    n_updates       | 380156   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -8.76    |
| time/              |          |
|    episodes        | 1540     |
|    fps             | 21       |
|    time_elapsed    | 18260    |
|    total timesteps | 383670   |
| train/             |          |
|    actor_loss      | 2.17     |
|    critic_loss     | 1.85     |
|    learning_rate   | 0.00062  |
|    n_updates       | 381160   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -8.77    |
| time/              |          |
|    episodes        | 1544     |
|    fps             | 21       |
|    time_elapsed    | 18305    |
|    total timesteps | 384674   |
| train/             |          |
|    actor_loss      | 2.19     |
|    critic_loss     | 1.83     |
|    learning_rate   | 0.000619 |
|    n_updates       | 382164   |
---------------------------------
Eval num_timesteps=385000, episode_reward=68.99 +/- 6.29
Episode length: 251.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 251      |
|    mean_reward     | 69       |
| time/              |          |
|    total_timesteps | 385000   |
| train/             |          |
|    actor_loss      | 2.21     |
|    critic_loss     | 2.24     |
|    learning_rate   | 0.000619 |
|    n_updates       | 382666   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -8.46    |
| time/              |          |
|    episodes        | 1548     |
|    fps             | 21       |
|    time_elapsed    | 18363    |
|    total timesteps | 385678   |
| train/             |          |
|    actor_loss      | 2.22     |
|    critic_loss     | 1.84     |
|    learning_rate   | 0.000618 |
|    n_updates       | 383168   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -8.63    |
| time/              |          |
|    episodes        | 1552     |
|    fps             | 21       |
|    time_elapsed    | 18408    |
|    total timesteps | 386682   |
| train/             |          |
|    actor_loss      | 2.21     |
|    critic_loss     | 1.8      |
|    learning_rate   | 0.000617 |
|    n_updates       | 384172   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -8.27    |
| time/              |          |
|    episodes        | 1556     |
|    fps             | 21       |
|    time_elapsed    | 18454    |
|    total timesteps | 387686   |
| train/             |          |
|    actor_loss      | 2.21     |
|    critic_loss     | 1.74     |
|    learning_rate   | 0.000616 |
|    n_updates       | 385176   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -8.74    |
| time/              |          |
|    episodes        | 1560     |
|    fps             | 21       |
|    time_elapsed    | 18500    |
|    total timesteps | 388690   |
| train/             |          |
|    actor_loss      | 2.21     |
|    critic_loss     | 2.04     |
|    learning_rate   | 0.000615 |
|    n_updates       | 386180   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -7.36    |
| time/              |          |
|    episodes        | 1564     |
|    fps             | 21       |
|    time_elapsed    | 18544    |
|    total timesteps | 389668   |
| train/             |          |
|    actor_loss      | 2.21     |
|    critic_loss     | 1.67     |
|    learning_rate   | 0.000614 |
|    n_updates       | 387158   |
---------------------------------
Eval num_timesteps=390000, episode_reward=45.48 +/- 18.73
Episode length: 241.40 +/- 19.20
---------------------------------
| eval/              |          |
|    mean_ep_length  | 241      |
|    mean_reward     | 45.5     |
| time/              |          |
|    total_timesteps | 390000   |
| train/             |          |
|    actor_loss      | 2.23     |
|    critic_loss     | 1.77     |
|    learning_rate   | 0.000614 |
|    n_updates       | 387660   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -7.61    |
| time/              |          |
|    episodes        | 1568     |
|    fps             | 21       |
|    time_elapsed    | 18602    |
|    total timesteps | 390672   |
| train/             |          |
|    actor_loss      | 2.18     |
|    critic_loss     | 1.63     |
|    learning_rate   | 0.000613 |
|    n_updates       | 388162   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -6.66    |
| time/              |          |
|    episodes        | 1572     |
|    fps             | 21       |
|    time_elapsed    | 18647    |
|    total timesteps | 391676   |
| train/             |          |
|    actor_loss      | 2.2      |
|    critic_loss     | 1.78     |
|    learning_rate   | 0.000612 |
|    n_updates       | 389166   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -7.68    |
| time/              |          |
|    episodes        | 1576     |
|    fps             | 21       |
|    time_elapsed    | 18692    |
|    total timesteps | 392680   |
| train/             |          |
|    actor_loss      | 2.19     |
|    critic_loss     | 1.81     |
|    learning_rate   | 0.000611 |
|    n_updates       | 390170   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -8.05    |
| time/              |          |
|    episodes        | 1580     |
|    fps             | 21       |
|    time_elapsed    | 18737    |
|    total timesteps | 393684   |
| train/             |          |
|    actor_loss      | 2.18     |
|    critic_loss     | 2.01     |
|    learning_rate   | 0.000611 |
|    n_updates       | 391174   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -6.58    |
| time/              |          |
|    episodes        | 1584     |
|    fps             | 21       |
|    time_elapsed    | 18782    |
|    total timesteps | 394688   |
| train/             |          |
|    actor_loss      | 2.23     |
|    critic_loss     | 2.2      |
|    learning_rate   | 0.00061  |
|    n_updates       | 392178   |
---------------------------------
Eval num_timesteps=395000, episode_reward=71.16 +/- 8.86
Episode length: 242.40 +/- 17.20
---------------------------------
| eval/              |          |
|    mean_ep_length  | 242      |
|    mean_reward     | 71.2     |
| time/              |          |
|    total_timesteps | 395000   |
| train/             |          |
|    actor_loss      | 2.19     |
|    critic_loss     | 1.53     |
|    learning_rate   | 0.000609 |
|    n_updates       | 392680   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -6.7     |
| time/              |          |
|    episodes        | 1588     |
|    fps             | 21       |
|    time_elapsed    | 18839    |
|    total timesteps | 395692   |
| train/             |          |
|    actor_loss      | 2.25     |
|    critic_loss     | 2.37     |
|    learning_rate   | 0.000609 |
|    n_updates       | 393182   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -6.36    |
| time/              |          |
|    episodes        | 1592     |
|    fps             | 21       |
|    time_elapsed    | 18884    |
|    total timesteps | 396696   |
| train/             |          |
|    actor_loss      | 2.26     |
|    critic_loss     | 1.95     |
|    learning_rate   | 0.000608 |
|    n_updates       | 394186   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -6.61    |
| time/              |          |
|    episodes        | 1596     |
|    fps             | 21       |
|    time_elapsed    | 18928    |
|    total timesteps | 397700   |
| train/             |          |
|    actor_loss      | 2.27     |
|    critic_loss     | 1.85     |
|    learning_rate   | 0.000607 |
|    n_updates       | 395190   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -6.07    |
| time/              |          |
|    episodes        | 1600     |
|    fps             | 21       |
|    time_elapsed    | 18975    |
|    total timesteps | 398704   |
| train/             |          |
|    actor_loss      | 2.3      |
|    critic_loss     | 1.8      |
|    learning_rate   | 0.000606 |
|    n_updates       | 396194   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -6.67    |
| time/              |          |
|    episodes        | 1604     |
|    fps             | 21       |
|    time_elapsed    | 19020    |
|    total timesteps | 399708   |
| train/             |          |
|    actor_loss      | 2.33     |
|    critic_loss     | 2.27     |
|    learning_rate   | 0.000605 |
|    n_updates       | 397198   |
---------------------------------
Eval num_timesteps=400000, episode_reward=65.93 +/- 14.02
Episode length: 240.20 +/- 21.60
---------------------------------
| eval/              |          |
|    mean_ep_length  | 240      |
|    mean_reward     | 65.9     |
| time/              |          |
|    total_timesteps | 400000   |
| train/             |          |
|    actor_loss      | 2.3      |
|    critic_loss     | 1.79     |
|    learning_rate   | 0.000604 |
|    n_updates       | 397700   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -8.04    |
| time/              |          |
|    episodes        | 1608     |
|    fps             | 21       |
|    time_elapsed    | 19077    |
|    total timesteps | 400712   |
| train/             |          |
|    actor_loss      | 2.33     |
|    critic_loss     | 2.21     |
|    learning_rate   | 0.000604 |
|    n_updates       | 398202   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -7.96    |
| time/              |          |
|    episodes        | 1612     |
|    fps             | 21       |
|    time_elapsed    | 19122    |
|    total timesteps | 401716   |
| train/             |          |
|    actor_loss      | 2.36     |
|    critic_loss     | 1.86     |
|    learning_rate   | 0.000603 |
|    n_updates       | 399206   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -9.67    |
| time/              |          |
|    episodes        | 1616     |
|    fps             | 21       |
|    time_elapsed    | 19167    |
|    total timesteps | 402720   |
| train/             |          |
|    actor_loss      | 2.34     |
|    critic_loss     | 2.03     |
|    learning_rate   | 0.000602 |
|    n_updates       | 400210   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -10.7    |
| time/              |          |
|    episodes        | 1620     |
|    fps             | 21       |
|    time_elapsed    | 19212    |
|    total timesteps | 403724   |
| train/             |          |
|    actor_loss      | 2.33     |
|    critic_loss     | 1.74     |
|    learning_rate   | 0.000601 |
|    n_updates       | 401214   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -9.45    |
| time/              |          |
|    episodes        | 1624     |
|    fps             | 21       |
|    time_elapsed    | 19258    |
|    total timesteps | 404728   |
| train/             |          |
|    actor_loss      | 2.33     |
|    critic_loss     | 1.55     |
|    learning_rate   | 0.0006   |
|    n_updates       | 402218   |
---------------------------------
Eval num_timesteps=405000, episode_reward=65.75 +/- 6.44
Episode length: 242.20 +/- 17.60
---------------------------------
| eval/              |          |
|    mean_ep_length  | 242      |
|    mean_reward     | 65.8     |
| time/              |          |
|    total_timesteps | 405000   |
| train/             |          |
|    actor_loss      | 2.34     |
|    critic_loss     | 2.1      |
|    learning_rate   | 0.000599 |
|    n_updates       | 402650   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -9.34    |
| time/              |          |
|    episodes        | 1628     |
|    fps             | 21       |
|    time_elapsed    | 19314    |
|    total timesteps | 405662   |
| train/             |          |
|    actor_loss      | 2.37     |
|    critic_loss     | 2.24     |
|    learning_rate   | 0.000599 |
|    n_updates       | 403152   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -9.29    |
| time/              |          |
|    episodes        | 1632     |
|    fps             | 21       |
|    time_elapsed    | 19359    |
|    total timesteps | 406666   |
| train/             |          |
|    actor_loss      | 2.36     |
|    critic_loss     | 1.93     |
|    learning_rate   | 0.000598 |
|    n_updates       | 404156   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -10.3    |
| time/              |          |
|    episodes        | 1636     |
|    fps             | 21       |
|    time_elapsed    | 19405    |
|    total timesteps | 407670   |
| train/             |          |
|    actor_loss      | 2.36     |
|    critic_loss     | 1.33     |
|    learning_rate   | 0.000597 |
|    n_updates       | 405160   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -10.5    |
| time/              |          |
|    episodes        | 1640     |
|    fps             | 21       |
|    time_elapsed    | 19451    |
|    total timesteps | 408674   |
| train/             |          |
|    actor_loss      | 2.36     |
|    critic_loss     | 1.72     |
|    learning_rate   | 0.000596 |
|    n_updates       | 406164   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -10.4    |
| time/              |          |
|    episodes        | 1644     |
|    fps             | 21       |
|    time_elapsed    | 19498    |
|    total timesteps | 409678   |
| train/             |          |
|    actor_loss      | 2.34     |
|    critic_loss     | 1.57     |
|    learning_rate   | 0.000595 |
|    n_updates       | 407168   |
---------------------------------
Eval num_timesteps=410000, episode_reward=66.24 +/- 16.02
Episode length: 251.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 251      |
|    mean_reward     | 66.2     |
| time/              |          |
|    total_timesteps | 410000   |
| train/             |          |
|    actor_loss      | 2.35     |
|    critic_loss     | 1.78     |
|    learning_rate   | 0.000594 |
|    n_updates       | 407670   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -10.3    |
| time/              |          |
|    episodes        | 1648     |
|    fps             | 20       |
|    time_elapsed    | 19556    |
|    total timesteps | 410682   |
| train/             |          |
|    actor_loss      | 2.4      |
|    critic_loss     | 2.48     |
|    learning_rate   | 0.000594 |
|    n_updates       | 408172   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -10.3    |
| time/              |          |
|    episodes        | 1652     |
|    fps             | 21       |
|    time_elapsed    | 19603    |
|    total timesteps | 411686   |
| train/             |          |
|    actor_loss      | 2.41     |
|    critic_loss     | 1.81     |
|    learning_rate   | 0.000593 |
|    n_updates       | 409176   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -11      |
| time/              |          |
|    episodes        | 1656     |
|    fps             | 21       |
|    time_elapsed    | 19649    |
|    total timesteps | 412690   |
| train/             |          |
|    actor_loss      | 2.41     |
|    critic_loss     | 1.89     |
|    learning_rate   | 0.000592 |
|    n_updates       | 410180   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -11      |
| time/              |          |
|    episodes        | 1660     |
|    fps             | 21       |
|    time_elapsed    | 19695    |
|    total timesteps | 413694   |
| train/             |          |
|    actor_loss      | 2.4      |
|    critic_loss     | 1.57     |
|    learning_rate   | 0.000591 |
|    n_updates       | 411184   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -11.6    |
| time/              |          |
|    episodes        | 1664     |
|    fps             | 21       |
|    time_elapsed    | 19741    |
|    total timesteps | 414698   |
| train/             |          |
|    actor_loss      | 2.43     |
|    critic_loss     | 1.9      |
|    learning_rate   | 0.00059  |
|    n_updates       | 412188   |
---------------------------------
Eval num_timesteps=415000, episode_reward=56.25 +/- 12.38
Episode length: 242.40 +/- 17.20
---------------------------------
| eval/              |          |
|    mean_ep_length  | 242      |
|    mean_reward     | 56.3     |
| time/              |          |
|    total_timesteps | 415000   |
| train/             |          |
|    actor_loss      | 2.43     |
|    critic_loss     | 1.72     |
|    learning_rate   | 0.000589 |
|    n_updates       | 412690   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -11.5    |
| time/              |          |
|    episodes        | 1668     |
|    fps             | 20       |
|    time_elapsed    | 19800    |
|    total timesteps | 415702   |
| train/             |          |
|    actor_loss      | 2.43     |
|    critic_loss     | 2        |
|    learning_rate   | 0.000589 |
|    n_updates       | 413192   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -11.9    |
| time/              |          |
|    episodes        | 1672     |
|    fps             | 20       |
|    time_elapsed    | 19845    |
|    total timesteps | 416706   |
| train/             |          |
|    actor_loss      | 2.45     |
|    critic_loss     | 2.1      |
|    learning_rate   | 0.000588 |
|    n_updates       | 414196   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -12.1    |
| time/              |          |
|    episodes        | 1676     |
|    fps             | 20       |
|    time_elapsed    | 19892    |
|    total timesteps | 417710   |
| train/             |          |
|    actor_loss      | 2.44     |
|    critic_loss     | 2.09     |
|    learning_rate   | 0.000587 |
|    n_updates       | 415200   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -10.9    |
| time/              |          |
|    episodes        | 1680     |
|    fps             | 20       |
|    time_elapsed    | 19936    |
|    total timesteps | 418590   |
| train/             |          |
|    actor_loss      | 2.46     |
|    critic_loss     | 2.36     |
|    learning_rate   | 0.000586 |
|    n_updates       | 416204   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -13.6    |
| time/              |          |
|    episodes        | 1684     |
|    fps             | 21       |
|    time_elapsed    | 19977    |
|    total timesteps | 419594   |
| train/             |          |
|    actor_loss      | 2.46     |
|    critic_loss     | 2.1      |
|    learning_rate   | 0.000585 |
|    n_updates       | 417084   |
---------------------------------
Eval num_timesteps=420000, episode_reward=57.46 +/- 8.97
Episode length: 222.00 +/- 23.90
---------------------------------
| eval/              |          |
|    mean_ep_length  | 222      |
|    mean_reward     | 57.5     |
| time/              |          |
|    total_timesteps | 420000   |
| train/             |          |
|    actor_loss      | 2.46     |
|    critic_loss     | 1.87     |
|    learning_rate   | 0.000584 |
|    n_updates       | 417586   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -12.8    |
| time/              |          |
|    episodes        | 1688     |
|    fps             | 20       |
|    time_elapsed    | 20033    |
|    total timesteps | 420598   |
| train/             |          |
|    actor_loss      | 2.45     |
|    critic_loss     | 1.92     |
|    learning_rate   | 0.000584 |
|    n_updates       | 418088   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -12.6    |
| time/              |          |
|    episodes        | 1692     |
|    fps             | 20       |
|    time_elapsed    | 20078    |
|    total timesteps | 421602   |
| train/             |          |
|    actor_loss      | 2.45     |
|    critic_loss     | 1.85     |
|    learning_rate   | 0.000583 |
|    n_updates       | 419092   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -13.8    |
| time/              |          |
|    episodes        | 1696     |
|    fps             | 21       |
|    time_elapsed    | 20122    |
|    total timesteps | 422606   |
| train/             |          |
|    actor_loss      | 2.43     |
|    critic_loss     | 1.87     |
|    learning_rate   | 0.000582 |
|    n_updates       | 420096   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -13.2    |
| time/              |          |
|    episodes        | 1700     |
|    fps             | 21       |
|    time_elapsed    | 20168    |
|    total timesteps | 423610   |
| train/             |          |
|    actor_loss      | 2.44     |
|    critic_loss     | 2.19     |
|    learning_rate   | 0.000581 |
|    n_updates       | 421100   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 248      |
|    ep_rew_mean     | -12.6    |
| time/              |          |
|    episodes        | 1704     |
|    fps             | 21       |
|    time_elapsed    | 20210    |
|    total timesteps | 424551   |
| train/             |          |
|    actor_loss      | 2.45     |
|    critic_loss     | 1.89     |
|    learning_rate   | 0.00058  |
|    n_updates       | 422041   |
---------------------------------
Eval num_timesteps=425000, episode_reward=53.48 +/- 22.13
Episode length: 239.60 +/- 22.80
---------------------------------
| eval/              |          |
|    mean_ep_length  | 240      |
|    mean_reward     | 53.5     |
| time/              |          |
|    total_timesteps | 425000   |
| train/             |          |
|    actor_loss      | 2.46     |
|    critic_loss     | 1.99     |
|    learning_rate   | 0.000579 |
|    n_updates       | 422543   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 248      |
|    ep_rew_mean     | -11.9    |
| time/              |          |
|    episodes        | 1708     |
|    fps             | 20       |
|    time_elapsed    | 20267    |
|    total timesteps | 425555   |
| train/             |          |
|    actor_loss      | 2.46     |
|    critic_loss     | 1.78     |
|    learning_rate   | 0.000579 |
|    n_updates       | 423045   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 248      |
|    ep_rew_mean     | -12.1    |
| time/              |          |
|    episodes        | 1712     |
|    fps             | 21       |
|    time_elapsed    | 20312    |
|    total timesteps | 426559   |
| train/             |          |
|    actor_loss      | 2.45     |
|    critic_loss     | 1.52     |
|    learning_rate   | 0.000578 |
|    n_updates       | 424049   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 248      |
|    ep_rew_mean     | -10.8    |
| time/              |          |
|    episodes        | 1716     |
|    fps             | 21       |
|    time_elapsed    | 20357    |
|    total timesteps | 427563   |
| train/             |          |
|    actor_loss      | 2.5      |
|    critic_loss     | 2.04     |
|    learning_rate   | 0.000577 |
|    n_updates       | 425053   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 248      |
|    ep_rew_mean     | -9.63    |
| time/              |          |
|    episodes        | 1720     |
|    fps             | 21       |
|    time_elapsed    | 20403    |
|    total timesteps | 428567   |
| train/             |          |
|    actor_loss      | 2.49     |
|    critic_loss     | 1.65     |
|    learning_rate   | 0.000576 |
|    n_updates       | 426057   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 248      |
|    ep_rew_mean     | -8.35    |
| time/              |          |
|    episodes        | 1724     |
|    fps             | 21       |
|    time_elapsed    | 20447    |
|    total timesteps | 429544   |
| train/             |          |
|    actor_loss      | 2.51     |
|    critic_loss     | 2.07     |
|    learning_rate   | 0.000575 |
|    n_updates       | 427034   |
---------------------------------
Eval num_timesteps=430000, episode_reward=54.11 +/- 22.47
Episode length: 251.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 251      |
|    mean_reward     | 54.1     |
| time/              |          |
|    total_timesteps | 430000   |
| train/             |          |
|    actor_loss      | 2.52     |
|    critic_loss     | 2.04     |
|    learning_rate   | 0.000575 |
|    n_updates       | 427536   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -8.61    |
| time/              |          |
|    episodes        | 1728     |
|    fps             | 20       |
|    time_elapsed    | 20506    |
|    total timesteps | 430548   |
| train/             |          |
|    actor_loss      | 2.51     |
|    critic_loss     | 1.98     |
|    learning_rate   | 0.000574 |
|    n_updates       | 428038   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -8.52    |
| time/              |          |
|    episodes        | 1732     |
|    fps             | 20       |
|    time_elapsed    | 20552    |
|    total timesteps | 431552   |
| train/             |          |
|    actor_loss      | 2.51     |
|    critic_loss     | 1.68     |
|    learning_rate   | 0.000573 |
|    n_updates       | 429042   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 249      |
|    ep_rew_mean     | -8.28    |
| time/              |          |
|    episodes        | 1736     |
|    fps             | 20       |
|    time_elapsed    | 20598    |
|    total timesteps | 432556   |
| train/             |          |
|    actor_loss      | 2.53     |
|    critic_loss     | 2.05     |
|    learning_rate   | 0.000572 |
|    n_updates       | 430046   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 248      |
|    ep_rew_mean     | -7.83    |
| time/              |          |
|    episodes        | 1740     |
|    fps             | 21       |
|    time_elapsed    | 20641    |
|    total timesteps | 433490   |
| train/             |          |
|    actor_loss      | 2.55     |
|    critic_loss     | 1.72     |
|    learning_rate   | 0.000571 |
|    n_updates       | 430980   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 248      |
|    ep_rew_mean     | -7.55    |
| time/              |          |
|    episodes        | 1744     |
|    fps             | 21       |
|    time_elapsed    | 20687    |
|    total timesteps | 434494   |
| train/             |          |
|    actor_loss      | 2.54     |
|    critic_loss     | 1.89     |
|    learning_rate   | 0.00057  |
|    n_updates       | 431984   |
---------------------------------
Eval num_timesteps=435000, episode_reward=67.23 +/- 7.63
Episode length: 234.00 +/- 21.85
---------------------------------
| eval/              |          |
|    mean_ep_length  | 234      |
|    mean_reward     | 67.2     |
| time/              |          |
|    total_timesteps | 435000   |
| train/             |          |
|    actor_loss      | 2.55     |
|    critic_loss     | 2.37     |
|    learning_rate   | 0.000569 |
|    n_updates       | 432737   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 248      |
|    ep_rew_mean     | -7.5     |
| time/              |          |
|    episodes        | 1748     |
|    fps             | 20       |
|    time_elapsed    | 20745    |
|    total timesteps | 435498   |
| train/             |          |
|    actor_loss      | 2.56     |
|    critic_loss     | 1.84     |
|    learning_rate   | 0.000569 |
|    n_updates       | 432988   |
---------------------------------
Terminated
2021-12-17 21:40:53.230702: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib/nvidia-470:/usr/local/cuda/lib64:/root/.mujoco/mjpro150/bin:/usr/local/nvidia/lib:/usr/local/nvidia/lib64
2021-12-17 21:40:53.230814: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
/root/trainer
Env Type: maze
Task: GoalRewardSimple
Model: <class 'stable_baselines3.td3.td3.TD3'>
Using cuda device
Logging to assets/out/models/exp17/TD3_17
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -32.1    |
| time/              |          |
|    episodes        | 4        |
|    fps             | 95       |
|    time_elapsed    | 10       |
|    total timesteps | 1004     |
---------------------------------
Terminated
2021-12-17 21:41:59.174998: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib/nvidia-470:/usr/local/cuda/lib64:/root/.mujoco/mjpro150/bin:/usr/local/nvidia/lib:/usr/local/nvidia/lib64
2021-12-17 21:41:59.175067: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
/root/trainer
Env Type: maze
Task: GoalRewardSimple
Model: <class 'stable_baselines3.td3.td3.TD3'>
Using cuda device
Logging to assets/out/models/exp17/TD3_18
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -43.4    |
| time/              |          |
|    episodes        | 4        |
|    fps             | 96       |
|    time_elapsed    | 10       |
|    total timesteps | 1004     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -24.1    |
| time/              |          |
|    episodes        | 8        |
|    fps             | 105      |
|    time_elapsed    | 19       |
|    total timesteps | 2008     |
---------------------------------
Found 1 GPUs for rendering. Using device 0.
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -32.3    |
| time/              |          |
|    episodes        | 12       |
|    fps             | 65       |
|    time_elapsed    | 46       |
|    total timesteps | 3012     |
| train/             |          |
|    actor_loss      | 0.78     |
|    critic_loss     | 9.96     |
|    learning_rate   | 0.000997 |
|    n_updates       | 502      |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -24.6    |
| time/              |          |
|    episodes        | 16       |
|    fps             | 43       |
|    time_elapsed    | 92       |
|    total timesteps | 4016     |
| train/             |          |
|    actor_loss      | 1.13     |
|    critic_loss     | 8.52     |
|    learning_rate   | 0.000996 |
|    n_updates       | 1506     |
---------------------------------
Eval num_timesteps=5000, episode_reward=67.20 +/- 8.51
Episode length: 242.60 +/- 16.80
---------------------------------
| eval/              |          |
|    mean_ep_length  | 243      |
|    mean_reward     | 67.2     |
| time/              |          |
|    total_timesteps | 5000     |
| train/             |          |
|    actor_loss      | 1.78     |
|    critic_loss     | 8.5      |
|    learning_rate   | 0.000995 |
|    n_updates       | 2510     |
---------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -19.5    |
| time/              |          |
|    episodes        | 20       |
|    fps             | 33       |
|    time_elapsed    | 150      |
|    total timesteps | 5020     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -21.2    |
| time/              |          |
|    episodes        | 24       |
|    fps             | 30       |
|    time_elapsed    | 195      |
|    total timesteps | 6024     |
| train/             |          |
|    actor_loss      | 1.81     |
|    critic_loss     | 7.44     |
|    learning_rate   | 0.000994 |
|    n_updates       | 3514     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -20      |
| time/              |          |
|    episodes        | 28       |
|    fps             | 29       |
|    time_elapsed    | 241      |
|    total timesteps | 7028     |
| train/             |          |
|    actor_loss      | 2.35     |
|    critic_loss     | 10.3     |
|    learning_rate   | 0.000993 |
|    n_updates       | 4518     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -17.1    |
| time/              |          |
|    episodes        | 32       |
|    fps             | 28       |
|    time_elapsed    | 286      |
|    total timesteps | 8032     |
| train/             |          |
|    actor_loss      | 2.71     |
|    critic_loss     | 8.65     |
|    learning_rate   | 0.000992 |
|    n_updates       | 5522     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -16.6    |
| time/              |          |
|    episodes        | 36       |
|    fps             | 27       |
|    time_elapsed    | 331      |
|    total timesteps | 9036     |
| train/             |          |
|    actor_loss      | 2.7      |
|    critic_loss     | 8.82     |
|    learning_rate   | 0.000991 |
|    n_updates       | 6526     |
---------------------------------
Eval num_timesteps=10000, episode_reward=70.97 +/- 8.00
Episode length: 251.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 251      |
|    mean_reward     | 71       |
| time/              |          |
|    total_timesteps | 10000    |
| train/             |          |
|    actor_loss      | 2.77     |
|    critic_loss     | 7.98     |
|    learning_rate   | 0.00099  |
|    n_updates       | 7530     |
---------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -17.3    |
| time/              |          |
|    episodes        | 40       |
|    fps             | 25       |
|    time_elapsed    | 390      |
|    total timesteps | 10040    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -18.6    |
| time/              |          |
|    episodes        | 44       |
|    fps             | 25       |
|    time_elapsed    | 435      |
|    total timesteps | 11044    |
| train/             |          |
|    actor_loss      | 2.89     |
|    critic_loss     | 8.56     |
|    learning_rate   | 0.000989 |
|    n_updates       | 8534     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -17.3    |
| time/              |          |
|    episodes        | 48       |
|    fps             | 25       |
|    time_elapsed    | 480      |
|    total timesteps | 12048    |
| train/             |          |
|    actor_loss      | 2.95     |
|    critic_loss     | 8.89     |
|    learning_rate   | 0.000988 |
|    n_updates       | 9538     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -14.9    |
| time/              |          |
|    episodes        | 52       |
|    fps             | 24       |
|    time_elapsed    | 525      |
|    total timesteps | 13052    |
| train/             |          |
|    actor_loss      | 2.96     |
|    critic_loss     | 8.86     |
|    learning_rate   | 0.000987 |
|    n_updates       | 10542    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 251      |
|    ep_rew_mean     | -14.7    |
| time/              |          |
|    episodes        | 56       |
|    fps             | 24       |
|    time_elapsed    | 570      |
|    total timesteps | 14056    |
| train/             |          |
|    actor_loss      | 2.93     |
|    critic_loss     | 7.99     |
|    learning_rate   | 0.000986 |
|    n_updates       | 11546    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -14      |
| time/              |          |
|    episodes        | 60       |
|    fps             | 24       |
|    time_elapsed    | 611      |
|    total timesteps | 14972    |
| train/             |          |
|    actor_loss      | 2.88     |
|    critic_loss     | 7.96     |
|    learning_rate   | 0.000985 |
|    n_updates       | 12462    |
---------------------------------
Eval num_timesteps=15000, episode_reward=70.44 +/- 13.26
Episode length: 251.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 251      |
|    mean_reward     | 70.4     |
| time/              |          |
|    total_timesteps | 15000    |
| train/             |          |
|    actor_loss      | 2.95     |
|    critic_loss     | 9.8      |
|    learning_rate   | 0.000985 |
|    n_updates       | 12713    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -12.1    |
| time/              |          |
|    episodes        | 64       |
|    fps             | 23       |
|    time_elapsed    | 669      |
|    total timesteps | 15976    |
| train/             |          |
|    actor_loss      | 2.85     |
|    critic_loss     | 8.24     |
|    learning_rate   | 0.000984 |
|    n_updates       | 13466    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -13.9    |
| time/              |          |
|    episodes        | 68       |
|    fps             | 23       |
|    time_elapsed    | 714      |
|    total timesteps | 16980    |
| train/             |          |
|    actor_loss      | 2.77     |
|    critic_loss     | 8.56     |
|    learning_rate   | 0.000983 |
|    n_updates       | 14470    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 250      |
|    ep_rew_mean     | -14.6    |
| time/              |          |
|    episodes        | 72       |
|    fps             | 23       |
|    time_elapsed    | 759      |
|    total timesteps | 17984    |
| train/             |          |
|    actor_loss      | 2.74     |
|    critic_loss     | 8        |
|    learning_rate   | 0.000982 |
|    n_updates       | 15474    |
---------------------------------
Terminated
2021-12-17 21:55:53.183065: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib/nvidia-470:/usr/local/cuda/lib64:/root/.mujoco/mjpro150/bin:/usr/local/nvidia/lib:/usr/local/nvidia/lib64
2021-12-17 21:55:53.183137: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
/root/trainer
Env Type: maze
Task: GoalRewardSimple
Model: <class 'stable_baselines3.td3.td3.TD3'>
Using cuda device
Logging to assets/out/models/exp17/TD3_19
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 110      |
|    ep_rew_mean     | -5.78    |
| time/              |          |
|    episodes        | 4        |
|    fps             | 73       |
|    time_elapsed    | 5        |
|    total timesteps | 438      |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 142      |
|    ep_rew_mean     | -4.06    |
| time/              |          |
|    episodes        | 8        |
|    fps             | 92       |
|    time_elapsed    | 12       |
|    total timesteps | 1135     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 143      |
|    ep_rew_mean     | -4.02    |
| time/              |          |
|    episodes        | 12       |
|    fps             | 97       |
|    time_elapsed    | 17       |
|    total timesteps | 1720     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 134      |
|    ep_rew_mean     | -5       |
| time/              |          |
|    episodes        | 16       |
|    fps             | 99       |
|    time_elapsed    | 21       |
|    total timesteps | 2148     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 119      |
|    ep_rew_mean     | -5.71    |
| time/              |          |
|    episodes        | 20       |
|    fps             | 98       |
|    time_elapsed    | 24       |
|    total timesteps | 2386     |
---------------------------------
Found 1 GPUs for rendering. Using device 0.
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 116      |
|    ep_rew_mean     | -5.9     |
| time/              |          |
|    episodes        | 24       |
|    fps             | 74       |
|    time_elapsed    | 37       |
|    total timesteps | 2774     |
| train/             |          |
|    actor_loss      | 0.294    |
|    critic_loss     | 4.68     |
|    learning_rate   | 0.000997 |
|    n_updates       | 245      |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 125      |
|    ep_rew_mean     | -2.59    |
| time/              |          |
|    episodes        | 28       |
|    fps             | 53       |
|    time_elapsed    | 65       |
|    total timesteps | 3498     |
| train/             |          |
|    actor_loss      | 0.478    |
|    critic_loss     | 4.21     |
|    learning_rate   | 0.000997 |
|    n_updates       | 826      |
---------------------------------
Terminated
2021-12-17 21:57:59.741775: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib/nvidia-470:/usr/local/cuda/lib64:/root/.mujoco/mjpro150/bin:/usr/local/nvidia/lib:/usr/local/nvidia/lib64
2021-12-17 21:57:59.741845: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
/root/trainer
Env Type: maze
Task: GoalRewardSimple
Model: <class 'stable_baselines3.td3.td3.TD3'>
Using cuda device
Logging to assets/out/models/exp17/TD3_20
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 168      |
|    ep_rew_mean     | -0.529   |
| time/              |          |
|    episodes        | 4        |
|    fps             | 85       |
|    time_elapsed    | 7        |
|    total timesteps | 670      |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 124      |
|    ep_rew_mean     | -4.12    |
| time/              |          |
|    episodes        | 8        |
|    fps             | 90       |
|    time_elapsed    | 11       |
|    total timesteps | 996      |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 128      |
|    ep_rew_mean     | -5.98    |
| time/              |          |
|    episodes        | 12       |
|    fps             | 96       |
|    time_elapsed    | 16       |
|    total timesteps | 1539     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 133      |
|    ep_rew_mean     | -5.15    |
| time/              |          |
|    episodes        | 16       |
|    fps             | 100      |
|    time_elapsed    | 21       |
|    total timesteps | 2121     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 121      |
|    ep_rew_mean     | -5.87    |
| time/              |          |
|    episodes        | 20       |
|    fps             | 99       |
|    time_elapsed    | 24       |
|    total timesteps | 2423     |
---------------------------------
Found 1 GPUs for rendering. Using device 0.
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 128      |
|    ep_rew_mean     | -4.39    |
| time/              |          |
|    episodes        | 24       |
|    fps             | 38       |
|    time_elapsed    | 80       |
|    total timesteps | 3063     |
| train/             |          |
|    actor_loss      | 1.2      |
|    critic_loss     | 3.24     |
|    learning_rate   | 0.000997 |
|    n_updates       | 480      |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 137      |
|    ep_rew_mean     | -3.69    |
| time/              |          |
|    episodes        | 28       |
|    fps             | 24       |
|    time_elapsed    | 156      |
|    total timesteps | 3840     |
| train/             |          |
|    actor_loss      | 1.09     |
|    critic_loss     | 2.97     |
|    learning_rate   | 0.000996 |
|    n_updates       | 1166     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 133      |
|    ep_rew_mean     | -4.1     |
| time/              |          |
|    episodes        | 32       |
|    fps             | 19       |
|    time_elapsed    | 216      |
|    total timesteps | 4264     |
| train/             |          |
|    actor_loss      | 1.2      |
|    critic_loss     | 2.85     |
|    learning_rate   | 0.000996 |
|    n_updates       | 1716     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 130      |
|    ep_rew_mean     | -4.28    |
| time/              |          |
|    episodes        | 36       |
|    fps             | 17       |
|    time_elapsed    | 261      |
|    total timesteps | 4692     |
| train/             |          |
|    actor_loss      | 1.24     |
|    critic_loss     | 3.35     |
|    learning_rate   | 0.000995 |
|    n_updates       | 2116     |
---------------------------------
Eval num_timesteps=5000, episode_reward=63.89 +/- 6.19
Episode length: 242.40 +/- 17.20
---------------------------------
| eval/              |          |
|    mean_ep_length  | 242      |
|    mean_reward     | 63.9     |
| time/              |          |
|    total_timesteps | 5000     |
| train/             |          |
|    actor_loss      | 1.34     |
|    critic_loss     | 3.02     |
|    learning_rate   | 0.000995 |
|    n_updates       | 2456     |
---------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 136      |
|    ep_rew_mean     | -3.29    |
| time/              |          |
|    episodes        | 40       |
|    fps             | 15       |
|    time_elapsed    | 342      |
|    total timesteps | 5441     |
| train/             |          |
|    actor_loss      | 1.39     |
|    critic_loss     | 2.84     |
|    learning_rate   | 0.000995 |
|    n_updates       | 2707     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 133      |
|    ep_rew_mean     | -3.25    |
| time/              |          |
|    episodes        | 44       |
|    fps             | 14       |
|    time_elapsed    | 392      |
|    total timesteps | 5865     |
| train/             |          |
|    actor_loss      | 1.51     |
|    critic_loss     | 2.84     |
|    learning_rate   | 0.000994 |
|    n_updates       | 3131     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 136      |
|    ep_rew_mean     | -3.06    |
| time/              |          |
|    episodes        | 48       |
|    fps             | 13       |
|    time_elapsed    | 467      |
|    total timesteps | 6517     |
| train/             |          |
|    actor_loss      | 1.08     |
|    critic_loss     | 2.99     |
|    learning_rate   | 0.000994 |
|    n_updates       | 3783     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 140      |
|    ep_rew_mean     | -0.981   |
| time/              |          |
|    episodes        | 52       |
|    fps             | 12       |
|    time_elapsed    | 563      |
|    total timesteps | 7258     |
| train/             |          |
|    actor_loss      | 0.936    |
|    critic_loss     | 2.94     |
|    learning_rate   | 0.000993 |
|    n_updates       | 4630     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 143      |
|    ep_rew_mean     | -1.13    |
| time/              |          |
|    episodes        | 56       |
|    fps             | 12       |
|    time_elapsed    | 635      |
|    total timesteps | 8015     |
| train/             |          |
|    actor_loss      | 0.85     |
|    critic_loss     | 3.01     |
|    learning_rate   | 0.000992 |
|    n_updates       | 5281     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 141      |
|    ep_rew_mean     | -1.45    |
| time/              |          |
|    episodes        | 60       |
|    fps             | 12       |
|    time_elapsed    | 699      |
|    total timesteps | 8459     |
| train/             |          |
|    actor_loss      | 0.796    |
|    critic_loss     | 3        |
|    learning_rate   | 0.000992 |
|    n_updates       | 5862     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 143      |
|    ep_rew_mean     | -1.34    |
| time/              |          |
|    episodes        | 64       |
|    fps             | 12       |
|    time_elapsed    | 760      |
|    total timesteps | 9137     |
| train/             |          |
|    actor_loss      | 0.765    |
|    critic_loss     | 3.02     |
|    learning_rate   | 0.000991 |
|    n_updates       | 6403     |
---------------------------------
Eval num_timesteps=10000, episode_reward=68.72 +/- 6.08
Episode length: 251.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 251      |
|    mean_reward     | 68.7     |
| time/              |          |
|    total_timesteps | 10000    |
| train/             |          |
|    actor_loss      | 0.715    |
|    critic_loss     | 2.81     |
|    learning_rate   | 0.00099  |
|    n_updates       | 7282     |
---------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 147      |
|    ep_rew_mean     | -0.726   |
| time/              |          |
|    episodes        | 68       |
|    fps             | 11       |
|    time_elapsed    | 871      |
|    total timesteps | 10016    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 147      |
|    ep_rew_mean     | -0.918   |
| time/              |          |
|    episodes        | 72       |
|    fps             | 11       |
|    time_elapsed    | 940      |
|    total timesteps | 10571    |
| train/             |          |
|    actor_loss      | 0.702    |
|    critic_loss     | 2.76     |
|    learning_rate   | 0.00099  |
|    n_updates       | 7910     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 147      |
|    ep_rew_mean     | -1.01    |
| time/              |          |
|    episodes        | 76       |
|    fps             | 11       |
|    time_elapsed    | 1013     |
|    total timesteps | 11204    |
| train/             |          |
|    actor_loss      | 0.686    |
|    critic_loss     | 2.75     |
|    learning_rate   | 0.000989 |
|    n_updates       | 8568     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 146      |
|    ep_rew_mean     | -1.11    |
| time/              |          |
|    episodes        | 80       |
|    fps             | 11       |
|    time_elapsed    | 1057     |
|    total timesteps | 11692    |
| train/             |          |
|    actor_loss      | 0.674    |
|    critic_loss     | 2.83     |
|    learning_rate   | 0.000989 |
|    n_updates       | 8958     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 146      |
|    ep_rew_mean     | -1.24    |
| time/              |          |
|    episodes        | 84       |
|    fps             | 10       |
|    time_elapsed    | 1134     |
|    total timesteps | 12266    |
| train/             |          |
|    actor_loss      | 0.631    |
|    critic_loss     | 2.86     |
|    learning_rate   | 0.000988 |
|    n_updates       | 9664     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 145      |
|    ep_rew_mean     | -1.45    |
| time/              |          |
|    episodes        | 88       |
|    fps             | 10       |
|    time_elapsed    | 1178     |
|    total timesteps | 12758    |
| train/             |          |
|    actor_loss      | 0.673    |
|    critic_loss     | 2.97     |
|    learning_rate   | 0.000988 |
|    n_updates       | 10045    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 148      |
|    ep_rew_mean     | -0.312   |
| time/              |          |
|    episodes        | 92       |
|    fps             | 10       |
|    time_elapsed    | 1272     |
|    total timesteps | 13592    |
| train/             |          |
|    actor_loss      | 0.65     |
|    critic_loss     | 2.85     |
|    learning_rate   | 0.000987 |
|    n_updates       | 10904    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 146      |
|    ep_rew_mean     | -0.42    |
| time/              |          |
|    episodes        | 96       |
|    fps             | 10       |
|    time_elapsed    | 1338     |
|    total timesteps | 14051    |
| train/             |          |
|    actor_loss      | 0.608    |
|    critic_loss     | 2.78     |
|    learning_rate   | 0.000986 |
|    n_updates       | 11513    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 144      |
|    ep_rew_mean     | -0.726   |
| time/              |          |
|    episodes        | 100      |
|    fps             | 10       |
|    time_elapsed    | 1372     |
|    total timesteps | 14429    |
| train/             |          |
|    actor_loss      | 0.614    |
|    critic_loss     | 3.01     |
|    learning_rate   | 0.000986 |
|    n_updates       | 11809    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 142      |
|    ep_rew_mean     | -0.807   |
| time/              |          |
|    episodes        | 104      |
|    fps             | 10       |
|    time_elapsed    | 1434     |
|    total timesteps | 14920    |
| train/             |          |
|    actor_loss      | 0.595    |
|    critic_loss     | 3.05     |
|    learning_rate   | 0.000985 |
|    n_updates       | 12378    |
---------------------------------
Eval num_timesteps=15000, episode_reward=74.42 +/- 2.83
Episode length: 251.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 251      |
|    mean_reward     | 74.4     |
| time/              |          |
|    total_timesteps | 15000    |
| train/             |          |
|    actor_loss      | 0.588    |
|    critic_loss     | 3.1      |
|    learning_rate   | 0.000985 |
|    n_updates       | 12437    |
---------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 145      |
|    ep_rew_mean     | -0.689   |
| time/              |          |
|    episodes        | 108      |
|    fps             | 10       |
|    time_elapsed    | 1507     |
|    total timesteps | 15537    |
| train/             |          |
|    actor_loss      | 0.554    |
|    critic_loss     | 3.1      |
|    learning_rate   | 0.000985 |
|    n_updates       | 12909    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 145      |
|    ep_rew_mean     | -0.552   |
| time/              |          |
|    episodes        | 112      |
|    fps             | 10       |
|    time_elapsed    | 1569     |
|    total timesteps | 16046    |
| train/             |          |
|    actor_loss      | 0.513    |
|    critic_loss     | 3.07     |
|    learning_rate   | 0.000984 |
|    n_updates       | 13474    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 145      |
|    ep_rew_mean     | -0.697   |
| time/              |          |
|    episodes        | 116      |
|    fps             | 10       |
|    time_elapsed    | 1628     |
|    total timesteps | 16595    |
| train/             |          |
|    actor_loss      | 0.51     |
|    critic_loss     | 3.23     |
|    learning_rate   | 0.000984 |
|    n_updates       | 14003    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 147      |
|    ep_rew_mean     | 0.582    |
| time/              |          |
|    episodes        | 120      |
|    fps             | 10       |
|    time_elapsed    | 1697     |
|    total timesteps | 17163    |
| train/             |          |
|    actor_loss      | 0.465    |
|    critic_loss     | 3.32     |
|    learning_rate   | 0.000983 |
|    n_updates       | 14641    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 146      |
|    ep_rew_mean     | 0.197    |
| time/              |          |
|    episodes        | 124      |
|    fps             | 10       |
|    time_elapsed    | 1744     |
|    total timesteps | 17624    |
| train/             |          |
|    actor_loss      | 0.463    |
|    critic_loss     | 3.47     |
|    learning_rate   | 0.000983 |
|    n_updates       | 15058    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 144      |
|    ep_rew_mean     | -0.00743 |
| time/              |          |
|    episodes        | 128      |
|    fps             | 10       |
|    time_elapsed    | 1809     |
|    total timesteps | 18281    |
| train/             |          |
|    actor_loss      | 0.415    |
|    critic_loss     | 3.31     |
|    learning_rate   | 0.000982 |
|    n_updates       | 15647    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 145      |
|    ep_rew_mean     | 0.122    |
| time/              |          |
|    episodes        | 132      |
|    fps             | 10       |
|    time_elapsed    | 1864     |
|    total timesteps | 18804    |
| train/             |          |
|    actor_loss      | 0.406    |
|    critic_loss     | 3.35     |
|    learning_rate   | 0.000982 |
|    n_updates       | 16145    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 145      |
|    ep_rew_mean     | 0.0662   |
| time/              |          |
|    episodes        | 136      |
|    fps             | 9        |
|    time_elapsed    | 1924     |
|    total timesteps | 19230    |
| train/             |          |
|    actor_loss      | 0.449    |
|    critic_loss     | 3.3      |
|    learning_rate   | 0.000981 |
|    n_updates       | 16701    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 144      |
|    ep_rew_mean     | 0.0889   |
| time/              |          |
|    episodes        | 140      |
|    fps             | 10       |
|    time_elapsed    | 1978     |
|    total timesteps | 19838    |
| train/             |          |
|    actor_loss      | 0.413    |
|    critic_loss     | 3.39     |
|    learning_rate   | 0.000981 |
|    n_updates       | 17177    |
---------------------------------
Eval num_timesteps=20000, episode_reward=68.60 +/- 11.81
Episode length: 231.40 +/- 24.30
---------------------------------
| eval/              |          |
|    mean_ep_length  | 231      |
|    mean_reward     | 68.6     |
| time/              |          |
|    total_timesteps | 20000    |
| train/             |          |
|    actor_loss      | 0.425    |
|    critic_loss     | 3.49     |
|    learning_rate   | 0.00098  |
|    n_updates       | 17446    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 147      |
|    ep_rew_mean     | 0.516    |
| time/              |          |
|    episodes        | 144      |
|    fps             | 9        |
|    time_elapsed    | 2072     |
|    total timesteps | 20585    |
| train/             |          |
|    actor_loss      | 0.413    |
|    critic_loss     | 3.26     |
|    learning_rate   | 0.00098  |
|    n_updates       | 17910    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 147      |
|    ep_rew_mean     | 0.546    |
| time/              |          |
|    episodes        | 148      |
|    fps             | 9        |
|    time_elapsed    | 2147     |
|    total timesteps | 21171    |
| train/             |          |
|    actor_loss      | 0.427    |
|    critic_loss     | 3.42     |
|    learning_rate   | 0.000979 |
|    n_updates       | 18596    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 147      |
|    ep_rew_mean     | 0.679    |
| time/              |          |
|    episodes        | 152      |
|    fps             | 9        |
|    time_elapsed    | 2214     |
|    total timesteps | 21925    |
| train/             |          |
|    actor_loss      | 0.411    |
|    critic_loss     | 3.32     |
|    learning_rate   | 0.000979 |
|    n_updates       | 19195    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 146      |
|    ep_rew_mean     | 0.74     |
| time/              |          |
|    episodes        | 156      |
|    fps             | 9        |
|    time_elapsed    | 2293     |
|    total timesteps | 22584    |
| train/             |          |
|    actor_loss      | 0.361    |
|    critic_loss     | 3.41     |
|    learning_rate   | 0.000978 |
|    n_updates       | 19915    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 146      |
|    ep_rew_mean     | 0.749    |
| time/              |          |
|    episodes        | 160      |
|    fps             | 9        |
|    time_elapsed    | 2362     |
|    total timesteps | 23091    |
| train/             |          |
|    actor_loss      | 0.328    |
|    critic_loss     | 3.46     |
|    learning_rate   | 0.000977 |
|    n_updates       | 20555    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 146      |
|    ep_rew_mean     | 1.41     |
| time/              |          |
|    episodes        | 164      |
|    fps             | 9        |
|    time_elapsed    | 2417     |
|    total timesteps | 23758    |
| train/             |          |
|    actor_loss      | 0.279    |
|    critic_loss     | 3.58     |
|    learning_rate   | 0.000977 |
|    n_updates       | 21024    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 142      |
|    ep_rew_mean     | 0.756    |
| time/              |          |
|    episodes        | 168      |
|    fps             | 9        |
|    time_elapsed    | 2480     |
|    total timesteps | 24168    |
| train/             |          |
|    actor_loss      | 0.227    |
|    critic_loss     | 3.47     |
|    learning_rate   | 0.000976 |
|    n_updates       | 21566    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 140      |
|    ep_rew_mean     | 0.649    |
| time/              |          |
|    episodes        | 172      |
|    fps             | 9        |
|    time_elapsed    | 2530     |
|    total timesteps | 24597    |
| train/             |          |
|    actor_loss      | 0.222    |
|    critic_loss     | 3.66     |
|    learning_rate   | 0.000976 |
|    n_updates       | 22016    |
---------------------------------
Eval num_timesteps=25000, episode_reward=59.82 +/- 10.13
Episode length: 232.60 +/- 22.54
---------------------------------
| eval/              |          |
|    mean_ep_length  | 233      |
|    mean_reward     | 59.8     |
| time/              |          |
|    total_timesteps | 25000    |
| train/             |          |
|    actor_loss      | 0.218    |
|    critic_loss     | 3.62     |
|    learning_rate   | 0.000975 |
|    n_updates       | 22434    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 139      |
|    ep_rew_mean     | 0.596    |
| time/              |          |
|    episodes        | 176      |
|    fps             | 9        |
|    time_elapsed    | 2601     |
|    total timesteps | 25083    |
| train/             |          |
|    actor_loss      | 0.223    |
|    critic_loss     | 3.58     |
|    learning_rate   | 0.000975 |
|    n_updates       | 22556    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 142      |
|    ep_rew_mean     | 1.15     |
| time/              |          |
|    episodes        | 180      |
|    fps             | 9        |
|    time_elapsed    | 2668     |
|    total timesteps | 25842    |
| train/             |          |
|    actor_loss      | 0.253    |
|    critic_loss     | 3.42     |
|    learning_rate   | 0.000975 |
|    n_updates       | 23155    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 143      |
|    ep_rew_mean     | 1.15     |
| time/              |          |
|    episodes        | 184      |
|    fps             | 9        |
|    time_elapsed    | 2754     |
|    total timesteps | 26578    |
| train/             |          |
|    actor_loss      | 0.245    |
|    critic_loss     | 3.58     |
|    learning_rate   | 0.000974 |
|    n_updates       | 23931    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 145      |
|    ep_rew_mean     | 1.23     |
| time/              |          |
|    episodes        | 188      |
|    fps             | 9        |
|    time_elapsed    | 2831     |
|    total timesteps | 27282    |
| train/             |          |
|    actor_loss      | 0.186    |
|    critic_loss     | 3.49     |
|    learning_rate   | 0.000973 |
|    n_updates       | 24629    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 143      |
|    ep_rew_mean     | 0.359    |
| time/              |          |
|    episodes        | 192      |
|    fps             | 9        |
|    time_elapsed    | 2893     |
|    total timesteps | 27857    |
| train/             |          |
|    actor_loss      | 0.167    |
|    critic_loss     | 3.58     |
|    learning_rate   | 0.000973 |
|    n_updates       | 25182    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 141      |
|    ep_rew_mean     | 0.144    |
| time/              |          |
|    episodes        | 196      |
|    fps             | 9        |
|    time_elapsed    | 2933     |
|    total timesteps | 28128    |
| train/             |          |
|    actor_loss      | 0.153    |
|    critic_loss     | 3.82     |
|    learning_rate   | 0.000972 |
|    n_updates       | 25550    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 143      |
|    ep_rew_mean     | 0.491    |
| time/              |          |
|    episodes        | 200      |
|    fps             | 9        |
|    time_elapsed    | 2988     |
|    total timesteps | 28762    |
| train/             |          |
|    actor_loss      | 0.163    |
|    critic_loss     | 3.72     |
|    learning_rate   | 0.000972 |
|    n_updates       | 26028    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 144      |
|    ep_rew_mean     | 0.373    |
| time/              |          |
|    episodes        | 204      |
|    fps             | 9        |
|    time_elapsed    | 3054     |
|    total timesteps | 29328    |
| train/             |          |
|    actor_loss      | 0.177    |
|    critic_loss     | 3.8      |
|    learning_rate   | 0.000971 |
|    n_updates       | 26630    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 141      |
|    ep_rew_mean     | 0.307    |
| time/              |          |
|    episodes        | 208      |
|    fps             | 9        |
|    time_elapsed    | 3109     |
|    total timesteps | 29667    |
| train/             |          |
|    actor_loss      | 0.148    |
|    critic_loss     | 3.71     |
|    learning_rate   | 0.000971 |
|    n_updates       | 27139    |
---------------------------------
Eval num_timesteps=30000, episode_reward=66.57 +/- 13.89
Episode length: 230.60 +/- 20.30
---------------------------------
| eval/              |          |
|    mean_ep_length  | 231      |
|    mean_reward     | 66.6     |
| time/              |          |
|    total_timesteps | 30000    |
| train/             |          |
|    actor_loss      | 0.14     |
|    critic_loss     | 3.59     |
|    learning_rate   | 0.00097  |
|    n_updates       | 27390    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 144      |
|    ep_rew_mean     | 0.411    |
| time/              |          |
|    episodes        | 212      |
|    fps             | 9        |
|    time_elapsed    | 3194     |
|    total timesteps | 30453    |
| train/             |          |
|    actor_loss      | 0.147    |
|    critic_loss     | 3.66     |
|    learning_rate   | 0.00097  |
|    n_updates       | 27797    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 145      |
|    ep_rew_mean     | 0.879    |
| time/              |          |
|    episodes        | 216      |
|    fps             | 9        |
|    time_elapsed    | 3281     |
|    total timesteps | 31108    |
| train/             |          |
|    actor_loss      | 0.165    |
|    critic_loss     | 3.6      |
|    learning_rate   | 0.000969 |
|    n_updates       | 28592    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 145      |
|    ep_rew_mean     | -0.218   |
| time/              |          |
|    episodes        | 220      |
|    fps             | 9        |
|    time_elapsed    | 3341     |
|    total timesteps | 31695    |
| train/             |          |
|    actor_loss      | 0.168    |
|    critic_loss     | 3.62     |
|    learning_rate   | 0.000969 |
|    n_updates       | 29126    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 147      |
|    ep_rew_mean     | -0.181   |
| time/              |          |
|    episodes        | 224      |
|    fps             | 9        |
|    time_elapsed    | 3413     |
|    total timesteps | 32329    |
| train/             |          |
|    actor_loss      | 0.165    |
|    critic_loss     | 3.59     |
|    learning_rate   | 0.000968 |
|    n_updates       | 29784    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 148      |
|    ep_rew_mean     | -0.0642  |
| time/              |          |
|    episodes        | 228      |
|    fps             | 9        |
|    time_elapsed    | 3477     |
|    total timesteps | 33085    |
| train/             |          |
|    actor_loss      | 0.162    |
|    critic_loss     | 3.57     |
|    learning_rate   | 0.000967 |
|    n_updates       | 30351    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 151      |
|    ep_rew_mean     | 0.0901   |
| time/              |          |
|    episodes        | 232      |
|    fps             | 9        |
|    time_elapsed    | 3572     |
|    total timesteps | 33926    |
| train/             |          |
|    actor_loss      | 0.172    |
|    critic_loss     | 3.48     |
|    learning_rate   | 0.000967 |
|    n_updates       | 31222    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 150      |
|    ep_rew_mean     | 0.0508   |
| time/              |          |
|    episodes        | 236      |
|    fps             | 9        |
|    time_elapsed    | 3621     |
|    total timesteps | 34267    |
| train/             |          |
|    actor_loss      | 0.17     |
|    critic_loss     | 3.54     |
|    learning_rate   | 0.000966 |
|    n_updates       | 31668    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 152      |
|    ep_rew_mean     | -0.107   |
| time/              |          |
|    episodes        | 240      |
|    fps             | 9        |
|    time_elapsed    | 3699     |
|    total timesteps | 34994    |
| train/             |          |
|    actor_loss      | 0.179    |
|    critic_loss     | 3.57     |
|    learning_rate   | 0.000965 |
|    n_updates       | 32373    |
---------------------------------
Eval num_timesteps=35000, episode_reward=54.13 +/- 14.02
Episode length: 242.80 +/- 16.40
---------------------------------
| eval/              |          |
|    mean_ep_length  | 243      |
|    mean_reward     | 54.1     |
| time/              |          |
|    total_timesteps | 35000    |
| train/             |          |
|    actor_loss      | 0.178    |
|    critic_loss     | 3.52     |
|    learning_rate   | 0.000965 |
|    n_updates       | 32511    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 149      |
|    ep_rew_mean     | -0.613   |
| time/              |          |
|    episodes        | 244      |
|    fps             | 9        |
|    time_elapsed    | 3755     |
|    total timesteps | 35497    |
| train/             |          |
|    actor_loss      | 0.179    |
|    critic_loss     | 3.52     |
|    learning_rate   | 0.000965 |
|    n_updates       | 32763    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 147      |
|    ep_rew_mean     | -0.869   |
| time/              |          |
|    episodes        | 248      |
|    fps             | 9        |
|    time_elapsed    | 3812     |
|    total timesteps | 35912    |
| train/             |          |
|    actor_loss      | 0.201    |
|    critic_loss     | 3.69     |
|    learning_rate   | 0.000965 |
|    n_updates       | 33288    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 145      |
|    ep_rew_mean     | -2.07    |
| time/              |          |
|    episodes        | 252      |
|    fps             | 9        |
|    time_elapsed    | 3860     |
|    total timesteps | 36451    |
| train/             |          |
|    actor_loss      | 0.203    |
|    critic_loss     | 3.6      |
|    learning_rate   | 0.000964 |
|    n_updates       | 33717    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 143      |
|    ep_rew_mean     | -2.29    |
| time/              |          |
|    episodes        | 256      |
|    fps             | 9        |
|    time_elapsed    | 3918     |
|    total timesteps | 36916    |
| train/             |          |
|    actor_loss      | 0.201    |
|    critic_loss     | 3.62     |
|    learning_rate   | 0.000964 |
|    n_updates       | 34248    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 145      |
|    ep_rew_mean     | -1.82    |
| time/              |          |
|    episodes        | 260      |
|    fps             | 9        |
|    time_elapsed    | 4000     |
|    total timesteps | 37604    |
| train/             |          |
|    actor_loss      | 0.213    |
|    critic_loss     | 3.44     |
|    learning_rate   | 0.000963 |
|    n_updates       | 34996    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 144      |
|    ep_rew_mean     | -2.67    |
| time/              |          |
|    episodes        | 264      |
|    fps             | 9        |
|    time_elapsed    | 4059     |
|    total timesteps | 38108    |
| train/             |          |
|    actor_loss      | 0.244    |
|    critic_loss     | 3.5      |
|    learning_rate   | 0.000962 |
|    n_updates       | 35495    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 144      |
|    ep_rew_mean     | -2.68    |
| time/              |          |
|    episodes        | 268      |
|    fps             | 9        |
|    time_elapsed    | 4112     |
|    total timesteps | 38608    |
| train/             |          |
|    actor_loss      | 0.264    |
|    critic_loss     | 3.59     |
|    learning_rate   | 0.000962 |
|    n_updates       | 35952    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 143      |
|    ep_rew_mean     | -2.71    |
| time/              |          |
|    episodes        | 272      |
|    fps             | 9        |
|    time_elapsed    | 4152     |
|    total timesteps | 38899    |
| train/             |          |
|    actor_loss      | 0.303    |
|    critic_loss     | 3.34     |
|    learning_rate   | 0.000962 |
|    n_updates       | 36326    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 144      |
|    ep_rew_mean     | -2.67    |
| time/              |          |
|    episodes        | 276      |
|    fps             | 9        |
|    time_elapsed    | 4206     |
|    total timesteps | 39436    |
| train/             |          |
|    actor_loss      | 0.289    |
|    critic_loss     | 3.22     |
|    learning_rate   | 0.000961 |
|    n_updates       | 36805    |
---------------------------------
Eval num_timesteps=40000, episode_reward=76.42 +/- 12.40
Episode length: 249.80 +/- 2.40
---------------------------------
| eval/              |          |
|    mean_ep_length  | 250      |
|    mean_reward     | 76.4     |
| time/              |          |
|    total_timesteps | 40000    |
| train/             |          |
|    actor_loss      | 0.303    |
|    critic_loss     | 3.43     |
|    learning_rate   | 0.00096  |
|    n_updates       | 37417    |
---------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 143      |
|    ep_rew_mean     | -3.27    |
| time/              |          |
|    episodes        | 280      |
|    fps             | 9        |
|    time_elapsed    | 4304     |
|    total timesteps | 40108    |
| train/             |          |
|    actor_loss      | 0.306    |
|    critic_loss     | 3.43     |
|    learning_rate   | 0.00096  |
|    n_updates       | 37584    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 142      |
|    ep_rew_mean     | -3.29    |
| time/              |          |
|    episodes        | 284      |
|    fps             | 9        |
|    time_elapsed    | 4377     |
|    total timesteps | 40789    |
| train/             |          |
|    actor_loss      | 0.332    |
|    critic_loss     | 3.38     |
|    learning_rate   | 0.00096  |
|    n_updates       | 38236    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 142      |
|    ep_rew_mean     | -2.69    |
| time/              |          |
|    episodes        | 288      |
|    fps             | 9        |
|    time_elapsed    | 4438     |
|    total timesteps | 41468    |
| train/             |          |
|    actor_loss      | 0.344    |
|    critic_loss     | 3.37     |
|    learning_rate   | 0.000959 |
|    n_updates       | 38775    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 142      |
|    ep_rew_mean     | -2.81    |
| time/              |          |
|    episodes        | 292      |
|    fps             | 9        |
|    time_elapsed    | 4527     |
|    total timesteps | 42107    |
| train/             |          |
|    actor_loss      | 0.333    |
|    critic_loss     | 3.37     |
|    learning_rate   | 0.000958 |
|    n_updates       | 39596    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 146      |
|    ep_rew_mean     | -2.74    |
| time/              |          |
|    episodes        | 296      |
|    fps             | 9        |
|    time_elapsed    | 4587     |
|    total timesteps | 42731    |
| train/             |          |
|    actor_loss      | 0.338    |
|    critic_loss     | 3.53     |
|    learning_rate   | 0.000958 |
|    n_updates       | 40125    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 144      |
|    ep_rew_mean     | -3.06    |
| time/              |          |
|    episodes        | 300      |
|    fps             | 9        |
|    time_elapsed    | 4640     |
|    total timesteps | 43178    |
| train/             |          |
|    actor_loss      | 0.34     |
|    critic_loss     | 3.22     |
|    learning_rate   | 0.000957 |
|    n_updates       | 40600    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 143      |
|    ep_rew_mean     | -3.1     |
| time/              |          |
|    episodes        | 304      |
|    fps             | 9        |
|    time_elapsed    | 4694     |
|    total timesteps | 43606    |
| train/             |          |
|    actor_loss      | 0.349    |
|    critic_loss     | 3.44     |
|    learning_rate   | 0.000957 |
|    n_updates       | 41091    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 144      |
|    ep_rew_mean     | -3.1     |
| time/              |          |
|    episodes        | 308      |
|    fps             | 9        |
|    time_elapsed    | 4747     |
|    total timesteps | 44100    |
| train/             |          |
|    actor_loss      | 0.351    |
|    critic_loss     | 3.41     |
|    learning_rate   | 0.000956 |
|    n_updates       | 41563    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 141      |
|    ep_rew_mean     | -3.17    |
| time/              |          |
|    episodes        | 312      |
|    fps             | 9        |
|    time_elapsed    | 4790     |
|    total timesteps | 44521    |
| train/             |          |
|    actor_loss      | 0.353    |
|    critic_loss     | 3.48     |
|    learning_rate   | 0.000956 |
|    n_updates       | 41955    |
---------------------------------
Eval num_timesteps=45000, episode_reward=43.37 +/- 20.49
Episode length: 241.20 +/- 19.60
---------------------------------
| eval/              |          |
|    mean_ep_length  | 241      |
|    mean_reward     | 43.4     |
| time/              |          |
|    total_timesteps | 45000    |
| train/             |          |
|    actor_loss      | 0.351    |
|    critic_loss     | 3.38     |
|    learning_rate   | 0.000956 |
|    n_updates       | 42289    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 144      |
|    ep_rew_mean     | -1.69    |
| time/              |          |
|    episodes        | 316      |
|    fps             | 9        |
|    time_elapsed    | 4897     |
|    total timesteps | 45525    |
| train/             |          |
|    actor_loss      | 0.351    |
|    critic_loss     | 3.42     |
|    learning_rate   | 0.000955 |
|    n_updates       | 42791    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 145      |
|    ep_rew_mean     | -1.58    |
| time/              |          |
|    episodes        | 320      |
|    fps             | 9        |
|    time_elapsed    | 4987     |
|    total timesteps | 46205    |
| train/             |          |
|    actor_loss      | 0.337    |
|    critic_loss     | 3.43     |
|    learning_rate   | 0.000954 |
|    n_updates       | 43626    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 146      |
|    ep_rew_mean     | -1.4     |
| time/              |          |
|    episodes        | 324      |
|    fps             | 9        |
|    time_elapsed    | 5056     |
|    total timesteps | 46965    |
| train/             |          |
|    actor_loss      | 0.327    |
|    critic_loss     | 3.46     |
|    learning_rate   | 0.000954 |
|    n_updates       | 44231    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 142      |
|    ep_rew_mean     | -1.62    |
| time/              |          |
|    episodes        | 328      |
|    fps             | 9        |
|    time_elapsed    | 5111     |
|    total timesteps | 47258    |
| train/             |          |
|    actor_loss      | 0.322    |
|    critic_loss     | 3.43     |
|    learning_rate   | 0.000953 |
|    n_updates       | 44749    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 139      |
|    ep_rew_mean     | -1.78    |
| time/              |          |
|    episodes        | 332      |
|    fps             | 9        |
|    time_elapsed    | 5158     |
|    total timesteps | 47832    |
| train/             |          |
|    actor_loss      | 0.319    |
|    critic_loss     | 3.52     |
|    learning_rate   | 0.000953 |
|    n_updates       | 45162    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 144      |
|    ep_rew_mean     | -1.26    |
| time/              |          |
|    episodes        | 336      |
|    fps             | 9        |
|    time_elapsed    | 5249     |
|    total timesteps | 48713    |
| train/             |          |
|    actor_loss      | 0.326    |
|    critic_loss     | 3.47     |
|    learning_rate   | 0.000952 |
|    n_updates       | 45979    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 140      |
|    ep_rew_mean     | -1.67    |
| time/              |          |
|    episodes        | 340      |
|    fps             | 9        |
|    time_elapsed    | 5301     |
|    total timesteps | 48990    |
| train/             |          |
|    actor_loss      | 0.434    |
|    critic_loss     | 3.48     |
|    learning_rate   | 0.000952 |
|    n_updates       | 46460    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 140      |
|    ep_rew_mean     | -1.68    |
| time/              |          |
|    episodes        | 344      |
|    fps             | 9        |
|    time_elapsed    | 5347     |
|    total timesteps | 49545    |
| train/             |          |
|    actor_loss      | 0.381    |
|    critic_loss     | 3.27     |
|    learning_rate   | 0.000951 |
|    n_updates       | 46865    |
---------------------------------
Eval num_timesteps=50000, episode_reward=54.18 +/- 22.26
Episode length: 251.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 251      |
|    mean_reward     | 54.2     |
| time/              |          |
|    total_timesteps | 50000    |
| train/             |          |
|    actor_loss      | 0.405    |
|    critic_loss     | 3.36     |
|    learning_rate   | 0.000951 |
|    n_updates       | 47436    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 143      |
|    ep_rew_mean     | -1.66    |
| time/              |          |
|    episodes        | 348      |
|    fps             | 9        |
|    time_elapsed    | 5445     |
|    total timesteps | 50228    |
| train/             |          |
|    actor_loss      | 0.398    |
|    critic_loss     | 3.4      |
|    learning_rate   | 0.00095  |
|    n_updates       | 47643    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 144      |
|    ep_rew_mean     | -1.62    |
| time/              |          |
|    episodes        | 352      |
|    fps             | 9        |
|    time_elapsed    | 5509     |
|    total timesteps | 50892    |
| train/             |          |
|    actor_loss      | 0.371    |
|    critic_loss     | 3.31     |
|    learning_rate   | 0.00095  |
|    n_updates       | 48215    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 144      |
|    ep_rew_mean     | -1.16    |
| time/              |          |
|    episodes        | 356      |
|    fps             | 9        |
|    time_elapsed    | 5567     |
|    total timesteps | 51356    |
| train/             |          |
|    actor_loss      | 0.355    |
|    critic_loss     | 3.46     |
|    learning_rate   | 0.000949 |
|    n_updates       | 48743    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 146      |
|    ep_rew_mean     | -1.02    |
| time/              |          |
|    episodes        | 360      |
|    fps             | 9        |
|    time_elapsed    | 5650     |
|    total timesteps | 52199    |
| train/             |          |
|    actor_loss      | 0.334    |
|    critic_loss     | 3.43     |
|    learning_rate   | 0.000949 |
|    n_updates       | 49465    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 147      |
|    ep_rew_mean     | -0.012   |
| time/              |          |
|    episodes        | 364      |
|    fps             | 9        |
|    time_elapsed    | 5733     |
|    total timesteps | 52788    |
| train/             |          |
|    actor_loss      | 0.296    |
|    critic_loss     | 3.28     |
|    learning_rate   | 0.000948 |
|    n_updates       | 50181    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 146      |
|    ep_rew_mean     | -0.0596  |
| time/              |          |
|    episodes        | 368      |
|    fps             | 9        |
|    time_elapsed    | 5796     |
|    total timesteps | 53251    |
| train/             |          |
|    actor_loss      | 0.297    |
|    critic_loss     | 3.53     |
|    learning_rate   | 0.000947 |
|    n_updates       | 50723    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 150      |
|    ep_rew_mean     | 0.0397   |
| time/              |          |
|    episodes        | 372      |
|    fps             | 9        |
|    time_elapsed    | 5867     |
|    total timesteps | 53899    |
| train/             |          |
|    actor_loss      | 0.286    |
|    critic_loss     | 3.53     |
|    learning_rate   | 0.000947 |
|    n_updates       | 51329    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 149      |
|    ep_rew_mean     | -0.146   |
| time/              |          |
|    episodes        | 376      |
|    fps             | 9        |
|    time_elapsed    | 5913     |
|    total timesteps | 54347    |
| train/             |          |
|    actor_loss      | 0.275    |
|    critic_loss     | 3.44     |
|    learning_rate   | 0.000946 |
|    n_updates       | 51737    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 147      |
|    ep_rew_mean     | -0.226   |
| time/              |          |
|    episodes        | 380      |
|    fps             | 9        |
|    time_elapsed    | 5958     |
|    total timesteps | 54763    |
| train/             |          |
|    actor_loss      | 0.276    |
|    critic_loss     | 3.53     |
|    learning_rate   | 0.000946 |
|    n_updates       | 52143    |
---------------------------------
Eval num_timesteps=55000, episode_reward=59.89 +/- 14.51
Episode length: 232.20 +/- 23.03
---------------------------------
| eval/              |          |
|    mean_ep_length  | 232      |
|    mean_reward     | 59.9     |
| time/              |          |
|    total_timesteps | 55000    |
| train/             |          |
|    actor_loss      | 0.268    |
|    critic_loss     | 3.49     |
|    learning_rate   | 0.000946 |
|    n_updates       | 52480    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 143      |
|    ep_rew_mean     | -0.371   |
| time/              |          |
|    episodes        | 384      |
|    fps             | 9        |
|    time_elapsed    | 6019     |
|    total timesteps | 55131    |
| train/             |          |
|    actor_loss      | 0.266    |
|    critic_loss     | 3.47     |
|    learning_rate   | 0.000945 |
|    n_updates       | 52590    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 142      |
|    ep_rew_mean     | -0.661   |
| time/              |          |
|    episodes        | 388      |
|    fps             | 9        |
|    time_elapsed    | 6079     |
|    total timesteps | 55653    |
| train/             |          |
|    actor_loss      | 0.354    |
|    critic_loss     | 3.5      |
|    learning_rate   | 0.000945 |
|    n_updates       | 53138    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 143      |
|    ep_rew_mean     | -0.55    |
| time/              |          |
|    episodes        | 392      |
|    fps             | 9        |
|    time_elapsed    | 6140     |
|    total timesteps | 56398    |
| train/             |          |
|    actor_loss      | 0.318    |
|    critic_loss     | 3.73     |
|    learning_rate   | 0.000944 |
|    n_updates       | 53664    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 142      |
|    ep_rew_mean     | 0.0614   |
| time/              |          |
|    episodes        | 396      |
|    fps             | 9        |
|    time_elapsed    | 6218     |
|    total timesteps | 56977    |
| train/             |          |
|    actor_loss      | 0.329    |
|    critic_loss     | 3.56     |
|    learning_rate   | 0.000944 |
|    n_updates       | 54378    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 142      |
|    ep_rew_mean     | 0.124    |
| time/              |          |
|    episodes        | 400      |
|    fps             | 9        |
|    time_elapsed    | 6266     |
|    total timesteps | 57413    |
| train/             |          |
|    actor_loss      | 0.307    |
|    critic_loss     | 3.65     |
|    learning_rate   | 0.000943 |
|    n_updates       | 54817    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 146      |
|    ep_rew_mean     | 0.383    |
| time/              |          |
|    episodes        | 404      |
|    fps             | 9        |
|    time_elapsed    | 6359     |
|    total timesteps | 58198    |
| train/             |          |
|    actor_loss      | 0.296    |
|    critic_loss     | 3.56     |
|    learning_rate   | 0.000942 |
|    n_updates       | 55660    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 149      |
|    ep_rew_mean     | 1.53     |
| time/              |          |
|    episodes        | 408      |
|    fps             | 9        |
|    time_elapsed    | 6426     |
|    total timesteps | 58980    |
| train/             |          |
|    actor_loss      | 0.283    |
|    critic_loss     | 3.51     |
|    learning_rate   | 0.000942 |
|    n_updates       | 56246    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 150      |
|    ep_rew_mean     | 1.91     |
| time/              |          |
|    episodes        | 412      |
|    fps             | 9        |
|    time_elapsed    | 6508     |
|    total timesteps | 59510    |
| train/             |          |
|    actor_loss      | 0.268    |
|    critic_loss     | 3.62     |
|    learning_rate   | 0.000941 |
|    n_updates       | 56973    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 144      |
|    ep_rew_mean     | 0.0571   |
| time/              |          |
|    episodes        | 416      |
|    fps             | 9        |
|    time_elapsed    | 6558     |
|    total timesteps | 59958    |
| train/             |          |
|    actor_loss      | 0.254    |
|    critic_loss     | 3.56     |
|    learning_rate   | 0.000941 |
|    n_updates       | 57427    |
---------------------------------
Eval num_timesteps=60000, episode_reward=42.88 +/- 16.67
Episode length: 221.20 +/- 24.51
---------------------------------
| eval/              |          |
|    mean_ep_length  | 221      |
|    mean_reward     | 42.9     |
| time/              |          |
|    total_timesteps | 60000    |
| train/             |          |
|    actor_loss      | 0.256    |
|    critic_loss     | 3.74     |
|    learning_rate   | 0.000941 |
|    n_updates       | 57475    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 144      |
|    ep_rew_mean     | -0.0702  |
| time/              |          |
|    episodes        | 420      |
|    fps             | 9        |
|    time_elapsed    | 6634     |
|    total timesteps | 60625    |
| train/             |          |
|    actor_loss      | 0.274    |
|    critic_loss     | 3.67     |
|    learning_rate   | 0.00094  |
|    n_updates       | 58008    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 143      |
|    ep_rew_mean     | -0.184   |
| time/              |          |
|    episodes        | 424      |
|    fps             | 9        |
|    time_elapsed    | 6694     |
|    total timesteps | 61235    |
| train/             |          |
|    actor_loss      | 0.267    |
|    critic_loss     | 3.54     |
|    learning_rate   | 0.00094  |
|    n_updates       | 58546    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 145      |
|    ep_rew_mean     | -0.119   |
| time/              |          |
|    episodes        | 428      |
|    fps             | 9        |
|    time_elapsed    | 6764     |
|    total timesteps | 61801    |
| train/             |          |
|    actor_loss      | 0.252    |
|    critic_loss     | 3.51     |
|    learning_rate   | 0.000939 |
|    n_updates       | 59187    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 145      |
|    ep_rew_mean     | 0.375    |
| time/              |          |
|    episodes        | 432      |
|    fps             | 9        |
|    time_elapsed    | 6829     |
|    total timesteps | 62379    |
| train/             |          |
|    actor_loss      | 0.245    |
|    critic_loss     | 3.53     |
|    learning_rate   | 0.000938 |
|    n_updates       | 59756    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 144      |
|    ep_rew_mean     | 0.679    |
| time/              |          |
|    episodes        | 436      |
|    fps             | 9        |
|    time_elapsed    | 6913     |
|    total timesteps | 63119    |
| train/             |          |
|    actor_loss      | 0.229    |
|    critic_loss     | 3.66     |
|    learning_rate   | 0.000938 |
|    n_updates       | 60523    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 145      |
|    ep_rew_mean     | 0.695    |
| time/              |          |
|    episodes        | 440      |
|    fps             | 9        |
|    time_elapsed    | 6956     |
|    total timesteps | 63450    |
| train/             |          |
|    actor_loss      | 0.23     |
|    critic_loss     | 3.56     |
|    learning_rate   | 0.000937 |
|    n_updates       | 60915    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 146      |
|    ep_rew_mean     | 0.803    |
| time/              |          |
|    episodes        | 444      |
|    fps             | 9        |
|    time_elapsed    | 7024     |
|    total timesteps | 64187    |
| train/             |          |
|    actor_loss      | 0.231    |
|    critic_loss     | 3.71     |
|    learning_rate   | 0.000937 |
|    n_updates       | 61516    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 144      |
|    ep_rew_mean     | 0.817    |
| time/              |          |
|    episodes        | 448      |
|    fps             | 9        |
|    time_elapsed    | 7072     |
|    total timesteps | 64606    |
| train/             |          |
|    actor_loss      | 0.256    |
|    critic_loss     | 3.62     |
|    learning_rate   | 0.000936 |
|    n_updates       | 61952    |
---------------------------------
Eval num_timesteps=65000, episode_reward=56.53 +/- 12.55
Episode length: 232.60 +/- 22.57
---------------------------------
| eval/              |          |
|    mean_ep_length  | 233      |
|    mean_reward     | 56.5     |
| time/              |          |
|    total_timesteps | 65000    |
| train/             |          |
|    actor_loss      | 0.246    |
|    critic_loss     | 3.64     |
|    learning_rate   | 0.000936 |
|    n_updates       | 62496    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 144      |
|    ep_rew_mean     | 0.932    |
| time/              |          |
|    episodes        | 452      |
|    fps             | 9        |
|    time_elapsed    | 7171     |
|    total timesteps | 65326    |
| train/             |          |
|    actor_loss      | 0.247    |
|    critic_loss     | 3.61     |
|    learning_rate   | 0.000935 |
|    n_updates       | 62747    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 144      |
|    ep_rew_mean     | 0.582    |
| time/              |          |
|    episodes        | 456      |
|    fps             | 9        |
|    time_elapsed    | 7212     |
|    total timesteps | 65707    |
| train/             |          |
|    actor_loss      | 0.25     |
|    critic_loss     | 3.61     |
|    learning_rate   | 0.000935 |
|    n_updates       | 63094    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 143      |
|    ep_rew_mean     | 0.206    |
| time/              |          |
|    episodes        | 460      |
|    fps             | 9        |
|    time_elapsed    | 7291     |
|    total timesteps | 66488    |
| train/             |          |
|    actor_loss      | 0.242    |
|    critic_loss     | 3.57     |
|    learning_rate   | 0.000934 |
|    n_updates       | 63754    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 145      |
|    ep_rew_mean     | -0.624   |
| time/              |          |
|    episodes        | 464      |
|    fps             | 9        |
|    time_elapsed    | 7388     |
|    total timesteps | 67302    |
| train/             |          |
|    actor_loss      | 0.238    |
|    critic_loss     | 3.6      |
|    learning_rate   | 0.000934 |
|    n_updates       | 64568    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 148      |
|    ep_rew_mean     | -0.393   |
| time/              |          |
|    episodes        | 468      |
|    fps             | 9        |
|    time_elapsed    | 7478     |
|    total timesteps | 68066    |
| train/             |          |
|    actor_loss      | 0.257    |
|    critic_loss     | 3.53     |
|    learning_rate   | 0.000933 |
|    n_updates       | 65332    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 147      |
|    ep_rew_mean     | -0.284   |
| time/              |          |
|    episodes        | 472      |
|    fps             | 9        |
|    time_elapsed    | 7536     |
|    total timesteps | 68553    |
| train/             |          |
|    actor_loss      | 0.258    |
|    critic_loss     | 3.34     |
|    learning_rate   | 0.000932 |
|    n_updates       | 65819    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 148      |
|    ep_rew_mean     | -0.145   |
| time/              |          |
|    episodes        | 476      |
|    fps             | 9        |
|    time_elapsed    | 7627     |
|    total timesteps | 69167    |
| train/             |          |
|    actor_loss      | 0.3      |
|    critic_loss     | 3.26     |
|    learning_rate   | 0.000932 |
|    n_updates       | 66603    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 149      |
|    ep_rew_mean     | -0.145   |
| time/              |          |
|    episodes        | 480      |
|    fps             | 9        |
|    time_elapsed    | 7680     |
|    total timesteps | 69625    |
| train/             |          |
|    actor_loss      | 0.314    |
|    critic_loss     | 3.45     |
|    learning_rate   | 0.000931 |
|    n_updates       | 67053    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 149      |
|    ep_rew_mean     | 0.847    |
| time/              |          |
|    episodes        | 484      |
|    fps             | 9        |
|    time_elapsed    | 7714     |
|    total timesteps | 69992    |
| train/             |          |
|    actor_loss      | 0.302    |
|    critic_loss     | 3.36     |
|    learning_rate   | 0.000931 |
|    n_updates       | 67354    |
---------------------------------
Eval num_timesteps=70000, episode_reward=69.34 +/- 7.60
Episode length: 251.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 251      |
|    mean_reward     | 69.3     |
| time/              |          |
|    total_timesteps | 70000    |
| train/             |          |
|    actor_loss      | 0.301    |
|    critic_loss     | 3.44     |
|    learning_rate   | 0.000931 |
|    n_updates       | 67509    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 149      |
|    ep_rew_mean     | 0.589    |
| time/              |          |
|    episodes        | 488      |
|    fps             | 9        |
|    time_elapsed    | 7790     |
|    total timesteps | 70510    |
| train/             |          |
|    actor_loss      | 0.295    |
|    critic_loss     | 3.42     |
|    learning_rate   | 0.00093  |
|    n_updates       | 67921    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 146      |
|    ep_rew_mean     | 0.179    |
| time/              |          |
|    episodes        | 492      |
|    fps             | 9        |
|    time_elapsed    | 7832     |
|    total timesteps | 70964    |
| train/             |          |
|    actor_loss      | 0.298    |
|    critic_loss     | 3.66     |
|    learning_rate   | 0.00093  |
|    n_updates       | 68289    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 148      |
|    ep_rew_mean     | -0.147   |
| time/              |          |
|    episodes        | 496      |
|    fps             | 9        |
|    time_elapsed    | 7925     |
|    total timesteps | 71788    |
| train/             |          |
|    actor_loss      | 0.295    |
|    critic_loss     | 3.49     |
|    learning_rate   | 0.000929 |
|    n_updates       | 69132    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 150      |
|    ep_rew_mean     | -0.113   |
| time/              |          |
|    episodes        | 500      |
|    fps             | 9        |
|    time_elapsed    | 7999     |
|    total timesteps | 72402    |
| train/             |          |
|    actor_loss      | 0.341    |
|    critic_loss     | 3.32     |
|    learning_rate   | 0.000928 |
|    n_updates       | 69813    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 146      |
|    ep_rew_mean     | -0.285   |
| time/              |          |
|    episodes        | 504      |
|    fps             | 9        |
|    time_elapsed    | 8034     |
|    total timesteps | 72844    |
| train/             |          |
|    actor_loss      | 0.335    |
|    critic_loss     | 3.34     |
|    learning_rate   | 0.000928 |
|    n_updates       | 70110    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 147      |
|    ep_rew_mean     | 0.251    |
| time/              |          |
|    episodes        | 508      |
|    fps             | 9        |
|    time_elapsed    | 8130     |
|    total timesteps | 73659    |
| train/             |          |
|    actor_loss      | 0.328    |
|    critic_loss     | 3.46     |
|    learning_rate   | 0.000927 |
|    n_updates       | 70985    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 149      |
|    ep_rew_mean     | -0.136   |
| time/              |          |
|    episodes        | 512      |
|    fps             | 9        |
|    time_elapsed    | 8209     |
|    total timesteps | 74365    |
| train/             |          |
|    actor_loss      | 0.315    |
|    critic_loss     | 3.47     |
|    learning_rate   | 0.000927 |
|    n_updates       | 71699    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 149      |
|    ep_rew_mean     | -0.211   |
| time/              |          |
|    episodes        | 516      |
|    fps             | 9        |
|    time_elapsed    | 8272     |
|    total timesteps | 74840    |
| train/             |          |
|    actor_loss      | 0.329    |
|    critic_loss     | 3.44     |
|    learning_rate   | 0.000926 |
|    n_updates       | 72276    |
---------------------------------
Eval num_timesteps=75000, episode_reward=51.63 +/- 20.40
Episode length: 242.00 +/- 18.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 242      |
|    mean_reward     | 51.6     |
| time/              |          |
|    total_timesteps | 75000    |
| train/             |          |
|    actor_loss      | 0.314    |
|    critic_loss     | 3.34     |
|    learning_rate   | 0.000926 |
|    n_updates       | 72357    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 148      |
|    ep_rew_mean     | -0.187   |
| time/              |          |
|    episodes        | 520      |
|    fps             | 9        |
|    time_elapsed    | 8346     |
|    total timesteps | 75459    |
| train/             |          |
|    actor_loss      | 0.308    |
|    critic_loss     | 3.31     |
|    learning_rate   | 0.000925 |
|    n_updates       | 72839    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 147      |
|    ep_rew_mean     | -0.226   |
| time/              |          |
|    episodes        | 524      |
|    fps             | 9        |
|    time_elapsed    | 8414     |
|    total timesteps | 75983    |
| train/             |          |
|    actor_loss      | 0.307    |
|    critic_loss     | 3.47     |
|    learning_rate   | 0.000925 |
|    n_updates       | 73462    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 146      |
|    ep_rew_mean     | -0.288   |
| time/              |          |
|    episodes        | 528      |
|    fps             | 9        |
|    time_elapsed    | 8451     |
|    total timesteps | 76429    |
| train/             |          |
|    actor_loss      | 0.397    |
|    critic_loss     | 3.45     |
|    learning_rate   | 0.000925 |
|    n_updates       | 73772    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 147      |
|    ep_rew_mean     | -0.039   |
| time/              |          |
|    episodes        | 532      |
|    fps             | 9        |
|    time_elapsed    | 8516     |
|    total timesteps | 77071    |
| train/             |          |
|    actor_loss      | 0.375    |
|    critic_loss     | 3.45     |
|    learning_rate   | 0.000924 |
|    n_updates       | 74337    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 146      |
|    ep_rew_mean     | -0.621   |
| time/              |          |
|    episodes        | 536      |
|    fps             | 9        |
|    time_elapsed    | 8588     |
|    total timesteps | 77703    |
| train/             |          |
|    actor_loss      | 0.369    |
|    critic_loss     | 3.39     |
|    learning_rate   | 0.000923 |
|    n_updates       | 74969    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 151      |
|    ep_rew_mean     | -0.38    |
| time/              |          |
|    episodes        | 540      |
|    fps             | 9        |
|    time_elapsed    | 8688     |
|    total timesteps | 78577    |
| train/             |          |
|    actor_loss      | 0.338    |
|    critic_loss     | 3.34     |
|    learning_rate   | 0.000922 |
|    n_updates       | 75861    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 152      |
|    ep_rew_mean     | -0.381   |
| time/              |          |
|    episodes        | 544      |
|    fps             | 9        |
|    time_elapsed    | 8784     |
|    total timesteps | 79386    |
| train/             |          |
|    actor_loss      | 0.322    |
|    critic_loss     | 3.46     |
|    learning_rate   | 0.000922 |
|    n_updates       | 76721    |
---------------------------------
Eval num_timesteps=80000, episode_reward=43.67 +/- 18.19
Episode length: 225.00 +/- 21.34
---------------------------------
| eval/              |          |
|    mean_ep_length  | 225      |
|    mean_reward     | 43.7     |
| time/              |          |
|    total_timesteps | 80000    |
| train/             |          |
|    actor_loss      | 0.296    |
|    critic_loss     | 3.3      |
|    learning_rate   | 0.000921 |
|    n_updates       | 77344    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 156      |
|    ep_rew_mean     | 0.21     |
| time/              |          |
|    episodes        | 548      |
|    fps             | 9        |
|    time_elapsed    | 8887     |
|    total timesteps | 80253    |
| train/             |          |
|    actor_loss      | 0.297    |
|    critic_loss     | 3.34     |
|    learning_rate   | 0.000921 |
|    n_updates       | 77519    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 155      |
|    ep_rew_mean     | 0.183    |
| time/              |          |
|    episodes        | 552      |
|    fps             | 9        |
|    time_elapsed    | 8967     |
|    total timesteps | 80787    |
| train/             |          |
|    actor_loss      | 0.291    |
|    critic_loss     | 3.27     |
|    learning_rate   | 0.00092  |
|    n_updates       | 78270    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 155      |
|    ep_rew_mean     | 0.227    |
| time/              |          |
|    episodes        | 556      |
|    fps             | 9        |
|    time_elapsed    | 9010     |
|    total timesteps | 81225    |
| train/             |          |
|    actor_loss      | 0.286    |
|    critic_loss     | 3.15     |
|    learning_rate   | 0.00092  |
|    n_updates       | 78653    |
---------------------------------
